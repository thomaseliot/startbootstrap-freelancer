
FrontSensorModule.elf:     file format elf32-avr

Sections:
Idx Name          Size      VMA       LMA       File off  Algn
  0 .data         0000000a  00800100  00001c80  00001d14  2**0
                  CONTENTS, ALLOC, LOAD, DATA
  1 .text         00001c80  00000000  00000000  00000094  2**1
                  CONTENTS, ALLOC, LOAD, READONLY, CODE
  2 .bss          00000447  0080010a  0080010a  00001d1e  2**0
                  ALLOC
  3 .comment      00000030  00000000  00000000  00001d1e  2**0
                  CONTENTS, READONLY
  4 .debug_aranges 000000e0  00000000  00000000  00001d4e  2**0
                  CONTENTS, READONLY, DEBUGGING
  5 .debug_info   00003232  00000000  00000000  00001e2e  2**0
                  CONTENTS, READONLY, DEBUGGING
  6 .debug_abbrev 00000b0c  00000000  00000000  00005060  2**0
                  CONTENTS, READONLY, DEBUGGING
  7 .debug_line   00001a32  00000000  00000000  00005b6c  2**0
                  CONTENTS, READONLY, DEBUGGING
  8 .debug_frame  00000814  00000000  00000000  000075a0  2**2
                  CONTENTS, READONLY, DEBUGGING
  9 .debug_str    0000dff7  00000000  00000000  00007db4  2**0
                  CONTENTS, READONLY, DEBUGGING
 10 .debug_loc    00003157  00000000  00000000  00015dab  2**0
                  CONTENTS, READONLY, DEBUGGING
 11 .debug_ranges 00000048  00000000  00000000  00018f02  2**0
                  CONTENTS, READONLY, DEBUGGING
 12 .debug_macro  000048b3  00000000  00000000  00018f4a  2**0
                  CONTENTS, READONLY, DEBUGGING

Disassembly of section .text:

00000000 <__vectors>:
       0:	0c 94 3e 00 	jmp	0x7c	; 0x7c <__ctors_end>
       4:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
       8:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
       c:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      10:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      14:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      18:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      1c:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      20:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      24:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      28:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      2c:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      30:	0c 94 eb 02 	jmp	0x5d6	; 0x5d6 <__vector_12>
      34:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      38:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      3c:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      40:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      44:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      48:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      4c:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      50:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      54:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      58:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      5c:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      60:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      64:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      68:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      6c:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      70:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      74:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>
      78:	0c 94 5b 00 	jmp	0xb6	; 0xb6 <__bad_interrupt>

0000007c <__ctors_end>:
      7c:	11 24       	eor	r1, r1
      7e:	1f be       	out	0x3f, r1	; 63
      80:	cf ef       	ldi	r28, 0xFF	; 255
      82:	d0 e1       	ldi	r29, 0x10	; 16
      84:	de bf       	out	0x3e, r29	; 62
      86:	cd bf       	out	0x3d, r28	; 61

00000088 <__do_copy_data>:
      88:	11 e0       	ldi	r17, 0x01	; 1
      8a:	a0 e0       	ldi	r26, 0x00	; 0
      8c:	b1 e0       	ldi	r27, 0x01	; 1
      8e:	e0 e8       	ldi	r30, 0x80	; 128
      90:	fc e1       	ldi	r31, 0x1C	; 28
      92:	02 c0       	rjmp	.+4      	; 0x98 <__do_copy_data+0x10>
      94:	05 90       	lpm	r0, Z+
      96:	0d 92       	st	X+, r0
      98:	aa 30       	cpi	r26, 0x0A	; 10
      9a:	b1 07       	cpc	r27, r17
      9c:	d9 f7       	brne	.-10     	; 0x94 <__do_copy_data+0xc>

0000009e <__do_clear_bss>:
      9e:	25 e0       	ldi	r18, 0x05	; 5
      a0:	aa e0       	ldi	r26, 0x0A	; 10
      a2:	b1 e0       	ldi	r27, 0x01	; 1
      a4:	01 c0       	rjmp	.+2      	; 0xa8 <.do_clear_bss_start>

000000a6 <.do_clear_bss_loop>:
      a6:	1d 92       	st	X+, r1

000000a8 <.do_clear_bss_start>:
      a8:	a1 35       	cpi	r26, 0x51	; 81
      aa:	b2 07       	cpc	r27, r18
      ac:	e1 f7       	brne	.-8      	; 0xa6 <.do_clear_bss_loop>
      ae:	0e 94 5d 00 	call	0xba	; 0xba <main>
      b2:	0c 94 3e 0e 	jmp	0x1c7c	; 0x1c7c <_exit>

000000b6 <__bad_interrupt>:
      b6:	0c 94 00 00 	jmp	0	; 0x0 <__vectors>

000000ba <main>:
#include "task.h"

#define mainLED_TASK_PRIORITY           1

int main(void)
{	
      ba:	af 92       	push	r10
      bc:	bf 92       	push	r11
      be:	cf 92       	push	r12
      c0:	df 92       	push	r13
      c2:	ef 92       	push	r14
      c4:	ff 92       	push	r15
      c6:	0f 93       	push	r16
	config_io_pin(IO_PORT_C, 0, IO_DIR_OUTPUT);
      c8:	41 e0       	ldi	r20, 0x01	; 1
      ca:	60 e0       	ldi	r22, 0x00	; 0
      cc:	81 e0       	ldi	r24, 0x01	; 1
      ce:	0e 94 86 00 	call	0x10c	; 0x10c <config_io_pin>
	
    xTaskCreate(vLEDFlashTask, "LED", configMINIMAL_STACK_SIZE, 
      d2:	a1 2c       	mov	r10, r1
      d4:	b1 2c       	mov	r11, r1
      d6:	c1 2c       	mov	r12, r1
      d8:	d1 2c       	mov	r13, r1
      da:	e1 2c       	mov	r14, r1
      dc:	f1 2c       	mov	r15, r1
      de:	01 e0       	ldi	r16, 0x01	; 1
      e0:	20 e0       	ldi	r18, 0x00	; 0
      e2:	30 e0       	ldi	r19, 0x00	; 0
      e4:	45 e5       	ldi	r20, 0x55	; 85
      e6:	50 e0       	ldi	r21, 0x00	; 0
      e8:	60 e0       	ldi	r22, 0x00	; 0
      ea:	71 e0       	ldi	r23, 0x01	; 1
      ec:	88 ef       	ldi	r24, 0xF8	; 248
      ee:	90 e0       	ldi	r25, 0x00	; 0
      f0:	0e 94 c1 06 	call	0xd82	; 0xd82 <xTaskGenericCreate>
		NULL, mainLED_TASK_PRIORITY, NULL);
	
	vTaskStartScheduler();
      f4:	0e 94 11 08 	call	0x1022	; 0x1022 <vTaskStartScheduler>
	
	return 0;
}
      f8:	80 e0       	ldi	r24, 0x00	; 0
      fa:	90 e0       	ldi	r25, 0x00	; 0
      fc:	0f 91       	pop	r16
      fe:	ff 90       	pop	r15
     100:	ef 90       	pop	r14
     102:	df 90       	pop	r13
     104:	cf 90       	pop	r12
     106:	bf 90       	pop	r11
     108:	af 90       	pop	r10
     10a:	08 95       	ret

0000010c <config_io_pin>:

#include "node_tasks.h"
#include <avr/io.h>

void config_io_pin(uint8_t port, uint8_t port_ch, uint8_t dir){
	switch(port){
     10c:	81 30       	cpi	r24, 0x01	; 1
     10e:	a9 f0       	breq	.+42     	; 0x13a <config_io_pin+0x2e>
     110:	18 f0       	brcs	.+6      	; 0x118 <config_io_pin+0xc>
     112:	82 30       	cpi	r24, 0x02	; 2
     114:	19 f1       	breq	.+70     	; 0x15c <config_io_pin+0x50>
     116:	08 95       	ret
		case IO_PORT_B:
		//Crazy bit trickery that sets the port_ch bit of DDRB to dir
		DDRB ^= ((-dir) ^ DDRB) & (1 << port_ch);
     118:	24 b1       	in	r18, 0x04	; 4
     11a:	84 b1       	in	r24, 0x04	; 4
     11c:	41 95       	neg	r20
     11e:	48 27       	eor	r20, r24
     120:	81 e0       	ldi	r24, 0x01	; 1
     122:	90 e0       	ldi	r25, 0x00	; 0
     124:	fc 01       	movw	r30, r24
     126:	02 c0       	rjmp	.+4      	; 0x12c <config_io_pin+0x20>
     128:	ee 0f       	add	r30, r30
     12a:	ff 1f       	adc	r31, r31
     12c:	6a 95       	dec	r22
     12e:	e2 f7       	brpl	.-8      	; 0x128 <config_io_pin+0x1c>
     130:	bf 01       	movw	r22, r30
     132:	64 23       	and	r22, r20
     134:	62 27       	eor	r22, r18
     136:	64 b9       	out	0x04, r22	; 4
		break;
     138:	08 95       	ret
		case IO_PORT_C:
		DDRC ^= ((-dir) ^ DDRC) & (1 << port_ch);
     13a:	27 b1       	in	r18, 0x07	; 7
     13c:	87 b1       	in	r24, 0x07	; 7
     13e:	41 95       	neg	r20
     140:	48 27       	eor	r20, r24
     142:	81 e0       	ldi	r24, 0x01	; 1
     144:	90 e0       	ldi	r25, 0x00	; 0
     146:	fc 01       	movw	r30, r24
     148:	02 c0       	rjmp	.+4      	; 0x14e <config_io_pin+0x42>
     14a:	ee 0f       	add	r30, r30
     14c:	ff 1f       	adc	r31, r31
     14e:	6a 95       	dec	r22
     150:	e2 f7       	brpl	.-8      	; 0x14a <config_io_pin+0x3e>
     152:	bf 01       	movw	r22, r30
     154:	64 23       	and	r22, r20
     156:	62 27       	eor	r22, r18
     158:	67 b9       	out	0x07, r22	; 7
		break;
     15a:	08 95       	ret
		case IO_PORT_D:
		DDRD ^= ((-dir) ^ DDRD) & (1 << port_ch);
     15c:	2a b1       	in	r18, 0x0a	; 10
     15e:	8a b1       	in	r24, 0x0a	; 10
     160:	41 95       	neg	r20
     162:	48 27       	eor	r20, r24
     164:	81 e0       	ldi	r24, 0x01	; 1
     166:	90 e0       	ldi	r25, 0x00	; 0
     168:	fc 01       	movw	r30, r24
     16a:	02 c0       	rjmp	.+4      	; 0x170 <config_io_pin+0x64>
     16c:	ee 0f       	add	r30, r30
     16e:	ff 1f       	adc	r31, r31
     170:	6a 95       	dec	r22
     172:	e2 f7       	brpl	.-8      	; 0x16c <config_io_pin+0x60>
     174:	bf 01       	movw	r22, r30
     176:	64 23       	and	r22, r20
     178:	62 27       	eor	r22, r18
     17a:	6a b9       	out	0x0a, r22	; 10
     17c:	08 95       	ret

0000017e <set_io_pin>:
		break;
	}
}

void set_io_pin(uint8_t port, uint8_t port_ch, uint8_t val) {
	switch(port){
     17e:	81 30       	cpi	r24, 0x01	; 1
     180:	a9 f0       	breq	.+42     	; 0x1ac <set_io_pin+0x2e>
     182:	18 f0       	brcs	.+6      	; 0x18a <set_io_pin+0xc>
     184:	82 30       	cpi	r24, 0x02	; 2
     186:	19 f1       	breq	.+70     	; 0x1ce <set_io_pin+0x50>
     188:	08 95       	ret
		case IO_PORT_B:
		PORTB ^= ((-val) ^ PORTB) & (1 << port_ch);
     18a:	25 b1       	in	r18, 0x05	; 5
     18c:	85 b1       	in	r24, 0x05	; 5
     18e:	41 95       	neg	r20
     190:	48 27       	eor	r20, r24
     192:	81 e0       	ldi	r24, 0x01	; 1
     194:	90 e0       	ldi	r25, 0x00	; 0
     196:	fc 01       	movw	r30, r24
     198:	02 c0       	rjmp	.+4      	; 0x19e <set_io_pin+0x20>
     19a:	ee 0f       	add	r30, r30
     19c:	ff 1f       	adc	r31, r31
     19e:	6a 95       	dec	r22
     1a0:	e2 f7       	brpl	.-8      	; 0x19a <set_io_pin+0x1c>
     1a2:	bf 01       	movw	r22, r30
     1a4:	64 23       	and	r22, r20
     1a6:	62 27       	eor	r22, r18
     1a8:	65 b9       	out	0x05, r22	; 5
		break;
     1aa:	08 95       	ret
		case IO_PORT_C:
		PORTC ^= ((-val) ^ PORTC) & (1 << port_ch);
     1ac:	28 b1       	in	r18, 0x08	; 8
     1ae:	88 b1       	in	r24, 0x08	; 8
     1b0:	41 95       	neg	r20
     1b2:	48 27       	eor	r20, r24
     1b4:	81 e0       	ldi	r24, 0x01	; 1
     1b6:	90 e0       	ldi	r25, 0x00	; 0
     1b8:	fc 01       	movw	r30, r24
     1ba:	02 c0       	rjmp	.+4      	; 0x1c0 <set_io_pin+0x42>
     1bc:	ee 0f       	add	r30, r30
     1be:	ff 1f       	adc	r31, r31
     1c0:	6a 95       	dec	r22
     1c2:	e2 f7       	brpl	.-8      	; 0x1bc <set_io_pin+0x3e>
     1c4:	bf 01       	movw	r22, r30
     1c6:	64 23       	and	r22, r20
     1c8:	62 27       	eor	r22, r18
     1ca:	68 b9       	out	0x08, r22	; 8
		break;
     1cc:	08 95       	ret
		case IO_PORT_D:
		PORTD ^= ((-val) ^ PORTD) & (1 << port_ch);
     1ce:	2b b1       	in	r18, 0x0b	; 11
     1d0:	8b b1       	in	r24, 0x0b	; 11
     1d2:	41 95       	neg	r20
     1d4:	48 27       	eor	r20, r24
     1d6:	81 e0       	ldi	r24, 0x01	; 1
     1d8:	90 e0       	ldi	r25, 0x00	; 0
     1da:	fc 01       	movw	r30, r24
     1dc:	02 c0       	rjmp	.+4      	; 0x1e2 <set_io_pin+0x64>
     1de:	ee 0f       	add	r30, r30
     1e0:	ff 1f       	adc	r31, r31
     1e2:	6a 95       	dec	r22
     1e4:	e2 f7       	brpl	.-8      	; 0x1de <set_io_pin+0x60>
     1e6:	bf 01       	movw	r22, r30
     1e8:	64 23       	and	r22, r20
     1ea:	62 27       	eor	r22, r18
     1ec:	6b b9       	out	0x0b, r22	; 11
     1ee:	08 95       	ret

000001f0 <vLEDFlashTask>:
}

void vLEDFlashTask(void *pvParameters) {
	
	for(;;) {
		PORTC ^= (1 << 0);
     1f0:	c1 e0       	ldi	r28, 0x01	; 1
     1f2:	88 b1       	in	r24, 0x08	; 8
     1f4:	8c 27       	eor	r24, r28
     1f6:	88 b9       	out	0x08, r24	; 8
		vTaskDelay((TickType_t)1000); 
     1f8:	88 ee       	ldi	r24, 0xE8	; 232
     1fa:	93 e0       	ldi	r25, 0x03	; 3
     1fc:	0e 94 e5 09 	call	0x13ca	; 0x13ca <vTaskDelay>
     200:	f8 cf       	rjmp	.-16     	; 0x1f2 <vLEDFlashTask+0x2>

00000202 <vListInitialise>:
/*-----------------------------------------------------------
 * PUBLIC LIST API documented in list.h
 *----------------------------------------------------------*/

void vListInitialise( List_t * const pxList )
{
     202:	fc 01       	movw	r30, r24
	/* The list structure contains a list item which is used to mark the
	end of the list.  To initialise the list the list end is inserted
	as the only list entry. */
	pxList->pxIndex = ( ListItem_t * ) &( pxList->xListEnd );			/*lint !e826 !e740 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     204:	03 96       	adiw	r24, 0x03	; 3
     206:	92 83       	std	Z+2, r25	; 0x02
     208:	81 83       	std	Z+1, r24	; 0x01

	/* The list end value is the highest possible value in the list to
	ensure it remains at the end of the list. */
	pxList->xListEnd.xItemValue = portMAX_DELAY;
     20a:	2f ef       	ldi	r18, 0xFF	; 255
     20c:	3f ef       	ldi	r19, 0xFF	; 255
     20e:	34 83       	std	Z+4, r19	; 0x04
     210:	23 83       	std	Z+3, r18	; 0x03

	/* The list end next and previous pointers point to itself so we know
	when the list is empty. */
	pxList->xListEnd.pxNext = ( ListItem_t * ) &( pxList->xListEnd );	/*lint !e826 !e740 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     212:	96 83       	std	Z+6, r25	; 0x06
     214:	85 83       	std	Z+5, r24	; 0x05
	pxList->xListEnd.pxPrevious = ( ListItem_t * ) &( pxList->xListEnd );/*lint !e826 !e740 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     216:	90 87       	std	Z+8, r25	; 0x08
     218:	87 83       	std	Z+7, r24	; 0x07

	pxList->uxNumberOfItems = ( UBaseType_t ) 0U;
     21a:	10 82       	st	Z, r1
     21c:	08 95       	ret

0000021e <vListInitialiseItem>:
/*-----------------------------------------------------------*/

void vListInitialiseItem( ListItem_t * const pxItem )
{
	/* Make sure the list item is not recorded as being on a list. */
	pxItem->pvContainer = NULL;
     21e:	fc 01       	movw	r30, r24
     220:	11 86       	std	Z+9, r1	; 0x09
     222:	10 86       	std	Z+8, r1	; 0x08
     224:	08 95       	ret

00000226 <vListInsertEnd>:
	listSET_SECOND_LIST_ITEM_INTEGRITY_CHECK_VALUE( pxItem );
}
/*-----------------------------------------------------------*/

void vListInsertEnd( List_t * const pxList, ListItem_t * const pxNewListItem )
{
     226:	cf 93       	push	r28
     228:	df 93       	push	r29
     22a:	9c 01       	movw	r18, r24
     22c:	fb 01       	movw	r30, r22
ListItem_t * const pxIndex = pxList->pxIndex;
     22e:	dc 01       	movw	r26, r24
     230:	11 96       	adiw	r26, 0x01	; 1
     232:	cd 91       	ld	r28, X+
     234:	dc 91       	ld	r29, X
     236:	12 97       	sbiw	r26, 0x02	; 2
	listTEST_LIST_ITEM_INTEGRITY( pxNewListItem );

	/* Insert a new list item into pxList, but rather than sort the list,
	makes the new list item the last item to be removed by a call to
	listGET_OWNER_OF_NEXT_ENTRY(). */
	pxNewListItem->pxNext = pxIndex;
     238:	d3 83       	std	Z+3, r29	; 0x03
     23a:	c2 83       	std	Z+2, r28	; 0x02
	pxNewListItem->pxPrevious = pxIndex->pxPrevious;
     23c:	8c 81       	ldd	r24, Y+4	; 0x04
     23e:	9d 81       	ldd	r25, Y+5	; 0x05
     240:	95 83       	std	Z+5, r25	; 0x05
     242:	84 83       	std	Z+4, r24	; 0x04

	/* Only used during decision coverage testing. */
	mtCOVERAGE_TEST_DELAY();

	pxIndex->pxPrevious->pxNext = pxNewListItem;
     244:	8c 81       	ldd	r24, Y+4	; 0x04
     246:	9d 81       	ldd	r25, Y+5	; 0x05
     248:	dc 01       	movw	r26, r24
     24a:	13 96       	adiw	r26, 0x03	; 3
     24c:	7c 93       	st	X, r23
     24e:	6e 93       	st	-X, r22
     250:	12 97       	sbiw	r26, 0x02	; 2
	pxIndex->pxPrevious = pxNewListItem;
     252:	7d 83       	std	Y+5, r23	; 0x05
     254:	6c 83       	std	Y+4, r22	; 0x04

	/* Remember which list the item is in. */
	pxNewListItem->pvContainer = ( void * ) pxList;
     256:	31 87       	std	Z+9, r19	; 0x09
     258:	20 87       	std	Z+8, r18	; 0x08

	( pxList->uxNumberOfItems )++;
     25a:	f9 01       	movw	r30, r18
     25c:	80 81       	ld	r24, Z
     25e:	8f 5f       	subi	r24, 0xFF	; 255
     260:	80 83       	st	Z, r24
}
     262:	df 91       	pop	r29
     264:	cf 91       	pop	r28
     266:	08 95       	ret

00000268 <vListInsert>:
/*-----------------------------------------------------------*/

void vListInsert( List_t * const pxList, ListItem_t * const pxNewListItem )
{
     268:	cf 93       	push	r28
     26a:	df 93       	push	r29
     26c:	eb 01       	movw	r28, r22
ListItem_t *pxIterator;
const TickType_t xValueOfInsertion = pxNewListItem->xItemValue;
     26e:	48 81       	ld	r20, Y
     270:	59 81       	ldd	r21, Y+1	; 0x01
	new list item should be placed after it.  This ensures that TCB's which are
	stored in ready lists (all of which have the same xItemValue value) get a
	share of the CPU.  However, if the xItemValue is the same as the back marker
	the iteration loop below will not end.  Therefore the value is checked
	first, and the algorithm slightly modified if necessary. */
	if( xValueOfInsertion == portMAX_DELAY )
     272:	4f 3f       	cpi	r20, 0xFF	; 255
     274:	2f ef       	ldi	r18, 0xFF	; 255
     276:	52 07       	cpc	r21, r18
     278:	21 f4       	brne	.+8      	; 0x282 <vListInsert+0x1a>
	{
		pxIterator = pxList->xListEnd.pxPrevious;
     27a:	fc 01       	movw	r30, r24
     27c:	a7 81       	ldd	r26, Z+7	; 0x07
     27e:	b0 85       	ldd	r27, Z+8	; 0x08
     280:	0d c0       	rjmp	.+26     	; 0x29c <vListInsert+0x34>
			4) Using a queue or semaphore before it has been initialised or
			   before the scheduler has been started (are interrupts firing
			   before vTaskStartScheduler() has been called?).
		**********************************************************************/

		for( pxIterator = ( ListItem_t * ) &( pxList->xListEnd ); pxIterator->pxNext->xItemValue <= xValueOfInsertion; pxIterator = pxIterator->pxNext ) /*lint !e826 !e740 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     282:	dc 01       	movw	r26, r24
     284:	13 96       	adiw	r26, 0x03	; 3
     286:	12 96       	adiw	r26, 0x02	; 2
     288:	ed 91       	ld	r30, X+
     28a:	fc 91       	ld	r31, X
     28c:	13 97       	sbiw	r26, 0x03	; 3
     28e:	20 81       	ld	r18, Z
     290:	31 81       	ldd	r19, Z+1	; 0x01
     292:	42 17       	cp	r20, r18
     294:	53 07       	cpc	r21, r19
     296:	10 f0       	brcs	.+4      	; 0x29c <vListInsert+0x34>
     298:	df 01       	movw	r26, r30
     29a:	f5 cf       	rjmp	.-22     	; 0x286 <vListInsert+0x1e>
			/* There is nothing to do here, just iterating to the wanted
			insertion position. */
		}
	}

	pxNewListItem->pxNext = pxIterator->pxNext;
     29c:	12 96       	adiw	r26, 0x02	; 2
     29e:	ed 91       	ld	r30, X+
     2a0:	fc 91       	ld	r31, X
     2a2:	13 97       	sbiw	r26, 0x03	; 3
     2a4:	fb 83       	std	Y+3, r31	; 0x03
     2a6:	ea 83       	std	Y+2, r30	; 0x02
	pxNewListItem->pxNext->pxPrevious = pxNewListItem;
     2a8:	d5 83       	std	Z+5, r29	; 0x05
     2aa:	c4 83       	std	Z+4, r28	; 0x04
	pxNewListItem->pxPrevious = pxIterator;
     2ac:	bd 83       	std	Y+5, r27	; 0x05
     2ae:	ac 83       	std	Y+4, r26	; 0x04
	pxIterator->pxNext = pxNewListItem;
     2b0:	13 96       	adiw	r26, 0x03	; 3
     2b2:	dc 93       	st	X, r29
     2b4:	ce 93       	st	-X, r28
     2b6:	12 97       	sbiw	r26, 0x02	; 2

	/* Remember which list the item is in.  This allows fast removal of the
	item later. */
	pxNewListItem->pvContainer = ( void * ) pxList;
     2b8:	99 87       	std	Y+9, r25	; 0x09
     2ba:	88 87       	std	Y+8, r24	; 0x08

	( pxList->uxNumberOfItems )++;
     2bc:	fc 01       	movw	r30, r24
     2be:	20 81       	ld	r18, Z
     2c0:	2f 5f       	subi	r18, 0xFF	; 255
     2c2:	20 83       	st	Z, r18
}
     2c4:	df 91       	pop	r29
     2c6:	cf 91       	pop	r28
     2c8:	08 95       	ret

000002ca <uxListRemove>:
/*-----------------------------------------------------------*/

UBaseType_t uxListRemove( ListItem_t * const pxItemToRemove )
{
     2ca:	cf 93       	push	r28
     2cc:	df 93       	push	r29
     2ce:	fc 01       	movw	r30, r24
/* The list item knows which list it is in.  Obtain the list from the list
item. */
List_t * const pxList = ( List_t * ) pxItemToRemove->pvContainer;
     2d0:	a0 85       	ldd	r26, Z+8	; 0x08
     2d2:	b1 85       	ldd	r27, Z+9	; 0x09

	pxItemToRemove->pxNext->pxPrevious = pxItemToRemove->pxPrevious;
     2d4:	c2 81       	ldd	r28, Z+2	; 0x02
     2d6:	d3 81       	ldd	r29, Z+3	; 0x03
     2d8:	84 81       	ldd	r24, Z+4	; 0x04
     2da:	95 81       	ldd	r25, Z+5	; 0x05
     2dc:	9d 83       	std	Y+5, r25	; 0x05
     2de:	8c 83       	std	Y+4, r24	; 0x04
	pxItemToRemove->pxPrevious->pxNext = pxItemToRemove->pxNext;
     2e0:	c4 81       	ldd	r28, Z+4	; 0x04
     2e2:	d5 81       	ldd	r29, Z+5	; 0x05
     2e4:	82 81       	ldd	r24, Z+2	; 0x02
     2e6:	93 81       	ldd	r25, Z+3	; 0x03
     2e8:	9b 83       	std	Y+3, r25	; 0x03
     2ea:	8a 83       	std	Y+2, r24	; 0x02

	/* Only used during decision coverage testing. */
	mtCOVERAGE_TEST_DELAY();

	/* Make sure the index is left pointing to a valid item. */
	if( pxList->pxIndex == pxItemToRemove )
     2ec:	11 96       	adiw	r26, 0x01	; 1
     2ee:	cd 91       	ld	r28, X+
     2f0:	dc 91       	ld	r29, X
     2f2:	12 97       	sbiw	r26, 0x02	; 2
     2f4:	ce 17       	cp	r28, r30
     2f6:	df 07       	cpc	r29, r31
     2f8:	31 f4       	brne	.+12     	; 0x306 <uxListRemove+0x3c>
	{
		pxList->pxIndex = pxItemToRemove->pxPrevious;
     2fa:	8c 81       	ldd	r24, Y+4	; 0x04
     2fc:	9d 81       	ldd	r25, Y+5	; 0x05
     2fe:	12 96       	adiw	r26, 0x02	; 2
     300:	9c 93       	st	X, r25
     302:	8e 93       	st	-X, r24
     304:	11 97       	sbiw	r26, 0x01	; 1
	else
	{
		mtCOVERAGE_TEST_MARKER();
	}

	pxItemToRemove->pvContainer = NULL;
     306:	11 86       	std	Z+9, r1	; 0x09
     308:	10 86       	std	Z+8, r1	; 0x08
	( pxList->uxNumberOfItems )--;
     30a:	8c 91       	ld	r24, X
     30c:	81 50       	subi	r24, 0x01	; 1
     30e:	8c 93       	st	X, r24

	return pxList->uxNumberOfItems;
}
     310:	df 91       	pop	r29
     312:	cf 91       	pop	r28
     314:	08 95       	ret

00000316 <pxPortInitialiseStack>:
uint16_t usAddress;

	/* Place a few bytes of known values on the bottom of the stack. 
	This is just useful for debugging. */

	*pxTopOfStack = 0x11;
     316:	31 e1       	ldi	r19, 0x11	; 17
     318:	fc 01       	movw	r30, r24
     31a:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = 0x22;
     31c:	31 97       	sbiw	r30, 0x01	; 1
     31e:	22 e2       	ldi	r18, 0x22	; 34
     320:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = 0x33;
     322:	31 97       	sbiw	r30, 0x01	; 1
     324:	a3 e3       	ldi	r26, 0x33	; 51
     326:	a0 83       	st	Z, r26
	/*lint -e950 -e611 -e923 Lint doesn't like this much - but nothing I can do about it. */

	/* The start of the task code will be popped off the stack last, so place
	it on first. */
	usAddress = ( uint16_t ) pxCode;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     328:	31 97       	sbiw	r30, 0x01	; 1
     32a:	60 83       	st	Z, r22
	pxTopOfStack--;

	usAddress >>= 8;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     32c:	31 97       	sbiw	r30, 0x01	; 1
     32e:	70 83       	st	Z, r23

	/* Next simulate the stack as if after a call to portSAVE_CONTEXT().  
	portSAVE_CONTEXT places the flags on the stack immediately after r0
	to ensure the interrupts get disabled as soon as possible, and so ensuring
	the stack use is minimal should a context switch interrupt occur. */
	*pxTopOfStack = ( StackType_t ) 0x00;	/* R0 */
     330:	31 97       	sbiw	r30, 0x01	; 1
     332:	10 82       	st	Z, r1
	pxTopOfStack--;
	*pxTopOfStack = portFLAGS_INT_ENABLED;
     334:	31 97       	sbiw	r30, 0x01	; 1
     336:	60 e8       	ldi	r22, 0x80	; 128
     338:	60 83       	st	Z, r22
	pxTopOfStack--;


	/* Now the remaining registers.   The compiler expects R1 to be 0. */
	*pxTopOfStack = ( StackType_t ) 0x00;	/* R1 */
     33a:	31 97       	sbiw	r30, 0x01	; 1
     33c:	10 82       	st	Z, r1
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x02;	/* R2 */
     33e:	31 97       	sbiw	r30, 0x01	; 1
     340:	62 e0       	ldi	r22, 0x02	; 2
     342:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x03;	/* R3 */
     344:	31 97       	sbiw	r30, 0x01	; 1
     346:	63 e0       	ldi	r22, 0x03	; 3
     348:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x04;	/* R4 */
     34a:	31 97       	sbiw	r30, 0x01	; 1
     34c:	64 e0       	ldi	r22, 0x04	; 4
     34e:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x05;	/* R5 */
     350:	31 97       	sbiw	r30, 0x01	; 1
     352:	65 e0       	ldi	r22, 0x05	; 5
     354:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x06;	/* R6 */
     356:	31 97       	sbiw	r30, 0x01	; 1
     358:	66 e0       	ldi	r22, 0x06	; 6
     35a:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x07;	/* R7 */
     35c:	31 97       	sbiw	r30, 0x01	; 1
     35e:	67 e0       	ldi	r22, 0x07	; 7
     360:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x08;	/* R8 */
     362:	31 97       	sbiw	r30, 0x01	; 1
     364:	68 e0       	ldi	r22, 0x08	; 8
     366:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x09;	/* R9 */
     368:	31 97       	sbiw	r30, 0x01	; 1
     36a:	69 e0       	ldi	r22, 0x09	; 9
     36c:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x10;	/* R10 */
     36e:	31 97       	sbiw	r30, 0x01	; 1
     370:	60 e1       	ldi	r22, 0x10	; 16
     372:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x11;	/* R11 */
     374:	31 97       	sbiw	r30, 0x01	; 1
     376:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x12;	/* R12 */
     378:	31 97       	sbiw	r30, 0x01	; 1
     37a:	32 e1       	ldi	r19, 0x12	; 18
     37c:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x13;	/* R13 */
     37e:	31 97       	sbiw	r30, 0x01	; 1
     380:	33 e1       	ldi	r19, 0x13	; 19
     382:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x14;	/* R14 */
     384:	31 97       	sbiw	r30, 0x01	; 1
     386:	34 e1       	ldi	r19, 0x14	; 20
     388:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x15;	/* R15 */
     38a:	31 97       	sbiw	r30, 0x01	; 1
     38c:	35 e1       	ldi	r19, 0x15	; 21
     38e:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x16;	/* R16 */
     390:	31 97       	sbiw	r30, 0x01	; 1
     392:	36 e1       	ldi	r19, 0x16	; 22
     394:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x17;	/* R17 */
     396:	31 97       	sbiw	r30, 0x01	; 1
     398:	37 e1       	ldi	r19, 0x17	; 23
     39a:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x18;	/* R18 */
     39c:	31 97       	sbiw	r30, 0x01	; 1
     39e:	38 e1       	ldi	r19, 0x18	; 24
     3a0:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x19;	/* R19 */
     3a2:	31 97       	sbiw	r30, 0x01	; 1
     3a4:	39 e1       	ldi	r19, 0x19	; 25
     3a6:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x20;	/* R20 */
     3a8:	31 97       	sbiw	r30, 0x01	; 1
     3aa:	30 e2       	ldi	r19, 0x20	; 32
     3ac:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x21;	/* R21 */
     3ae:	31 97       	sbiw	r30, 0x01	; 1
     3b0:	31 e2       	ldi	r19, 0x21	; 33
     3b2:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x22;	/* R22 */
     3b4:	31 97       	sbiw	r30, 0x01	; 1
     3b6:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x23;	/* R23 */
     3b8:	31 97       	sbiw	r30, 0x01	; 1
     3ba:	23 e2       	ldi	r18, 0x23	; 35
     3bc:	20 83       	st	Z, r18
	pxTopOfStack--;

	/* Place the parameter on the stack in the expected location. */
	usAddress = ( uint16_t ) pvParameters;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     3be:	31 97       	sbiw	r30, 0x01	; 1
     3c0:	40 83       	st	Z, r20
	pxTopOfStack--;

	usAddress >>= 8;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     3c2:	31 97       	sbiw	r30, 0x01	; 1
     3c4:	50 83       	st	Z, r21
	pxTopOfStack--;

	*pxTopOfStack = ( StackType_t ) 0x26;	/* R26 X */
     3c6:	31 97       	sbiw	r30, 0x01	; 1
     3c8:	26 e2       	ldi	r18, 0x26	; 38
     3ca:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x27;	/* R27 */
     3cc:	31 97       	sbiw	r30, 0x01	; 1
     3ce:	27 e2       	ldi	r18, 0x27	; 39
     3d0:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x28;	/* R28 Y */
     3d2:	31 97       	sbiw	r30, 0x01	; 1
     3d4:	28 e2       	ldi	r18, 0x28	; 40
     3d6:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x29;	/* R29 */
     3d8:	31 97       	sbiw	r30, 0x01	; 1
     3da:	29 e2       	ldi	r18, 0x29	; 41
     3dc:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x30;	/* R30 Z */
     3de:	31 97       	sbiw	r30, 0x01	; 1
     3e0:	20 e3       	ldi	r18, 0x30	; 48
     3e2:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x031;	/* R31 */
     3e4:	31 97       	sbiw	r30, 0x01	; 1
     3e6:	21 e3       	ldi	r18, 0x31	; 49
     3e8:	20 83       	st	Z, r18
	pxTopOfStack--;

	/*lint +e950 +e611 +e923 */

	return pxTopOfStack;
}
     3ea:	86 97       	sbiw	r24, 0x26	; 38
     3ec:	08 95       	ret

000003ee <xPortStartScheduler>:
	/* Setup compare match value for compare match A.  Interrupts are disabled 
	before this is called so we need not worry here. */
	ucLowByte = ( uint8_t ) ( ulCompareMatch & ( uint32_t ) 0xff );
	ulCompareMatch >>= 8;
	ucHighByte = ( uint8_t ) ( ulCompareMatch & ( uint32_t ) 0xff );
	OCR1AH = ucHighByte;
     3ee:	10 92 89 00 	sts	0x0089, r1
	OCR1AL = ucLowByte;
     3f2:	89 ef       	ldi	r24, 0xF9	; 249
     3f4:	80 93 88 00 	sts	0x0088, r24

	/* Setup clock source and compare match behaviour. */
	ucLowByte = portCLEAR_COUNTER_ON_MATCH | portPRESCALE_64;
	TCCR1B = ucLowByte;
     3f8:	8b e0       	ldi	r24, 0x0B	; 11
     3fa:	80 93 81 00 	sts	0x0081, r24

	/* Enable the interrupt - this is okay as interrupt are currently globally
	disabled. */
	ucLowByte = TIMSK1;
     3fe:	ef e6       	ldi	r30, 0x6F	; 111
     400:	f0 e0       	ldi	r31, 0x00	; 0
     402:	80 81       	ld	r24, Z
	ucLowByte |= portCOMPARE_MATCH_A_INTERRUPT_ENABLE;
     404:	82 60       	ori	r24, 0x02	; 2
	TIMSK1 = ucLowByte;
     406:	80 83       	st	Z, r24
	
	TCNT1 = 0;
     408:	10 92 85 00 	sts	0x0085, r1
     40c:	10 92 84 00 	sts	0x0084, r1
{
	/* Setup the hardware to generate the tick. */
	prvSetupTimerInterrupt();

	/* Restore the context of the first task that is going to run. */
	portRESTORE_CONTEXT();
     410:	a0 91 f6 04 	lds	r26, 0x04F6
     414:	b0 91 f7 04 	lds	r27, 0x04F7
     418:	cd 91       	ld	r28, X+
     41a:	cd bf       	out	0x3d, r28	; 61
     41c:	dd 91       	ld	r29, X+
     41e:	de bf       	out	0x3e, r29	; 62
     420:	ff 91       	pop	r31
     422:	ef 91       	pop	r30
     424:	df 91       	pop	r29
     426:	cf 91       	pop	r28
     428:	bf 91       	pop	r27
     42a:	af 91       	pop	r26
     42c:	9f 91       	pop	r25
     42e:	8f 91       	pop	r24
     430:	7f 91       	pop	r23
     432:	6f 91       	pop	r22
     434:	5f 91       	pop	r21
     436:	4f 91       	pop	r20
     438:	3f 91       	pop	r19
     43a:	2f 91       	pop	r18
     43c:	1f 91       	pop	r17
     43e:	0f 91       	pop	r16
     440:	ff 90       	pop	r15
     442:	ef 90       	pop	r14
     444:	df 90       	pop	r13
     446:	cf 90       	pop	r12
     448:	bf 90       	pop	r11
     44a:	af 90       	pop	r10
     44c:	9f 90       	pop	r9
     44e:	8f 90       	pop	r8
     450:	7f 90       	pop	r7
     452:	6f 90       	pop	r6
     454:	5f 90       	pop	r5
     456:	4f 90       	pop	r4
     458:	3f 90       	pop	r3
     45a:	2f 90       	pop	r2
     45c:	1f 90       	pop	r1
     45e:	0f 90       	pop	r0
     460:	0f be       	out	0x3f, r0	; 63
     462:	0f 90       	pop	r0

	/* Simulate a function call end as generated by the compiler.  We will now
	jump to the start of the task the context of which we have just restored. */
	asm volatile ( "ret" );
     464:	08 95       	ret

	/* Should not get here. */
	return pdTRUE;
}
     466:	81 e0       	ldi	r24, 0x01	; 1
     468:	08 95       	ret

0000046a <vPortEndScheduler>:
/*-----------------------------------------------------------*/

void vPortEndScheduler( void )
{
     46a:	08 95       	ret

0000046c <vPortYield>:
 * can use a naked attribute.
 */
void vPortYield( void ) __attribute__ ( ( naked ) );
void vPortYield( void )
{
	portSAVE_CONTEXT();
     46c:	0f 92       	push	r0
     46e:	0f b6       	in	r0, 0x3f	; 63
     470:	f8 94       	cli
     472:	0f 92       	push	r0
     474:	1f 92       	push	r1
     476:	11 24       	eor	r1, r1
     478:	2f 92       	push	r2
     47a:	3f 92       	push	r3
     47c:	4f 92       	push	r4
     47e:	5f 92       	push	r5
     480:	6f 92       	push	r6
     482:	7f 92       	push	r7
     484:	8f 92       	push	r8
     486:	9f 92       	push	r9
     488:	af 92       	push	r10
     48a:	bf 92       	push	r11
     48c:	cf 92       	push	r12
     48e:	df 92       	push	r13
     490:	ef 92       	push	r14
     492:	ff 92       	push	r15
     494:	0f 93       	push	r16
     496:	1f 93       	push	r17
     498:	2f 93       	push	r18
     49a:	3f 93       	push	r19
     49c:	4f 93       	push	r20
     49e:	5f 93       	push	r21
     4a0:	6f 93       	push	r22
     4a2:	7f 93       	push	r23
     4a4:	8f 93       	push	r24
     4a6:	9f 93       	push	r25
     4a8:	af 93       	push	r26
     4aa:	bf 93       	push	r27
     4ac:	cf 93       	push	r28
     4ae:	df 93       	push	r29
     4b0:	ef 93       	push	r30
     4b2:	ff 93       	push	r31
     4b4:	a0 91 f6 04 	lds	r26, 0x04F6
     4b8:	b0 91 f7 04 	lds	r27, 0x04F7
     4bc:	0d b6       	in	r0, 0x3d	; 61
     4be:	0d 92       	st	X+, r0
     4c0:	0e b6       	in	r0, 0x3e	; 62
     4c2:	0d 92       	st	X+, r0
	vTaskSwitchContext();
     4c4:	0e 94 41 0a 	call	0x1482	; 0x1482 <vTaskSwitchContext>
	portRESTORE_CONTEXT();
     4c8:	a0 91 f6 04 	lds	r26, 0x04F6
     4cc:	b0 91 f7 04 	lds	r27, 0x04F7
     4d0:	cd 91       	ld	r28, X+
     4d2:	cd bf       	out	0x3d, r28	; 61
     4d4:	dd 91       	ld	r29, X+
     4d6:	de bf       	out	0x3e, r29	; 62
     4d8:	ff 91       	pop	r31
     4da:	ef 91       	pop	r30
     4dc:	df 91       	pop	r29
     4de:	cf 91       	pop	r28
     4e0:	bf 91       	pop	r27
     4e2:	af 91       	pop	r26
     4e4:	9f 91       	pop	r25
     4e6:	8f 91       	pop	r24
     4e8:	7f 91       	pop	r23
     4ea:	6f 91       	pop	r22
     4ec:	5f 91       	pop	r21
     4ee:	4f 91       	pop	r20
     4f0:	3f 91       	pop	r19
     4f2:	2f 91       	pop	r18
     4f4:	1f 91       	pop	r17
     4f6:	0f 91       	pop	r16
     4f8:	ff 90       	pop	r15
     4fa:	ef 90       	pop	r14
     4fc:	df 90       	pop	r13
     4fe:	cf 90       	pop	r12
     500:	bf 90       	pop	r11
     502:	af 90       	pop	r10
     504:	9f 90       	pop	r9
     506:	8f 90       	pop	r8
     508:	7f 90       	pop	r7
     50a:	6f 90       	pop	r6
     50c:	5f 90       	pop	r5
     50e:	4f 90       	pop	r4
     510:	3f 90       	pop	r3
     512:	2f 90       	pop	r2
     514:	1f 90       	pop	r1
     516:	0f 90       	pop	r0
     518:	0f be       	out	0x3f, r0	; 63
     51a:	0f 90       	pop	r0

	asm volatile ( "ret" );
     51c:	08 95       	ret

0000051e <vPortYieldFromTick>:
 * call comes from the tick ISR.
 */
void vPortYieldFromTick( void ) __attribute__ ( ( naked ) );
void vPortYieldFromTick( void )
{
	portSAVE_CONTEXT();
     51e:	0f 92       	push	r0
     520:	0f b6       	in	r0, 0x3f	; 63
     522:	f8 94       	cli
     524:	0f 92       	push	r0
     526:	1f 92       	push	r1
     528:	11 24       	eor	r1, r1
     52a:	2f 92       	push	r2
     52c:	3f 92       	push	r3
     52e:	4f 92       	push	r4
     530:	5f 92       	push	r5
     532:	6f 92       	push	r6
     534:	7f 92       	push	r7
     536:	8f 92       	push	r8
     538:	9f 92       	push	r9
     53a:	af 92       	push	r10
     53c:	bf 92       	push	r11
     53e:	cf 92       	push	r12
     540:	df 92       	push	r13
     542:	ef 92       	push	r14
     544:	ff 92       	push	r15
     546:	0f 93       	push	r16
     548:	1f 93       	push	r17
     54a:	2f 93       	push	r18
     54c:	3f 93       	push	r19
     54e:	4f 93       	push	r20
     550:	5f 93       	push	r21
     552:	6f 93       	push	r22
     554:	7f 93       	push	r23
     556:	8f 93       	push	r24
     558:	9f 93       	push	r25
     55a:	af 93       	push	r26
     55c:	bf 93       	push	r27
     55e:	cf 93       	push	r28
     560:	df 93       	push	r29
     562:	ef 93       	push	r30
     564:	ff 93       	push	r31
     566:	a0 91 f6 04 	lds	r26, 0x04F6
     56a:	b0 91 f7 04 	lds	r27, 0x04F7
     56e:	0d b6       	in	r0, 0x3d	; 61
     570:	0d 92       	st	X+, r0
     572:	0e b6       	in	r0, 0x3e	; 62
     574:	0d 92       	st	X+, r0
	if( xTaskIncrementTick() != pdFALSE )
     576:	0e 94 61 08 	call	0x10c2	; 0x10c2 <xTaskIncrementTick>
     57a:	81 11       	cpse	r24, r1
	{
		vTaskSwitchContext();
     57c:	0e 94 41 0a 	call	0x1482	; 0x1482 <vTaskSwitchContext>
	}
	portRESTORE_CONTEXT();
     580:	a0 91 f6 04 	lds	r26, 0x04F6
     584:	b0 91 f7 04 	lds	r27, 0x04F7
     588:	cd 91       	ld	r28, X+
     58a:	cd bf       	out	0x3d, r28	; 61
     58c:	dd 91       	ld	r29, X+
     58e:	de bf       	out	0x3e, r29	; 62
     590:	ff 91       	pop	r31
     592:	ef 91       	pop	r30
     594:	df 91       	pop	r29
     596:	cf 91       	pop	r28
     598:	bf 91       	pop	r27
     59a:	af 91       	pop	r26
     59c:	9f 91       	pop	r25
     59e:	8f 91       	pop	r24
     5a0:	7f 91       	pop	r23
     5a2:	6f 91       	pop	r22
     5a4:	5f 91       	pop	r21
     5a6:	4f 91       	pop	r20
     5a8:	3f 91       	pop	r19
     5aa:	2f 91       	pop	r18
     5ac:	1f 91       	pop	r17
     5ae:	0f 91       	pop	r16
     5b0:	ff 90       	pop	r15
     5b2:	ef 90       	pop	r14
     5b4:	df 90       	pop	r13
     5b6:	cf 90       	pop	r12
     5b8:	bf 90       	pop	r11
     5ba:	af 90       	pop	r10
     5bc:	9f 90       	pop	r9
     5be:	8f 90       	pop	r8
     5c0:	7f 90       	pop	r7
     5c2:	6f 90       	pop	r6
     5c4:	5f 90       	pop	r5
     5c6:	4f 90       	pop	r4
     5c8:	3f 90       	pop	r3
     5ca:	2f 90       	pop	r2
     5cc:	1f 90       	pop	r1
     5ce:	0f 90       	pop	r0
     5d0:	0f be       	out	0x3f, r0	; 63
     5d2:	0f 90       	pop	r0

	asm volatile ( "ret" );
     5d4:	08 95       	ret

000005d6 <__vector_12>:
	 * count is incremented after the context is saved.
	 */
	void TIMER1_COMPA_vect( void ) __attribute__ ( ( signal, naked ) );
	ISR(TIMER1_COMPA_vect)
	{
		vPortYieldFromTick();
     5d6:	0e 94 8f 02 	call	0x51e	; 0x51e <vPortYieldFromTick>
		asm volatile ( "reti" );
     5da:	18 95       	reti

000005dc <pvPortMalloc>:
static size_t xNextFreeByte = ( size_t ) 0;

/*-----------------------------------------------------------*/

void *pvPortMalloc( size_t xWantedSize )
{
     5dc:	cf 93       	push	r28
     5de:	df 93       	push	r29
     5e0:	ec 01       	movw	r28, r24
			/* Byte alignment required. */
			xWantedSize += ( portBYTE_ALIGNMENT - ( xWantedSize & portBYTE_ALIGNMENT_MASK ) );
		}
	#endif

	vTaskSuspendAll();
     5e2:	0e 94 49 08 	call	0x1092	; 0x1092 <vTaskSuspendAll>
	{
		if( pucAlignedHeap == NULL )
     5e6:	80 91 0a 01 	lds	r24, 0x010A
     5ea:	90 91 0b 01 	lds	r25, 0x010B
     5ee:	89 2b       	or	r24, r25
     5f0:	31 f4       	brne	.+12     	; 0x5fe <pvPortMalloc+0x22>
		{
			/* Ensure the heap starts on a correctly aligned boundary. */
			pucAlignedHeap = ( uint8_t * ) ( ( ( portPOINTER_SIZE_TYPE ) &ucHeap[ portBYTE_ALIGNMENT ] ) & ( ~( ( portPOINTER_SIZE_TYPE ) portBYTE_ALIGNMENT_MASK ) ) );
     5f2:	8f e0       	ldi	r24, 0x0F	; 15
     5f4:	91 e0       	ldi	r25, 0x01	; 1
     5f6:	90 93 0b 01 	sts	0x010B, r25
     5fa:	80 93 0a 01 	sts	0x010A, r24
		}

		/* Check there is enough room left for the allocation. */
		if( ( ( xNextFreeByte + xWantedSize ) < configADJUSTED_HEAP_SIZE ) &&
     5fe:	40 91 0c 01 	lds	r20, 0x010C
     602:	50 91 0d 01 	lds	r21, 0x010D
     606:	9e 01       	movw	r18, r28
     608:	24 0f       	add	r18, r20
     60a:	35 1f       	adc	r19, r21
     60c:	27 3e       	cpi	r18, 0xE7	; 231
     60e:	83 e0       	ldi	r24, 0x03	; 3
     610:	38 07       	cpc	r19, r24
     612:	70 f4       	brcc	.+28     	; 0x630 <pvPortMalloc+0x54>
     614:	42 17       	cp	r20, r18
     616:	53 07       	cpc	r21, r19
     618:	70 f4       	brcc	.+28     	; 0x636 <pvPortMalloc+0x5a>
			( ( xNextFreeByte + xWantedSize ) > xNextFreeByte )	)/* Check for overflow. */
		{
			/* Return the next free byte then increment the index past this
			block. */
			pvReturn = pucAlignedHeap + xNextFreeByte;
     61a:	c0 91 0a 01 	lds	r28, 0x010A
     61e:	d0 91 0b 01 	lds	r29, 0x010B
     622:	c4 0f       	add	r28, r20
     624:	d5 1f       	adc	r29, r21
			xNextFreeByte += xWantedSize;
     626:	30 93 0d 01 	sts	0x010D, r19
     62a:	20 93 0c 01 	sts	0x010C, r18
     62e:	05 c0       	rjmp	.+10     	; 0x63a <pvPortMalloc+0x5e>

/*-----------------------------------------------------------*/

void *pvPortMalloc( size_t xWantedSize )
{
void *pvReturn = NULL;
     630:	c0 e0       	ldi	r28, 0x00	; 0
     632:	d0 e0       	ldi	r29, 0x00	; 0
     634:	02 c0       	rjmp	.+4      	; 0x63a <pvPortMalloc+0x5e>
     636:	c0 e0       	ldi	r28, 0x00	; 0
     638:	d0 e0       	ldi	r29, 0x00	; 0
			xNextFreeByte += xWantedSize;
		}

		traceMALLOC( pvReturn, xWantedSize );
	}
	( void ) xTaskResumeAll();
     63a:	0e 94 20 09 	call	0x1240	; 0x1240 <xTaskResumeAll>
		}
	}
	#endif

	return pvReturn;
}
     63e:	ce 01       	movw	r24, r28
     640:	df 91       	pop	r29
     642:	cf 91       	pop	r28
     644:	08 95       	ret

00000646 <vPortFree>:
/*-----------------------------------------------------------*/

void vPortFree( void *pv )
{
     646:	08 95       	ret

00000648 <vPortInitialiseBlocks>:
/*-----------------------------------------------------------*/

void vPortInitialiseBlocks( void )
{
	/* Only required when static memory is not cleared. */
	xNextFreeByte = ( size_t ) 0;
     648:	10 92 0d 01 	sts	0x010D, r1
     64c:	10 92 0c 01 	sts	0x010C, r1
     650:	08 95       	ret

00000652 <xPortGetFreeHeapSize>:
}
/*-----------------------------------------------------------*/

size_t xPortGetFreeHeapSize( void )
{
	return ( configADJUSTED_HEAP_SIZE - xNextFreeByte );
     652:	20 91 0c 01 	lds	r18, 0x010C
     656:	30 91 0d 01 	lds	r19, 0x010D
}
     65a:	87 ee       	ldi	r24, 0xE7	; 231
     65c:	93 e0       	ldi	r25, 0x03	; 3
     65e:	82 1b       	sub	r24, r18
     660:	93 0b       	sbc	r25, r19
     662:	08 95       	ret

00000664 <prvCopyDataToQueue>:

#endif /* configUSE_TRACE_FACILITY */
/*-----------------------------------------------------------*/

static BaseType_t prvCopyDataToQueue( Queue_t * const pxQueue, const void *pvItemToQueue, const BaseType_t xPosition )
{
     664:	1f 93       	push	r17
     666:	cf 93       	push	r28
     668:	df 93       	push	r29
     66a:	ec 01       	movw	r28, r24
     66c:	14 2f       	mov	r17, r20
BaseType_t xReturn = pdFALSE;

	if( pxQueue->uxItemSize == ( UBaseType_t ) 0 )
     66e:	8c 8d       	ldd	r24, Y+28	; 0x1c
     670:	88 23       	and	r24, r24
     672:	e9 f1       	breq	.+122    	; 0x6ee <prvCopyDataToQueue+0x8a>
				mtCOVERAGE_TEST_MARKER();
			}
		}
		#endif /* configUSE_MUTEXES */
	}
	else if( xPosition == queueSEND_TO_BACK )
     674:	41 11       	cpse	r20, r1
     676:	17 c0       	rjmp	.+46     	; 0x6a6 <prvCopyDataToQueue+0x42>
	{
		( void ) memcpy( ( void * ) pxQueue->pcWriteTo, pvItemToQueue, ( size_t ) pxQueue->uxItemSize ); /*lint !e961 !e418 MISRA exception as the casts are only redundant for some ports, plus previous logic ensures a null pointer can only be passed to memcpy() if the copy size is 0. */
     678:	48 2f       	mov	r20, r24
     67a:	50 e0       	ldi	r21, 0x00	; 0
     67c:	8c 81       	ldd	r24, Y+4	; 0x04
     67e:	9d 81       	ldd	r25, Y+5	; 0x05
     680:	0e 94 35 0e 	call	0x1c6a	; 0x1c6a <memcpy>
		pxQueue->pcWriteTo += pxQueue->uxItemSize;
     684:	2c 8d       	ldd	r18, Y+28	; 0x1c
     686:	8c 81       	ldd	r24, Y+4	; 0x04
     688:	9d 81       	ldd	r25, Y+5	; 0x05
     68a:	82 0f       	add	r24, r18
     68c:	91 1d       	adc	r25, r1
     68e:	9d 83       	std	Y+5, r25	; 0x05
     690:	8c 83       	std	Y+4, r24	; 0x04
		if( pxQueue->pcWriteTo >= pxQueue->pcTail ) /*lint !e946 MISRA exception justified as comparison of pointers is the cleanest solution. */
     692:	2a 81       	ldd	r18, Y+2	; 0x02
     694:	3b 81       	ldd	r19, Y+3	; 0x03
     696:	82 17       	cp	r24, r18
     698:	93 07       	cpc	r25, r19
     69a:	48 f1       	brcs	.+82     	; 0x6ee <prvCopyDataToQueue+0x8a>
		{
			pxQueue->pcWriteTo = pxQueue->pcHead;
     69c:	88 81       	ld	r24, Y
     69e:	99 81       	ldd	r25, Y+1	; 0x01
     6a0:	9d 83       	std	Y+5, r25	; 0x05
     6a2:	8c 83       	std	Y+4, r24	; 0x04
     6a4:	24 c0       	rjmp	.+72     	; 0x6ee <prvCopyDataToQueue+0x8a>
			mtCOVERAGE_TEST_MARKER();
		}
	}
	else
	{
		( void ) memcpy( ( void * ) pxQueue->u.pcReadFrom, pvItemToQueue, ( size_t ) pxQueue->uxItemSize ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
     6a6:	48 2f       	mov	r20, r24
     6a8:	50 e0       	ldi	r21, 0x00	; 0
     6aa:	8e 81       	ldd	r24, Y+6	; 0x06
     6ac:	9f 81       	ldd	r25, Y+7	; 0x07
     6ae:	0e 94 35 0e 	call	0x1c6a	; 0x1c6a <memcpy>
		pxQueue->u.pcReadFrom -= pxQueue->uxItemSize;
     6b2:	2c 8d       	ldd	r18, Y+28	; 0x1c
     6b4:	30 e0       	ldi	r19, 0x00	; 0
     6b6:	31 95       	neg	r19
     6b8:	21 95       	neg	r18
     6ba:	31 09       	sbc	r19, r1
     6bc:	8e 81       	ldd	r24, Y+6	; 0x06
     6be:	9f 81       	ldd	r25, Y+7	; 0x07
     6c0:	82 0f       	add	r24, r18
     6c2:	93 1f       	adc	r25, r19
     6c4:	9f 83       	std	Y+7, r25	; 0x07
     6c6:	8e 83       	std	Y+6, r24	; 0x06
		if( pxQueue->u.pcReadFrom < pxQueue->pcHead ) /*lint !e946 MISRA exception justified as comparison of pointers is the cleanest solution. */
     6c8:	68 81       	ld	r22, Y
     6ca:	79 81       	ldd	r23, Y+1	; 0x01
     6cc:	86 17       	cp	r24, r22
     6ce:	97 07       	cpc	r25, r23
     6d0:	30 f4       	brcc	.+12     	; 0x6de <prvCopyDataToQueue+0x7a>
		{
			pxQueue->u.pcReadFrom = ( pxQueue->pcTail - pxQueue->uxItemSize );
     6d2:	8a 81       	ldd	r24, Y+2	; 0x02
     6d4:	9b 81       	ldd	r25, Y+3	; 0x03
     6d6:	28 0f       	add	r18, r24
     6d8:	39 1f       	adc	r19, r25
     6da:	3f 83       	std	Y+7, r19	; 0x07
     6dc:	2e 83       	std	Y+6, r18	; 0x06
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}

		if( xPosition == queueOVERWRITE )
     6de:	12 30       	cpi	r17, 0x02	; 2
     6e0:	31 f4       	brne	.+12     	; 0x6ee <prvCopyDataToQueue+0x8a>
		{
			if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )
     6e2:	8a 8d       	ldd	r24, Y+26	; 0x1a
     6e4:	88 23       	and	r24, r24
     6e6:	19 f0       	breq	.+6      	; 0x6ee <prvCopyDataToQueue+0x8a>
			{
				/* An item is not being added but overwritten, so subtract
				one from the recorded number of items in the queue so when
				one is added again below the number of recorded items remains
				correct. */
				--( pxQueue->uxMessagesWaiting );
     6e8:	8a 8d       	ldd	r24, Y+26	; 0x1a
     6ea:	81 50       	subi	r24, 0x01	; 1
     6ec:	8a 8f       	std	Y+26, r24	; 0x1a
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}

	++( pxQueue->uxMessagesWaiting );
     6ee:	8a 8d       	ldd	r24, Y+26	; 0x1a
     6f0:	8f 5f       	subi	r24, 0xFF	; 255
     6f2:	8a 8f       	std	Y+26, r24	; 0x1a

	return xReturn;
}
     6f4:	80 e0       	ldi	r24, 0x00	; 0
     6f6:	df 91       	pop	r29
     6f8:	cf 91       	pop	r28
     6fa:	1f 91       	pop	r17
     6fc:	08 95       	ret

000006fe <prvCopyDataFromQueue>:
/*-----------------------------------------------------------*/

static void prvCopyDataFromQueue( Queue_t * const pxQueue, void * const pvBuffer )
{
     6fe:	fc 01       	movw	r30, r24
     700:	cb 01       	movw	r24, r22
	if( pxQueue->uxItemSize != ( UBaseType_t ) 0 )
     702:	44 8d       	ldd	r20, Z+28	; 0x1c
     704:	44 23       	and	r20, r20
     706:	a1 f0       	breq	.+40     	; 0x730 <prvCopyDataFromQueue+0x32>
	{
		pxQueue->u.pcReadFrom += pxQueue->uxItemSize;
     708:	50 e0       	ldi	r21, 0x00	; 0
     70a:	26 81       	ldd	r18, Z+6	; 0x06
     70c:	37 81       	ldd	r19, Z+7	; 0x07
     70e:	24 0f       	add	r18, r20
     710:	35 1f       	adc	r19, r21
     712:	37 83       	std	Z+7, r19	; 0x07
     714:	26 83       	std	Z+6, r18	; 0x06
		if( pxQueue->u.pcReadFrom >= pxQueue->pcTail ) /*lint !e946 MISRA exception justified as use of the relational operator is the cleanest solutions. */
     716:	62 81       	ldd	r22, Z+2	; 0x02
     718:	73 81       	ldd	r23, Z+3	; 0x03
     71a:	26 17       	cp	r18, r22
     71c:	37 07       	cpc	r19, r23
     71e:	20 f0       	brcs	.+8      	; 0x728 <prvCopyDataFromQueue+0x2a>
		{
			pxQueue->u.pcReadFrom = pxQueue->pcHead;
     720:	20 81       	ld	r18, Z
     722:	31 81       	ldd	r19, Z+1	; 0x01
     724:	37 83       	std	Z+7, r19	; 0x07
     726:	26 83       	std	Z+6, r18	; 0x06
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
		( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.pcReadFrom, ( size_t ) pxQueue->uxItemSize ); /*lint !e961 !e418 MISRA exception as the casts are only redundant for some ports.  Also previous logic ensures a null pointer can only be passed to memcpy() when the count is 0. */
     728:	66 81       	ldd	r22, Z+6	; 0x06
     72a:	77 81       	ldd	r23, Z+7	; 0x07
     72c:	0e 94 35 0e 	call	0x1c6a	; 0x1c6a <memcpy>
     730:	08 95       	ret

00000732 <prvUnlockQueue>:
	}
}
/*-----------------------------------------------------------*/

static void prvUnlockQueue( Queue_t * const pxQueue )
{
     732:	0f 93       	push	r16
     734:	1f 93       	push	r17
     736:	cf 93       	push	r28
     738:	df 93       	push	r29
     73a:	ec 01       	movw	r28, r24

	/* The lock counts contains the number of extra data items placed or
	removed from the queue while the queue was locked.  When a queue is
	locked items can be added or removed, but the event lists cannot be
	updated. */
	taskENTER_CRITICAL();
     73c:	0f b6       	in	r0, 0x3f	; 63
     73e:	f8 94       	cli
     740:	0f 92       	push	r0
	{
		/* See if data was added to the queue while it was locked. */
		while( pxQueue->xTxLock > queueLOCKED_UNMODIFIED )
     742:	8e 8d       	ldd	r24, Y+30	; 0x1e
     744:	18 16       	cp	r1, r24
     746:	b4 f4       	brge	.+44     	; 0x774 <prvUnlockQueue+0x42>
			}
			#else /* configUSE_QUEUE_SETS */
			{
				/* Tasks that are removed from the event list will get added to
				the pending ready list as the scheduler is still suspended. */
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
     748:	89 89       	ldd	r24, Y+17	; 0x11
     74a:	88 23       	and	r24, r24
     74c:	99 f0       	breq	.+38     	; 0x774 <prvUnlockQueue+0x42>
				{
					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
     74e:	8e 01       	movw	r16, r28
     750:	0f 5e       	subi	r16, 0xEF	; 239
     752:	1f 4f       	sbci	r17, 0xFF	; 255
     754:	03 c0       	rjmp	.+6      	; 0x75c <prvUnlockQueue+0x2a>
			}
			#else /* configUSE_QUEUE_SETS */
			{
				/* Tasks that are removed from the event list will get added to
				the pending ready list as the scheduler is still suspended. */
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
     756:	89 89       	ldd	r24, Y+17	; 0x11
     758:	88 23       	and	r24, r24
     75a:	61 f0       	breq	.+24     	; 0x774 <prvUnlockQueue+0x42>
				{
					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
     75c:	c8 01       	movw	r24, r16
     75e:	0e 94 e0 0a 	call	0x15c0	; 0x15c0 <xTaskRemoveFromEventList>
     762:	81 11       	cpse	r24, r1
					{
						/* The task waiting has a higher priority so record that a
						context	switch is required. */
						vTaskMissedYield();
     764:	0e 94 a0 0b 	call	0x1740	; 0x1740 <vTaskMissedYield>
					break;
				}
			}
			#endif /* configUSE_QUEUE_SETS */

			--( pxQueue->xTxLock );
     768:	8e 8d       	ldd	r24, Y+30	; 0x1e
     76a:	81 50       	subi	r24, 0x01	; 1
     76c:	8e 8f       	std	Y+30, r24	; 0x1e
	locked items can be added or removed, but the event lists cannot be
	updated. */
	taskENTER_CRITICAL();
	{
		/* See if data was added to the queue while it was locked. */
		while( pxQueue->xTxLock > queueLOCKED_UNMODIFIED )
     76e:	8e 8d       	ldd	r24, Y+30	; 0x1e
     770:	18 16       	cp	r1, r24
     772:	8c f3       	brlt	.-30     	; 0x756 <prvUnlockQueue+0x24>
			#endif /* configUSE_QUEUE_SETS */

			--( pxQueue->xTxLock );
		}

		pxQueue->xTxLock = queueUNLOCKED;
     774:	8f ef       	ldi	r24, 0xFF	; 255
     776:	8e 8f       	std	Y+30, r24	; 0x1e
	}
	taskEXIT_CRITICAL();
     778:	0f 90       	pop	r0
     77a:	0f be       	out	0x3f, r0	; 63

	/* Do the same for the Rx lock. */
	taskENTER_CRITICAL();
     77c:	0f b6       	in	r0, 0x3f	; 63
     77e:	f8 94       	cli
     780:	0f 92       	push	r0
	{
		while( pxQueue->xRxLock > queueLOCKED_UNMODIFIED )
     782:	8d 8d       	ldd	r24, Y+29	; 0x1d
     784:	18 16       	cp	r1, r24
     786:	b4 f4       	brge	.+44     	; 0x7b4 <prvUnlockQueue+0x82>
		{
			if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
     788:	88 85       	ldd	r24, Y+8	; 0x08
     78a:	88 23       	and	r24, r24
     78c:	99 f0       	breq	.+38     	; 0x7b4 <prvUnlockQueue+0x82>
			{
				if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
     78e:	8e 01       	movw	r16, r28
     790:	08 5f       	subi	r16, 0xF8	; 248
     792:	1f 4f       	sbci	r17, 0xFF	; 255
     794:	03 c0       	rjmp	.+6      	; 0x79c <prvUnlockQueue+0x6a>
	/* Do the same for the Rx lock. */
	taskENTER_CRITICAL();
	{
		while( pxQueue->xRxLock > queueLOCKED_UNMODIFIED )
		{
			if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
     796:	88 85       	ldd	r24, Y+8	; 0x08
     798:	88 23       	and	r24, r24
     79a:	61 f0       	breq	.+24     	; 0x7b4 <prvUnlockQueue+0x82>
			{
				if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
     79c:	c8 01       	movw	r24, r16
     79e:	0e 94 e0 0a 	call	0x15c0	; 0x15c0 <xTaskRemoveFromEventList>
     7a2:	81 11       	cpse	r24, r1
				{
					vTaskMissedYield();
     7a4:	0e 94 a0 0b 	call	0x1740	; 0x1740 <vTaskMissedYield>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}

				--( pxQueue->xRxLock );
     7a8:	8d 8d       	ldd	r24, Y+29	; 0x1d
     7aa:	81 50       	subi	r24, 0x01	; 1
     7ac:	8d 8f       	std	Y+29, r24	; 0x1d
	taskEXIT_CRITICAL();

	/* Do the same for the Rx lock. */
	taskENTER_CRITICAL();
	{
		while( pxQueue->xRxLock > queueLOCKED_UNMODIFIED )
     7ae:	8d 8d       	ldd	r24, Y+29	; 0x1d
     7b0:	18 16       	cp	r1, r24
     7b2:	8c f3       	brlt	.-30     	; 0x796 <prvUnlockQueue+0x64>
			{
				break;
			}
		}

		pxQueue->xRxLock = queueUNLOCKED;
     7b4:	8f ef       	ldi	r24, 0xFF	; 255
     7b6:	8d 8f       	std	Y+29, r24	; 0x1d
	}
	taskEXIT_CRITICAL();
     7b8:	0f 90       	pop	r0
     7ba:	0f be       	out	0x3f, r0	; 63
}
     7bc:	df 91       	pop	r29
     7be:	cf 91       	pop	r28
     7c0:	1f 91       	pop	r17
     7c2:	0f 91       	pop	r16
     7c4:	08 95       	ret

000007c6 <xQueueGenericReset>:
	}														\
	taskEXIT_CRITICAL()
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericReset( QueueHandle_t xQueue, BaseType_t xNewQueue )
{
     7c6:	cf 93       	push	r28
     7c8:	df 93       	push	r29
     7ca:	ec 01       	movw	r28, r24
Queue_t * const pxQueue = ( Queue_t * ) xQueue;

	configASSERT( pxQueue );

	taskENTER_CRITICAL();
     7cc:	0f b6       	in	r0, 0x3f	; 63
     7ce:	f8 94       	cli
     7d0:	0f 92       	push	r0
	{
		pxQueue->pcTail = pxQueue->pcHead + ( pxQueue->uxLength * pxQueue->uxItemSize );
     7d2:	88 81       	ld	r24, Y
     7d4:	99 81       	ldd	r25, Y+1	; 0x01
     7d6:	2c 8d       	ldd	r18, Y+28	; 0x1c
     7d8:	30 e0       	ldi	r19, 0x00	; 0
     7da:	7b 8d       	ldd	r23, Y+27	; 0x1b
     7dc:	72 9f       	mul	r23, r18
     7de:	a0 01       	movw	r20, r0
     7e0:	73 9f       	mul	r23, r19
     7e2:	50 0d       	add	r21, r0
     7e4:	11 24       	eor	r1, r1
     7e6:	fc 01       	movw	r30, r24
     7e8:	e4 0f       	add	r30, r20
     7ea:	f5 1f       	adc	r31, r21
     7ec:	fb 83       	std	Y+3, r31	; 0x03
     7ee:	ea 83       	std	Y+2, r30	; 0x02
		pxQueue->uxMessagesWaiting = ( UBaseType_t ) 0U;
     7f0:	1a 8e       	std	Y+26, r1	; 0x1a
		pxQueue->pcWriteTo = pxQueue->pcHead;
     7f2:	9d 83       	std	Y+5, r25	; 0x05
     7f4:	8c 83       	std	Y+4, r24	; 0x04
		pxQueue->u.pcReadFrom = pxQueue->pcHead + ( ( pxQueue->uxLength - ( UBaseType_t ) 1U ) * pxQueue->uxItemSize );
     7f6:	42 1b       	sub	r20, r18
     7f8:	53 0b       	sbc	r21, r19
     7fa:	84 0f       	add	r24, r20
     7fc:	95 1f       	adc	r25, r21
     7fe:	9f 83       	std	Y+7, r25	; 0x07
     800:	8e 83       	std	Y+6, r24	; 0x06
		pxQueue->xRxLock = queueUNLOCKED;
     802:	8f ef       	ldi	r24, 0xFF	; 255
     804:	8d 8f       	std	Y+29, r24	; 0x1d
		pxQueue->xTxLock = queueUNLOCKED;
     806:	8e 8f       	std	Y+30, r24	; 0x1e

		if( xNewQueue == pdFALSE )
     808:	61 11       	cpse	r22, r1
     80a:	0c c0       	rjmp	.+24     	; 0x824 <xQueueGenericReset+0x5e>
			/* If there are tasks blocked waiting to read from the queue, then
			the tasks will remain blocked as after this function exits the queue
			will still be empty.  If there are tasks blocked waiting to write to
			the queue, then one should be unblocked as after this function exits
			it will be possible to write to it. */
			if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
     80c:	88 85       	ldd	r24, Y+8	; 0x08
     80e:	88 23       	and	r24, r24
     810:	89 f0       	breq	.+34     	; 0x834 <xQueueGenericReset+0x6e>
			{
				if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) == pdTRUE )
     812:	ce 01       	movw	r24, r28
     814:	08 96       	adiw	r24, 0x08	; 8
     816:	0e 94 e0 0a 	call	0x15c0	; 0x15c0 <xTaskRemoveFromEventList>
     81a:	81 30       	cpi	r24, 0x01	; 1
     81c:	59 f4       	brne	.+22     	; 0x834 <xQueueGenericReset+0x6e>
				{
					queueYIELD_IF_USING_PREEMPTION();
     81e:	0e 94 36 02 	call	0x46c	; 0x46c <vPortYield>
     822:	08 c0       	rjmp	.+16     	; 0x834 <xQueueGenericReset+0x6e>
			}
		}
		else
		{
			/* Ensure the event queues start in the correct state. */
			vListInitialise( &( pxQueue->xTasksWaitingToSend ) );
     824:	ce 01       	movw	r24, r28
     826:	08 96       	adiw	r24, 0x08	; 8
     828:	0e 94 01 01 	call	0x202	; 0x202 <vListInitialise>
			vListInitialise( &( pxQueue->xTasksWaitingToReceive ) );
     82c:	ce 01       	movw	r24, r28
     82e:	41 96       	adiw	r24, 0x11	; 17
     830:	0e 94 01 01 	call	0x202	; 0x202 <vListInitialise>
		}
	}
	taskEXIT_CRITICAL();
     834:	0f 90       	pop	r0
     836:	0f be       	out	0x3f, r0	; 63

	/* A value is returned for calling semantic consistency with previous
	versions. */
	return pdPASS;
}
     838:	81 e0       	ldi	r24, 0x01	; 1
     83a:	df 91       	pop	r29
     83c:	cf 91       	pop	r28
     83e:	08 95       	ret

00000840 <xQueueGenericCreate>:
/*-----------------------------------------------------------*/

QueueHandle_t xQueueGenericCreate( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, const uint8_t ucQueueType )
{
     840:	0f 93       	push	r16
     842:	1f 93       	push	r17
     844:	cf 93       	push	r28
     846:	df 93       	push	r29
     848:	08 2f       	mov	r16, r24
     84a:	16 2f       	mov	r17, r22
	configUSE_TRACE_FACILITY not be set to 1. */
	( void ) ucQueueType;

	configASSERT( uxQueueLength > ( UBaseType_t ) 0 );

	if( uxItemSize == ( UBaseType_t ) 0 )
     84c:	66 23       	and	r22, r22
     84e:	c9 f0       	breq	.+50     	; 0x882 <xQueueGenericCreate+0x42>
	}
	else
	{
		/* The queue is one byte longer than asked for to make wrap checking
		easier/faster. */
		xQueueSizeInBytes = ( size_t ) ( uxQueueLength * uxItemSize ) + ( size_t ) 1; /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
     850:	86 9f       	mul	r24, r22
     852:	c0 01       	movw	r24, r0
     854:	11 24       	eor	r1, r1
	}

	/* Allocate the new queue structure and storage area. */
	pxNewQueue = ( Queue_t * ) pvPortMalloc( sizeof( Queue_t ) + xQueueSizeInBytes );
     856:	80 96       	adiw	r24, 0x20	; 32
     858:	0e 94 ee 02 	call	0x5dc	; 0x5dc <pvPortMalloc>
     85c:	ec 01       	movw	r28, r24

	if( pxNewQueue != NULL )
     85e:	00 97       	sbiw	r24, 0x00	; 0
     860:	21 f4       	brne	.+8      	; 0x86a <xQueueGenericCreate+0x2a>
     862:	16 c0       	rjmp	.+44     	; 0x890 <xQueueGenericCreate+0x50>
		{
			/* No RAM was allocated for the queue storage area, but PC head
			cannot be set to NULL because NULL is used as a key to say the queue
			is used as a mutex.  Therefore just set pcHead to point to the queue
			as a benign value that is known to be within the memory map. */
			pxNewQueue->pcHead = ( int8_t * ) pxNewQueue;
     864:	d9 83       	std	Y+1, r29	; 0x01
     866:	c8 83       	st	Y, r28
     868:	05 c0       	rjmp	.+10     	; 0x874 <xQueueGenericCreate+0x34>
		}
		else
		{
			/* Jump past the queue structure to find the location of the queue
			storage area. */
			pxNewQueue->pcHead = ( ( int8_t * ) pxNewQueue ) + sizeof( Queue_t );
     86a:	9c 01       	movw	r18, r24
     86c:	21 5e       	subi	r18, 0xE1	; 225
     86e:	3f 4f       	sbci	r19, 0xFF	; 255
     870:	39 83       	std	Y+1, r19	; 0x01
     872:	28 83       	st	Y, r18
		}

		/* Initialise the queue members as described above where the queue type
		is defined. */
		pxNewQueue->uxLength = uxQueueLength;
     874:	0b 8f       	std	Y+27, r16	; 0x1b
		pxNewQueue->uxItemSize = uxItemSize;
     876:	1c 8f       	std	Y+28, r17	; 0x1c
		( void ) xQueueGenericReset( pxNewQueue, pdTRUE );
     878:	61 e0       	ldi	r22, 0x01	; 1
     87a:	ce 01       	movw	r24, r28
     87c:	0e 94 e3 03 	call	0x7c6	; 0x7c6 <xQueueGenericReset>
     880:	07 c0       	rjmp	.+14     	; 0x890 <xQueueGenericCreate+0x50>
		easier/faster. */
		xQueueSizeInBytes = ( size_t ) ( uxQueueLength * uxItemSize ) + ( size_t ) 1; /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
	}

	/* Allocate the new queue structure and storage area. */
	pxNewQueue = ( Queue_t * ) pvPortMalloc( sizeof( Queue_t ) + xQueueSizeInBytes );
     882:	8f e1       	ldi	r24, 0x1F	; 31
     884:	90 e0       	ldi	r25, 0x00	; 0
     886:	0e 94 ee 02 	call	0x5dc	; 0x5dc <pvPortMalloc>
     88a:	ec 01       	movw	r28, r24

	if( pxNewQueue != NULL )
     88c:	00 97       	sbiw	r24, 0x00	; 0
     88e:	51 f7       	brne	.-44     	; 0x864 <xQueueGenericCreate+0x24>
	}

	configASSERT( xReturn );

	return xReturn;
}
     890:	ce 01       	movw	r24, r28
     892:	df 91       	pop	r29
     894:	cf 91       	pop	r28
     896:	1f 91       	pop	r17
     898:	0f 91       	pop	r16
     89a:	08 95       	ret

0000089c <xQueueGenericSend>:

#endif /* configUSE_COUNTING_SEMAPHORES */
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericSend( QueueHandle_t xQueue, const void * const pvItemToQueue, TickType_t xTicksToWait, const BaseType_t xCopyPosition )
{
     89c:	9f 92       	push	r9
     89e:	af 92       	push	r10
     8a0:	bf 92       	push	r11
     8a2:	cf 92       	push	r12
     8a4:	df 92       	push	r13
     8a6:	ef 92       	push	r14
     8a8:	ff 92       	push	r15
     8aa:	0f 93       	push	r16
     8ac:	1f 93       	push	r17
     8ae:	cf 93       	push	r28
     8b0:	df 93       	push	r29
     8b2:	00 d0       	rcall	.+0      	; 0x8b4 <xQueueGenericSend+0x18>
     8b4:	00 d0       	rcall	.+0      	; 0x8b6 <xQueueGenericSend+0x1a>
     8b6:	1f 92       	push	r1
     8b8:	cd b7       	in	r28, 0x3d	; 61
     8ba:	de b7       	in	r29, 0x3e	; 62
     8bc:	8c 01       	movw	r16, r24
     8be:	6b 01       	movw	r12, r22
     8c0:	5d 83       	std	Y+5, r21	; 0x05
     8c2:	4c 83       	std	Y+4, r20	; 0x04
     8c4:	a2 2e       	mov	r10, r18
BaseType_t xEntryTimeSet = pdFALSE, xYieldRequired;
     8c6:	b1 2c       	mov	r11, r1
				else if( xEntryTimeSet == pdFALSE )
				{
					/* The queue was full and a block time was specified so
					configure the timeout structure. */
					vTaskSetTimeOutState( &xTimeOut );
					xEntryTimeSet = pdTRUE;
     8c8:	99 24       	eor	r9, r9
     8ca:	93 94       	inc	r9
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
		{
			if( prvIsQueueFull( pxQueue ) != pdFALSE )
			{
				traceBLOCKING_ON_QUEUE_SEND( pxQueue );
				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToSend ), xTicksToWait );
     8cc:	7c 01       	movw	r14, r24
     8ce:	88 e0       	ldi	r24, 0x08	; 8
     8d0:	e8 0e       	add	r14, r24
     8d2:	f1 1c       	adc	r15, r1
	/* This function relaxes the coding standard somewhat to allow return
	statements within the function itself.  This is done in the interest
	of execution time efficiency. */
	for( ;; )
	{
		taskENTER_CRITICAL();
     8d4:	0f b6       	in	r0, 0x3f	; 63
     8d6:	f8 94       	cli
     8d8:	0f 92       	push	r0
		{
			/* Is there room on the queue now?  The running task must be the
			highest priority task wanting to access the queue.  If the head item
			in the queue is to be overwritten then it does not matter if the
			queue is full. */
			if( ( pxQueue->uxMessagesWaiting < pxQueue->uxLength ) || ( xCopyPosition == queueOVERWRITE ) )
     8da:	f8 01       	movw	r30, r16
     8dc:	92 8d       	ldd	r25, Z+26	; 0x1a
     8de:	83 8d       	ldd	r24, Z+27	; 0x1b
     8e0:	98 17       	cp	r25, r24
     8e2:	18 f0       	brcs	.+6      	; 0x8ea <xQueueGenericSend+0x4e>
     8e4:	f2 e0       	ldi	r31, 0x02	; 2
     8e6:	af 12       	cpse	r10, r31
     8e8:	19 c0       	rjmp	.+50     	; 0x91c <xQueueGenericSend+0x80>
			{
				traceQUEUE_SEND( pxQueue );
				xYieldRequired = prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );
     8ea:	4a 2d       	mov	r20, r10
     8ec:	b6 01       	movw	r22, r12
     8ee:	c8 01       	movw	r24, r16
     8f0:	0e 94 32 03 	call	0x664	; 0x664 <prvCopyDataToQueue>
				}
				#else /* configUSE_QUEUE_SETS */
				{
					/* If there was a task waiting for data to arrive on the
					queue then unblock it now. */
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
     8f4:	f8 01       	movw	r30, r16
     8f6:	91 89       	ldd	r25, Z+17	; 0x11
     8f8:	99 23       	and	r25, r25
     8fa:	49 f0       	breq	.+18     	; 0x90e <xQueueGenericSend+0x72>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) == pdTRUE )
     8fc:	c8 01       	movw	r24, r16
     8fe:	41 96       	adiw	r24, 0x11	; 17
     900:	0e 94 e0 0a 	call	0x15c0	; 0x15c0 <xTaskRemoveFromEventList>
     904:	81 30       	cpi	r24, 0x01	; 1
     906:	31 f4       	brne	.+12     	; 0x914 <xQueueGenericSend+0x78>
						{
							/* The unblocked task has a priority higher than
							our own so yield immediately.  Yes it is ok to do
							this from within the critical section - the kernel
							takes care of that. */
							queueYIELD_IF_USING_PREEMPTION();
     908:	0e 94 36 02 	call	0x46c	; 0x46c <vPortYield>
     90c:	03 c0       	rjmp	.+6      	; 0x914 <xQueueGenericSend+0x78>
						else
						{
							mtCOVERAGE_TEST_MARKER();
						}
					}
					else if( xYieldRequired != pdFALSE )
     90e:	81 11       	cpse	r24, r1
					{
						/* This path is a special case that will only get
						executed if the task was holding multiple mutexes and
						the mutexes were given back in an order that is
						different to that in which they were taken. */
						queueYIELD_IF_USING_PREEMPTION();
     910:	0e 94 36 02 	call	0x46c	; 0x46c <vPortYield>
						mtCOVERAGE_TEST_MARKER();
					}
				}
				#endif /* configUSE_QUEUE_SETS */

				taskEXIT_CRITICAL();
     914:	0f 90       	pop	r0
     916:	0f be       	out	0x3f, r0	; 63
				return pdPASS;
     918:	81 e0       	ldi	r24, 0x01	; 1
     91a:	51 c0       	rjmp	.+162    	; 0x9be <xQueueGenericSend+0x122>
			}
			else
			{
				if( xTicksToWait == ( TickType_t ) 0 )
     91c:	ec 81       	ldd	r30, Y+4	; 0x04
     91e:	fd 81       	ldd	r31, Y+5	; 0x05
     920:	ef 2b       	or	r30, r31
     922:	21 f4       	brne	.+8      	; 0x92c <xQueueGenericSend+0x90>
				{
					/* The queue was full and no block time is specified (or
					the block time has expired) so leave now. */
					taskEXIT_CRITICAL();
     924:	0f 90       	pop	r0
     926:	0f be       	out	0x3f, r0	; 63

					/* Return to the original privilege level before exiting
					the function. */
					traceQUEUE_SEND_FAILED( pxQueue );
					return errQUEUE_FULL;
     928:	80 e0       	ldi	r24, 0x00	; 0
     92a:	49 c0       	rjmp	.+146    	; 0x9be <xQueueGenericSend+0x122>
				}
				else if( xEntryTimeSet == pdFALSE )
     92c:	b1 10       	cpse	r11, r1
     92e:	05 c0       	rjmp	.+10     	; 0x93a <xQueueGenericSend+0x9e>
				{
					/* The queue was full and a block time was specified so
					configure the timeout structure. */
					vTaskSetTimeOutState( &xTimeOut );
     930:	ce 01       	movw	r24, r28
     932:	01 96       	adiw	r24, 0x01	; 1
     934:	0e 94 62 0b 	call	0x16c4	; 0x16c4 <vTaskSetTimeOutState>
					xEntryTimeSet = pdTRUE;
     938:	b9 2c       	mov	r11, r9
					/* Entry time was already set. */
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		taskEXIT_CRITICAL();
     93a:	0f 90       	pop	r0
     93c:	0f be       	out	0x3f, r0	; 63

		/* Interrupts and other tasks can send to and receive from the queue
		now the critical section has been exited. */

		vTaskSuspendAll();
     93e:	0e 94 49 08 	call	0x1092	; 0x1092 <vTaskSuspendAll>
		prvLockQueue( pxQueue );
     942:	0f b6       	in	r0, 0x3f	; 63
     944:	f8 94       	cli
     946:	0f 92       	push	r0
     948:	f8 01       	movw	r30, r16
     94a:	85 8d       	ldd	r24, Z+29	; 0x1d
     94c:	8f 3f       	cpi	r24, 0xFF	; 255
     94e:	09 f4       	brne	.+2      	; 0x952 <xQueueGenericSend+0xb6>
     950:	15 8e       	std	Z+29, r1	; 0x1d
     952:	f8 01       	movw	r30, r16
     954:	86 8d       	ldd	r24, Z+30	; 0x1e
     956:	8f 3f       	cpi	r24, 0xFF	; 255
     958:	09 f4       	brne	.+2      	; 0x95c <xQueueGenericSend+0xc0>
     95a:	16 8e       	std	Z+30, r1	; 0x1e
     95c:	0f 90       	pop	r0
     95e:	0f be       	out	0x3f, r0	; 63

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
     960:	be 01       	movw	r22, r28
     962:	6c 5f       	subi	r22, 0xFC	; 252
     964:	7f 4f       	sbci	r23, 0xFF	; 255
     966:	ce 01       	movw	r24, r28
     968:	01 96       	adiw	r24, 0x01	; 1
     96a:	0e 94 6d 0b 	call	0x16da	; 0x16da <xTaskCheckForTimeOut>
     96e:	81 11       	cpse	r24, r1
     970:	20 c0       	rjmp	.+64     	; 0x9b2 <xQueueGenericSend+0x116>

static BaseType_t prvIsQueueFull( const Queue_t *pxQueue )
{
BaseType_t xReturn;

	taskENTER_CRITICAL();
     972:	0f b6       	in	r0, 0x3f	; 63
     974:	f8 94       	cli
     976:	0f 92       	push	r0
	{
		if( pxQueue->uxMessagesWaiting == pxQueue->uxLength )
     978:	f8 01       	movw	r30, r16
     97a:	92 8d       	ldd	r25, Z+26	; 0x1a
		else
		{
			xReturn = pdFALSE;
		}
	}
	taskEXIT_CRITICAL();
     97c:	0f 90       	pop	r0
     97e:	0f be       	out	0x3f, r0	; 63
		prvLockQueue( pxQueue );

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
		{
			if( prvIsQueueFull( pxQueue ) != pdFALSE )
     980:	f8 01       	movw	r30, r16
     982:	83 8d       	ldd	r24, Z+27	; 0x1b
     984:	98 13       	cpse	r25, r24
     986:	0f c0       	rjmp	.+30     	; 0x9a6 <xQueueGenericSend+0x10a>
			{
				traceBLOCKING_ON_QUEUE_SEND( pxQueue );
				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToSend ), xTicksToWait );
     988:	6c 81       	ldd	r22, Y+4	; 0x04
     98a:	7d 81       	ldd	r23, Y+5	; 0x05
     98c:	c7 01       	movw	r24, r14
     98e:	0e 94 9f 0a 	call	0x153e	; 0x153e <vTaskPlaceOnEventList>
				/* Unlocking the queue means queue events can effect the
				event list.  It is possible	that interrupts occurring now
				remove this task from the event	list again - but as the
				scheduler is suspended the task will go onto the pending
				ready last instead of the actual ready list. */
				prvUnlockQueue( pxQueue );
     992:	c8 01       	movw	r24, r16
     994:	0e 94 99 03 	call	0x732	; 0x732 <prvUnlockQueue>
				/* Resuming the scheduler will move tasks from the pending
				ready list into the ready list - so it is feasible that this
				task is already in a ready list before it yields - in which
				case the yield will not cause a context switch unless there
				is also a higher priority task in the pending ready list. */
				if( xTaskResumeAll() == pdFALSE )
     998:	0e 94 20 09 	call	0x1240	; 0x1240 <xTaskResumeAll>
     99c:	81 11       	cpse	r24, r1
     99e:	9a cf       	rjmp	.-204    	; 0x8d4 <xQueueGenericSend+0x38>
				{
					portYIELD_WITHIN_API();
     9a0:	0e 94 36 02 	call	0x46c	; 0x46c <vPortYield>
     9a4:	97 cf       	rjmp	.-210    	; 0x8d4 <xQueueGenericSend+0x38>
				}
			}
			else
			{
				/* Try again. */
				prvUnlockQueue( pxQueue );
     9a6:	c8 01       	movw	r24, r16
     9a8:	0e 94 99 03 	call	0x732	; 0x732 <prvUnlockQueue>
				( void ) xTaskResumeAll();
     9ac:	0e 94 20 09 	call	0x1240	; 0x1240 <xTaskResumeAll>
     9b0:	91 cf       	rjmp	.-222    	; 0x8d4 <xQueueGenericSend+0x38>
			}
		}
		else
		{
			/* The timeout has expired. */
			prvUnlockQueue( pxQueue );
     9b2:	c8 01       	movw	r24, r16
     9b4:	0e 94 99 03 	call	0x732	; 0x732 <prvUnlockQueue>
			( void ) xTaskResumeAll();
     9b8:	0e 94 20 09 	call	0x1240	; 0x1240 <xTaskResumeAll>

			/* Return to the original privilege level before exiting the
			function. */
			traceQUEUE_SEND_FAILED( pxQueue );
			return errQUEUE_FULL;
     9bc:	80 e0       	ldi	r24, 0x00	; 0
		}
	}
}
     9be:	0f 90       	pop	r0
     9c0:	0f 90       	pop	r0
     9c2:	0f 90       	pop	r0
     9c4:	0f 90       	pop	r0
     9c6:	0f 90       	pop	r0
     9c8:	df 91       	pop	r29
     9ca:	cf 91       	pop	r28
     9cc:	1f 91       	pop	r17
     9ce:	0f 91       	pop	r16
     9d0:	ff 90       	pop	r15
     9d2:	ef 90       	pop	r14
     9d4:	df 90       	pop	r13
     9d6:	cf 90       	pop	r12
     9d8:	bf 90       	pop	r11
     9da:	af 90       	pop	r10
     9dc:	9f 90       	pop	r9
     9de:	08 95       	ret

000009e0 <xQueueGenericSendFromISR>:

#endif /* configUSE_ALTERNATIVE_API */
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericSendFromISR( QueueHandle_t xQueue, const void * const pvItemToQueue, BaseType_t * const pxHigherPriorityTaskWoken, const BaseType_t xCopyPosition )
{
     9e0:	0f 93       	push	r16
     9e2:	1f 93       	push	r17
     9e4:	cf 93       	push	r28
     9e6:	df 93       	push	r29
     9e8:	ec 01       	movw	r28, r24
     9ea:	8a 01       	movw	r16, r20
	read, instead return a flag to say whether a context switch is required or
	not (i.e. has a task with a higher priority than us been woken by this
	post). */
	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		if( ( pxQueue->uxMessagesWaiting < pxQueue->uxLength ) || ( xCopyPosition == queueOVERWRITE ) )
     9ec:	9a 8d       	ldd	r25, Y+26	; 0x1a
     9ee:	8b 8d       	ldd	r24, Y+27	; 0x1b
     9f0:	98 17       	cp	r25, r24
     9f2:	10 f0       	brcs	.+4      	; 0x9f8 <xQueueGenericSendFromISR+0x18>
     9f4:	22 30       	cpi	r18, 0x02	; 2
     9f6:	e1 f4       	brne	.+56     	; 0xa30 <xQueueGenericSendFromISR+0x50>
			/* Semaphores use xQueueGiveFromISR(), so pxQueue will not be a
			semaphore or mutex.  That means prvCopyDataToQueue() cannot result
			in a task disinheriting a priority and prvCopyDataToQueue() can be
			called here even though the disinherit function does not check if
			the scheduler is suspended before accessing the ready lists. */
			( void ) prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );
     9f8:	42 2f       	mov	r20, r18
     9fa:	ce 01       	movw	r24, r28
     9fc:	0e 94 32 03 	call	0x664	; 0x664 <prvCopyDataToQueue>

			/* The event list is not altered if the queue is locked.  This will
			be done when the queue is unlocked later. */
			if( pxQueue->xTxLock == queueUNLOCKED )
     a00:	8e 8d       	ldd	r24, Y+30	; 0x1e
     a02:	8f 3f       	cpi	r24, 0xFF	; 255
     a04:	81 f4       	brne	.+32     	; 0xa26 <xQueueGenericSendFromISR+0x46>
						}
					}
				}
				#else /* configUSE_QUEUE_SETS */
				{
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
     a06:	89 89       	ldd	r24, Y+17	; 0x11
     a08:	88 23       	and	r24, r24
     a0a:	a1 f0       	breq	.+40     	; 0xa34 <xQueueGenericSendFromISR+0x54>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
     a0c:	ce 01       	movw	r24, r28
     a0e:	41 96       	adiw	r24, 0x11	; 17
     a10:	0e 94 e0 0a 	call	0x15c0	; 0x15c0 <xTaskRemoveFromEventList>
     a14:	88 23       	and	r24, r24
     a16:	81 f0       	breq	.+32     	; 0xa38 <xQueueGenericSendFromISR+0x58>
						{
							/* The task waiting has a higher priority so record that a
							context	switch is required. */
							if( pxHigherPriorityTaskWoken != NULL )
     a18:	01 15       	cp	r16, r1
     a1a:	11 05       	cpc	r17, r1
     a1c:	79 f0       	breq	.+30     	; 0xa3c <xQueueGenericSendFromISR+0x5c>
							{
								*pxHigherPriorityTaskWoken = pdTRUE;
     a1e:	81 e0       	ldi	r24, 0x01	; 1
     a20:	f8 01       	movw	r30, r16
     a22:	80 83       	st	Z, r24
     a24:	0c c0       	rjmp	.+24     	; 0xa3e <xQueueGenericSendFromISR+0x5e>
			}
			else
			{
				/* Increment the lock count so the task that unlocks the queue
				knows that data was posted while it was locked. */
				++( pxQueue->xTxLock );
     a26:	8e 8d       	ldd	r24, Y+30	; 0x1e
     a28:	8f 5f       	subi	r24, 0xFF	; 255
     a2a:	8e 8f       	std	Y+30, r24	; 0x1e
			}

			xReturn = pdPASS;
     a2c:	81 e0       	ldi	r24, 0x01	; 1
     a2e:	07 c0       	rjmp	.+14     	; 0xa3e <xQueueGenericSendFromISR+0x5e>
		}
		else
		{
			traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue );
			xReturn = errQUEUE_FULL;
     a30:	80 e0       	ldi	r24, 0x00	; 0
     a32:	05 c0       	rjmp	.+10     	; 0xa3e <xQueueGenericSendFromISR+0x5e>
				/* Increment the lock count so the task that unlocks the queue
				knows that data was posted while it was locked. */
				++( pxQueue->xTxLock );
			}

			xReturn = pdPASS;
     a34:	81 e0       	ldi	r24, 0x01	; 1
     a36:	03 c0       	rjmp	.+6      	; 0xa3e <xQueueGenericSendFromISR+0x5e>
     a38:	81 e0       	ldi	r24, 0x01	; 1
     a3a:	01 c0       	rjmp	.+2      	; 0xa3e <xQueueGenericSendFromISR+0x5e>
     a3c:	81 e0       	ldi	r24, 0x01	; 1
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
     a3e:	df 91       	pop	r29
     a40:	cf 91       	pop	r28
     a42:	1f 91       	pop	r17
     a44:	0f 91       	pop	r16
     a46:	08 95       	ret

00000a48 <xQueueGiveFromISR>:
/*-----------------------------------------------------------*/

BaseType_t xQueueGiveFromISR( QueueHandle_t xQueue, BaseType_t * const pxHigherPriorityTaskWoken )
{
     a48:	cf 93       	push	r28
     a4a:	df 93       	push	r29
     a4c:	fc 01       	movw	r30, r24
     a4e:	eb 01       	movw	r28, r22
	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		/* When the queue is used to implement a semaphore no data is ever
		moved through the queue but it is still valid to see if the queue 'has
		space'. */
		if( pxQueue->uxMessagesWaiting < pxQueue->uxLength )
     a50:	92 8d       	ldd	r25, Z+26	; 0x1a
     a52:	83 8d       	ldd	r24, Z+27	; 0x1b
     a54:	98 17       	cp	r25, r24
     a56:	c8 f4       	brcc	.+50     	; 0xa8a <xQueueGiveFromISR+0x42>
			holder - and if there is a mutex holder then the mutex cannot be
			given from an ISR.  As this is the ISR version of the function it
			can be assumed there is no mutex holder and no need to determine if
			priority disinheritance is needed.  Simply increase the count of
			messages (semaphores) available. */
			++( pxQueue->uxMessagesWaiting );
     a58:	82 8d       	ldd	r24, Z+26	; 0x1a
     a5a:	8f 5f       	subi	r24, 0xFF	; 255
     a5c:	82 8f       	std	Z+26, r24	; 0x1a

			/* The event list is not altered if the queue is locked.  This will
			be done when the queue is unlocked later. */
			if( pxQueue->xTxLock == queueUNLOCKED )
     a5e:	86 8d       	ldd	r24, Z+30	; 0x1e
     a60:	8f 3f       	cpi	r24, 0xFF	; 255
     a62:	71 f4       	brne	.+28     	; 0xa80 <xQueueGiveFromISR+0x38>
						}
					}
				}
				#else /* configUSE_QUEUE_SETS */
				{
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
     a64:	81 89       	ldd	r24, Z+17	; 0x11
     a66:	88 23       	and	r24, r24
     a68:	91 f0       	breq	.+36     	; 0xa8e <xQueueGiveFromISR+0x46>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
     a6a:	cf 01       	movw	r24, r30
     a6c:	41 96       	adiw	r24, 0x11	; 17
     a6e:	0e 94 e0 0a 	call	0x15c0	; 0x15c0 <xTaskRemoveFromEventList>
     a72:	88 23       	and	r24, r24
     a74:	71 f0       	breq	.+28     	; 0xa92 <xQueueGiveFromISR+0x4a>
						{
							/* The task waiting has a higher priority so record that a
							context	switch is required. */
							if( pxHigherPriorityTaskWoken != NULL )
     a76:	20 97       	sbiw	r28, 0x00	; 0
     a78:	71 f0       	breq	.+28     	; 0xa96 <xQueueGiveFromISR+0x4e>
							{
								*pxHigherPriorityTaskWoken = pdTRUE;
     a7a:	81 e0       	ldi	r24, 0x01	; 1
     a7c:	88 83       	st	Y, r24
     a7e:	0c c0       	rjmp	.+24     	; 0xa98 <xQueueGiveFromISR+0x50>
			}
			else
			{
				/* Increment the lock count so the task that unlocks the queue
				knows that data was posted while it was locked. */
				++( pxQueue->xTxLock );
     a80:	86 8d       	ldd	r24, Z+30	; 0x1e
     a82:	8f 5f       	subi	r24, 0xFF	; 255
     a84:	86 8f       	std	Z+30, r24	; 0x1e
			}

			xReturn = pdPASS;
     a86:	81 e0       	ldi	r24, 0x01	; 1
     a88:	07 c0       	rjmp	.+14     	; 0xa98 <xQueueGiveFromISR+0x50>
		}
		else
		{
			traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue );
			xReturn = errQUEUE_FULL;
     a8a:	80 e0       	ldi	r24, 0x00	; 0
     a8c:	05 c0       	rjmp	.+10     	; 0xa98 <xQueueGiveFromISR+0x50>
				/* Increment the lock count so the task that unlocks the queue
				knows that data was posted while it was locked. */
				++( pxQueue->xTxLock );
			}

			xReturn = pdPASS;
     a8e:	81 e0       	ldi	r24, 0x01	; 1
     a90:	03 c0       	rjmp	.+6      	; 0xa98 <xQueueGiveFromISR+0x50>
     a92:	81 e0       	ldi	r24, 0x01	; 1
     a94:	01 c0       	rjmp	.+2      	; 0xa98 <xQueueGiveFromISR+0x50>
     a96:	81 e0       	ldi	r24, 0x01	; 1
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
     a98:	df 91       	pop	r29
     a9a:	cf 91       	pop	r28
     a9c:	08 95       	ret

00000a9e <xQueueGenericReceive>:
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericReceive( QueueHandle_t xQueue, void * const pvBuffer, TickType_t xTicksToWait, const BaseType_t xJustPeeking )
{
     a9e:	9f 92       	push	r9
     aa0:	af 92       	push	r10
     aa2:	bf 92       	push	r11
     aa4:	cf 92       	push	r12
     aa6:	df 92       	push	r13
     aa8:	ef 92       	push	r14
     aaa:	ff 92       	push	r15
     aac:	0f 93       	push	r16
     aae:	1f 93       	push	r17
     ab0:	cf 93       	push	r28
     ab2:	df 93       	push	r29
     ab4:	00 d0       	rcall	.+0      	; 0xab6 <xQueueGenericReceive+0x18>
     ab6:	00 d0       	rcall	.+0      	; 0xab8 <xQueueGenericReceive+0x1a>
     ab8:	1f 92       	push	r1
     aba:	cd b7       	in	r28, 0x3d	; 61
     abc:	de b7       	in	r29, 0x3e	; 62
     abe:	8c 01       	movw	r16, r24
     ac0:	6b 01       	movw	r12, r22
     ac2:	5d 83       	std	Y+5, r21	; 0x05
     ac4:	4c 83       	std	Y+4, r20	; 0x04
     ac6:	b2 2e       	mov	r11, r18
BaseType_t xEntryTimeSet = pdFALSE;
     ac8:	a1 2c       	mov	r10, r1
				else if( xEntryTimeSet == pdFALSE )
				{
					/* The queue was empty and a block time was specified so
					configure the timeout structure. */
					vTaskSetTimeOutState( &xTimeOut );
					xEntryTimeSet = pdTRUE;
     aca:	99 24       	eor	r9, r9
     acc:	93 94       	inc	r9
						mtCOVERAGE_TEST_MARKER();
					}
				}
				#endif

				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
     ace:	7c 01       	movw	r14, r24
     ad0:	81 e1       	ldi	r24, 0x11	; 17
     ad2:	e8 0e       	add	r14, r24
     ad4:	f1 1c       	adc	r15, r1
	statements within the function itself.  This is done in the interest
	of execution time efficiency. */

	for( ;; )
	{
		taskENTER_CRITICAL();
     ad6:	0f b6       	in	r0, 0x3f	; 63
     ad8:	f8 94       	cli
     ada:	0f 92       	push	r0
		{
			/* Is there data in the queue now?  To be running the calling task
			must be	the highest priority task wanting to access the queue. */
			if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )
     adc:	f8 01       	movw	r30, r16
     ade:	82 8d       	ldd	r24, Z+26	; 0x1a
     ae0:	88 23       	and	r24, r24
     ae2:	49 f1       	breq	.+82     	; 0xb36 <xQueueGenericReceive+0x98>
			{
				/* Remember the read position in case the queue is only being
				peeked. */
				pcOriginalReadPosition = pxQueue->u.pcReadFrom;
     ae4:	e6 80       	ldd	r14, Z+6	; 0x06
     ae6:	f7 80       	ldd	r15, Z+7	; 0x07

				prvCopyDataFromQueue( pxQueue, pvBuffer );
     ae8:	b6 01       	movw	r22, r12
     aea:	c8 01       	movw	r24, r16
     aec:	0e 94 7f 03 	call	0x6fe	; 0x6fe <prvCopyDataFromQueue>

				if( xJustPeeking == pdFALSE )
     af0:	b1 10       	cpse	r11, r1
     af2:	10 c0       	rjmp	.+32     	; 0xb14 <xQueueGenericReceive+0x76>
				{
					traceQUEUE_RECEIVE( pxQueue );

					/* Actually removing data, not just peeking. */
					--( pxQueue->uxMessagesWaiting );
     af4:	f8 01       	movw	r30, r16
     af6:	82 8d       	ldd	r24, Z+26	; 0x1a
     af8:	81 50       	subi	r24, 0x01	; 1
     afa:	82 8f       	std	Z+26, r24	; 0x1a
							mtCOVERAGE_TEST_MARKER();
						}
					}
					#endif /* configUSE_MUTEXES */

					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
     afc:	80 85       	ldd	r24, Z+8	; 0x08
     afe:	88 23       	and	r24, r24
     b00:	b1 f0       	breq	.+44     	; 0xb2e <xQueueGenericReceive+0x90>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) == pdTRUE )
     b02:	c8 01       	movw	r24, r16
     b04:	08 96       	adiw	r24, 0x08	; 8
     b06:	0e 94 e0 0a 	call	0x15c0	; 0x15c0 <xTaskRemoveFromEventList>
     b0a:	81 30       	cpi	r24, 0x01	; 1
     b0c:	81 f4       	brne	.+32     	; 0xb2e <xQueueGenericReceive+0x90>
						{
							queueYIELD_IF_USING_PREEMPTION();
     b0e:	0e 94 36 02 	call	0x46c	; 0x46c <vPortYield>
     b12:	0d c0       	rjmp	.+26     	; 0xb2e <xQueueGenericReceive+0x90>
				{
					traceQUEUE_PEEK( pxQueue );

					/* The data is not being removed, so reset the read
					pointer. */
					pxQueue->u.pcReadFrom = pcOriginalReadPosition;
     b14:	f8 01       	movw	r30, r16
     b16:	f7 82       	std	Z+7, r15	; 0x07
     b18:	e6 82       	std	Z+6, r14	; 0x06

					/* The data is being left in the queue, so see if there are
					any other tasks waiting for the data. */
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
     b1a:	81 89       	ldd	r24, Z+17	; 0x11
     b1c:	88 23       	and	r24, r24
     b1e:	39 f0       	breq	.+14     	; 0xb2e <xQueueGenericReceive+0x90>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
     b20:	c8 01       	movw	r24, r16
     b22:	41 96       	adiw	r24, 0x11	; 17
     b24:	0e 94 e0 0a 	call	0x15c0	; 0x15c0 <xTaskRemoveFromEventList>
     b28:	81 11       	cpse	r24, r1
						{
							/* The task waiting has a higher priority than this task. */
							queueYIELD_IF_USING_PREEMPTION();
     b2a:	0e 94 36 02 	call	0x46c	; 0x46c <vPortYield>
					{
						mtCOVERAGE_TEST_MARKER();
					}
				}

				taskEXIT_CRITICAL();
     b2e:	0f 90       	pop	r0
     b30:	0f be       	out	0x3f, r0	; 63
				return pdPASS;
     b32:	81 e0       	ldi	r24, 0x01	; 1
     b34:	4f c0       	rjmp	.+158    	; 0xbd4 <xQueueGenericReceive+0x136>
			}
			else
			{
				if( xTicksToWait == ( TickType_t ) 0 )
     b36:	4c 81       	ldd	r20, Y+4	; 0x04
     b38:	5d 81       	ldd	r21, Y+5	; 0x05
     b3a:	45 2b       	or	r20, r21
     b3c:	21 f4       	brne	.+8      	; 0xb46 <xQueueGenericReceive+0xa8>
				{
					/* The queue was empty and no block time is specified (or
					the block time has expired) so leave now. */
					taskEXIT_CRITICAL();
     b3e:	0f 90       	pop	r0
     b40:	0f be       	out	0x3f, r0	; 63
					traceQUEUE_RECEIVE_FAILED( pxQueue );
					return errQUEUE_EMPTY;
     b42:	80 e0       	ldi	r24, 0x00	; 0
     b44:	47 c0       	rjmp	.+142    	; 0xbd4 <xQueueGenericReceive+0x136>
				}
				else if( xEntryTimeSet == pdFALSE )
     b46:	a1 10       	cpse	r10, r1
     b48:	05 c0       	rjmp	.+10     	; 0xb54 <xQueueGenericReceive+0xb6>
				{
					/* The queue was empty and a block time was specified so
					configure the timeout structure. */
					vTaskSetTimeOutState( &xTimeOut );
     b4a:	ce 01       	movw	r24, r28
     b4c:	01 96       	adiw	r24, 0x01	; 1
     b4e:	0e 94 62 0b 	call	0x16c4	; 0x16c4 <vTaskSetTimeOutState>
					xEntryTimeSet = pdTRUE;
     b52:	a9 2c       	mov	r10, r9
					/* Entry time was already set. */
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		taskEXIT_CRITICAL();
     b54:	0f 90       	pop	r0
     b56:	0f be       	out	0x3f, r0	; 63

		/* Interrupts and other tasks can send to and receive from the queue
		now the critical section has been exited. */

		vTaskSuspendAll();
     b58:	0e 94 49 08 	call	0x1092	; 0x1092 <vTaskSuspendAll>
		prvLockQueue( pxQueue );
     b5c:	0f b6       	in	r0, 0x3f	; 63
     b5e:	f8 94       	cli
     b60:	0f 92       	push	r0
     b62:	f8 01       	movw	r30, r16
     b64:	85 8d       	ldd	r24, Z+29	; 0x1d
     b66:	8f 3f       	cpi	r24, 0xFF	; 255
     b68:	09 f4       	brne	.+2      	; 0xb6c <xQueueGenericReceive+0xce>
     b6a:	15 8e       	std	Z+29, r1	; 0x1d
     b6c:	f8 01       	movw	r30, r16
     b6e:	86 8d       	ldd	r24, Z+30	; 0x1e
     b70:	8f 3f       	cpi	r24, 0xFF	; 255
     b72:	09 f4       	brne	.+2      	; 0xb76 <xQueueGenericReceive+0xd8>
     b74:	16 8e       	std	Z+30, r1	; 0x1e
     b76:	0f 90       	pop	r0
     b78:	0f be       	out	0x3f, r0	; 63

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
     b7a:	be 01       	movw	r22, r28
     b7c:	6c 5f       	subi	r22, 0xFC	; 252
     b7e:	7f 4f       	sbci	r23, 0xFF	; 255
     b80:	ce 01       	movw	r24, r28
     b82:	01 96       	adiw	r24, 0x01	; 1
     b84:	0e 94 6d 0b 	call	0x16da	; 0x16da <xTaskCheckForTimeOut>
     b88:	81 11       	cpse	r24, r1
     b8a:	1e c0       	rjmp	.+60     	; 0xbc8 <xQueueGenericReceive+0x12a>

static BaseType_t prvIsQueueEmpty( const Queue_t *pxQueue )
{
BaseType_t xReturn;

	taskENTER_CRITICAL();
     b8c:	0f b6       	in	r0, 0x3f	; 63
     b8e:	f8 94       	cli
     b90:	0f 92       	push	r0
	{
		if( pxQueue->uxMessagesWaiting == ( UBaseType_t )  0 )
     b92:	f8 01       	movw	r30, r16
     b94:	82 8d       	ldd	r24, Z+26	; 0x1a
		else
		{
			xReturn = pdFALSE;
		}
	}
	taskEXIT_CRITICAL();
     b96:	0f 90       	pop	r0
     b98:	0f be       	out	0x3f, r0	; 63
		prvLockQueue( pxQueue );

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
		{
			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
     b9a:	81 11       	cpse	r24, r1
     b9c:	0f c0       	rjmp	.+30     	; 0xbbc <xQueueGenericReceive+0x11e>
						mtCOVERAGE_TEST_MARKER();
					}
				}
				#endif

				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
     b9e:	6c 81       	ldd	r22, Y+4	; 0x04
     ba0:	7d 81       	ldd	r23, Y+5	; 0x05
     ba2:	c7 01       	movw	r24, r14
     ba4:	0e 94 9f 0a 	call	0x153e	; 0x153e <vTaskPlaceOnEventList>
				prvUnlockQueue( pxQueue );
     ba8:	c8 01       	movw	r24, r16
     baa:	0e 94 99 03 	call	0x732	; 0x732 <prvUnlockQueue>
				if( xTaskResumeAll() == pdFALSE )
     bae:	0e 94 20 09 	call	0x1240	; 0x1240 <xTaskResumeAll>
     bb2:	81 11       	cpse	r24, r1
     bb4:	90 cf       	rjmp	.-224    	; 0xad6 <xQueueGenericReceive+0x38>
				{
					portYIELD_WITHIN_API();
     bb6:	0e 94 36 02 	call	0x46c	; 0x46c <vPortYield>
     bba:	8d cf       	rjmp	.-230    	; 0xad6 <xQueueGenericReceive+0x38>
				}
			}
			else
			{
				/* Try again. */
				prvUnlockQueue( pxQueue );
     bbc:	c8 01       	movw	r24, r16
     bbe:	0e 94 99 03 	call	0x732	; 0x732 <prvUnlockQueue>
				( void ) xTaskResumeAll();
     bc2:	0e 94 20 09 	call	0x1240	; 0x1240 <xTaskResumeAll>
     bc6:	87 cf       	rjmp	.-242    	; 0xad6 <xQueueGenericReceive+0x38>
			}
		}
		else
		{
			prvUnlockQueue( pxQueue );
     bc8:	c8 01       	movw	r24, r16
     bca:	0e 94 99 03 	call	0x732	; 0x732 <prvUnlockQueue>
			( void ) xTaskResumeAll();
     bce:	0e 94 20 09 	call	0x1240	; 0x1240 <xTaskResumeAll>
			traceQUEUE_RECEIVE_FAILED( pxQueue );
			return errQUEUE_EMPTY;
     bd2:	80 e0       	ldi	r24, 0x00	; 0
		}
	}
}
     bd4:	0f 90       	pop	r0
     bd6:	0f 90       	pop	r0
     bd8:	0f 90       	pop	r0
     bda:	0f 90       	pop	r0
     bdc:	0f 90       	pop	r0
     bde:	df 91       	pop	r29
     be0:	cf 91       	pop	r28
     be2:	1f 91       	pop	r17
     be4:	0f 91       	pop	r16
     be6:	ff 90       	pop	r15
     be8:	ef 90       	pop	r14
     bea:	df 90       	pop	r13
     bec:	cf 90       	pop	r12
     bee:	bf 90       	pop	r11
     bf0:	af 90       	pop	r10
     bf2:	9f 90       	pop	r9
     bf4:	08 95       	ret

00000bf6 <xQueueReceiveFromISR>:
/*-----------------------------------------------------------*/

BaseType_t xQueueReceiveFromISR( QueueHandle_t xQueue, void * const pvBuffer, BaseType_t * const pxHigherPriorityTaskWoken )
{
     bf6:	0f 93       	push	r16
     bf8:	1f 93       	push	r17
     bfa:	cf 93       	push	r28
     bfc:	df 93       	push	r29
     bfe:	ec 01       	movw	r28, r24
     c00:	8a 01       	movw	r16, r20
	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		/* Cannot block in an ISR, so check there is data available. */
		if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )
     c02:	8a 8d       	ldd	r24, Y+26	; 0x1a
     c04:	88 23       	and	r24, r24
     c06:	f1 f0       	breq	.+60     	; 0xc44 <xQueueReceiveFromISR+0x4e>
		{
			traceQUEUE_RECEIVE_FROM_ISR( pxQueue );

			prvCopyDataFromQueue( pxQueue, pvBuffer );
     c08:	ce 01       	movw	r24, r28
     c0a:	0e 94 7f 03 	call	0x6fe	; 0x6fe <prvCopyDataFromQueue>
			--( pxQueue->uxMessagesWaiting );
     c0e:	8a 8d       	ldd	r24, Y+26	; 0x1a
     c10:	81 50       	subi	r24, 0x01	; 1
     c12:	8a 8f       	std	Y+26, r24	; 0x1a

			/* If the queue is locked the event list will not be modified.
			Instead update the lock count so the task that unlocks the queue
			will know that an ISR has removed data while the queue was
			locked. */
			if( pxQueue->xRxLock == queueUNLOCKED )
     c14:	8d 8d       	ldd	r24, Y+29	; 0x1d
     c16:	8f 3f       	cpi	r24, 0xFF	; 255
     c18:	81 f4       	brne	.+32     	; 0xc3a <xQueueReceiveFromISR+0x44>
			{
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
     c1a:	88 85       	ldd	r24, Y+8	; 0x08
     c1c:	88 23       	and	r24, r24
     c1e:	a1 f0       	breq	.+40     	; 0xc48 <xQueueReceiveFromISR+0x52>
				{
					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
     c20:	ce 01       	movw	r24, r28
     c22:	08 96       	adiw	r24, 0x08	; 8
     c24:	0e 94 e0 0a 	call	0x15c0	; 0x15c0 <xTaskRemoveFromEventList>
     c28:	88 23       	and	r24, r24
     c2a:	81 f0       	breq	.+32     	; 0xc4c <xQueueReceiveFromISR+0x56>
					{
						/* The task waiting has a higher priority than us so
						force a context switch. */
						if( pxHigherPriorityTaskWoken != NULL )
     c2c:	01 15       	cp	r16, r1
     c2e:	11 05       	cpc	r17, r1
     c30:	79 f0       	breq	.+30     	; 0xc50 <xQueueReceiveFromISR+0x5a>
						{
							*pxHigherPriorityTaskWoken = pdTRUE;
     c32:	81 e0       	ldi	r24, 0x01	; 1
     c34:	f8 01       	movw	r30, r16
     c36:	80 83       	st	Z, r24
     c38:	0c c0       	rjmp	.+24     	; 0xc52 <xQueueReceiveFromISR+0x5c>
			}
			else
			{
				/* Increment the lock count so the task that unlocks the queue
				knows that data was removed while it was locked. */
				++( pxQueue->xRxLock );
     c3a:	8d 8d       	ldd	r24, Y+29	; 0x1d
     c3c:	8f 5f       	subi	r24, 0xFF	; 255
     c3e:	8d 8f       	std	Y+29, r24	; 0x1d
			}

			xReturn = pdPASS;
     c40:	81 e0       	ldi	r24, 0x01	; 1
     c42:	07 c0       	rjmp	.+14     	; 0xc52 <xQueueReceiveFromISR+0x5c>
		}
		else
		{
			xReturn = pdFAIL;
     c44:	80 e0       	ldi	r24, 0x00	; 0
     c46:	05 c0       	rjmp	.+10     	; 0xc52 <xQueueReceiveFromISR+0x5c>
				/* Increment the lock count so the task that unlocks the queue
				knows that data was removed while it was locked. */
				++( pxQueue->xRxLock );
			}

			xReturn = pdPASS;
     c48:	81 e0       	ldi	r24, 0x01	; 1
     c4a:	03 c0       	rjmp	.+6      	; 0xc52 <xQueueReceiveFromISR+0x5c>
     c4c:	81 e0       	ldi	r24, 0x01	; 1
     c4e:	01 c0       	rjmp	.+2      	; 0xc52 <xQueueReceiveFromISR+0x5c>
     c50:	81 e0       	ldi	r24, 0x01	; 1
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
     c52:	df 91       	pop	r29
     c54:	cf 91       	pop	r28
     c56:	1f 91       	pop	r17
     c58:	0f 91       	pop	r16
     c5a:	08 95       	ret

00000c5c <xQueuePeekFromISR>:
/*-----------------------------------------------------------*/

BaseType_t xQueuePeekFromISR( QueueHandle_t xQueue,  void * const pvBuffer )
{
     c5c:	0f 93       	push	r16
     c5e:	1f 93       	push	r17
     c60:	cf 93       	push	r28
     c62:	df 93       	push	r29
     c64:	ec 01       	movw	r28, r24
	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		/* Cannot block in an ISR, so check there is data available. */
		if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )
     c66:	8a 8d       	ldd	r24, Y+26	; 0x1a
     c68:	88 23       	and	r24, r24
     c6a:	49 f0       	breq	.+18     	; 0xc7e <xQueuePeekFromISR+0x22>
		{
			traceQUEUE_PEEK_FROM_ISR( pxQueue );

			/* Remember the read position so it can be reset as nothing is
			actually being removed from the queue. */
			pcOriginalReadPosition = pxQueue->u.pcReadFrom;
     c6c:	0e 81       	ldd	r16, Y+6	; 0x06
     c6e:	1f 81       	ldd	r17, Y+7	; 0x07
			prvCopyDataFromQueue( pxQueue, pvBuffer );
     c70:	ce 01       	movw	r24, r28
     c72:	0e 94 7f 03 	call	0x6fe	; 0x6fe <prvCopyDataFromQueue>
			pxQueue->u.pcReadFrom = pcOriginalReadPosition;
     c76:	1f 83       	std	Y+7, r17	; 0x07
     c78:	0e 83       	std	Y+6, r16	; 0x06

			xReturn = pdPASS;
     c7a:	81 e0       	ldi	r24, 0x01	; 1
     c7c:	01 c0       	rjmp	.+2      	; 0xc80 <xQueuePeekFromISR+0x24>
		}
		else
		{
			xReturn = pdFAIL;
     c7e:	80 e0       	ldi	r24, 0x00	; 0
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
     c80:	df 91       	pop	r29
     c82:	cf 91       	pop	r28
     c84:	1f 91       	pop	r17
     c86:	0f 91       	pop	r16
     c88:	08 95       	ret

00000c8a <uxQueueMessagesWaiting>:
{
UBaseType_t uxReturn;

	configASSERT( xQueue );

	taskENTER_CRITICAL();
     c8a:	0f b6       	in	r0, 0x3f	; 63
     c8c:	f8 94       	cli
     c8e:	0f 92       	push	r0
	{
		uxReturn = ( ( Queue_t * ) xQueue )->uxMessagesWaiting;
     c90:	fc 01       	movw	r30, r24
     c92:	82 8d       	ldd	r24, Z+26	; 0x1a
	}
	taskEXIT_CRITICAL();
     c94:	0f 90       	pop	r0
     c96:	0f be       	out	0x3f, r0	; 63

	return uxReturn;
} /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
     c98:	08 95       	ret

00000c9a <uxQueueSpacesAvailable>:
Queue_t *pxQueue;

	pxQueue = ( Queue_t * ) xQueue;
	configASSERT( pxQueue );

	taskENTER_CRITICAL();
     c9a:	0f b6       	in	r0, 0x3f	; 63
     c9c:	f8 94       	cli
     c9e:	0f 92       	push	r0
	{
		uxReturn = pxQueue->uxLength - pxQueue->uxMessagesWaiting;
     ca0:	fc 01       	movw	r30, r24
     ca2:	22 8d       	ldd	r18, Z+26	; 0x1a
	}
	taskEXIT_CRITICAL();
     ca4:	0f 90       	pop	r0
     ca6:	0f be       	out	0x3f, r0	; 63
	pxQueue = ( Queue_t * ) xQueue;
	configASSERT( pxQueue );

	taskENTER_CRITICAL();
	{
		uxReturn = pxQueue->uxLength - pxQueue->uxMessagesWaiting;
     ca8:	fc 01       	movw	r30, r24
     caa:	83 8d       	ldd	r24, Z+27	; 0x1b
	}
	taskEXIT_CRITICAL();

	return uxReturn;
} /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
     cac:	82 1b       	sub	r24, r18
     cae:	08 95       	ret

00000cb0 <uxQueueMessagesWaitingFromISR>:
{
UBaseType_t uxReturn;

	configASSERT( xQueue );

	uxReturn = ( ( Queue_t * ) xQueue )->uxMessagesWaiting;
     cb0:	fc 01       	movw	r30, r24
     cb2:	82 8d       	ldd	r24, Z+26	; 0x1a

	return uxReturn;
} /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
     cb4:	08 95       	ret

00000cb6 <vQueueDelete>:
	#if ( configQUEUE_REGISTRY_SIZE > 0 )
	{
		vQueueUnregisterQueue( pxQueue );
	}
	#endif
	vPortFree( pxQueue );
     cb6:	0e 94 23 03 	call	0x646	; 0x646 <vPortFree>
     cba:	08 95       	ret

00000cbc <xQueueIsQueueEmptyFromISR>:
BaseType_t xQueueIsQueueEmptyFromISR( const QueueHandle_t xQueue )
{
BaseType_t xReturn;

	configASSERT( xQueue );
	if( ( ( Queue_t * ) xQueue )->uxMessagesWaiting == ( UBaseType_t ) 0 )
     cbc:	fc 01       	movw	r30, r24
     cbe:	92 8d       	ldd	r25, Z+26	; 0x1a
     cc0:	81 e0       	ldi	r24, 0x01	; 1
     cc2:	91 11       	cpse	r25, r1
     cc4:	80 e0       	ldi	r24, 0x00	; 0
	{
		xReturn = pdFALSE;
	}

	return xReturn;
} /*lint !e818 xQueue could not be pointer to const because it is a typedef. */
     cc6:	08 95       	ret

00000cc8 <xQueueIsQueueFullFromISR>:
	return xReturn;
}
/*-----------------------------------------------------------*/

BaseType_t xQueueIsQueueFullFromISR( const QueueHandle_t xQueue )
{
     cc8:	fc 01       	movw	r30, r24
BaseType_t xReturn;

	configASSERT( xQueue );
	if( ( ( Queue_t * ) xQueue )->uxMessagesWaiting == ( ( Queue_t * ) xQueue )->uxLength )
     cca:	22 8d       	ldd	r18, Z+26	; 0x1a
     ccc:	81 e0       	ldi	r24, 0x01	; 1
     cce:	93 8d       	ldd	r25, Z+27	; 0x1b
     cd0:	29 13       	cpse	r18, r25
     cd2:	80 e0       	ldi	r24, 0x00	; 0
	{
		xReturn = pdFALSE;
	}

	return xReturn;
} /*lint !e818 xQueue could not be pointer to const because it is a typedef. */
     cd4:	08 95       	ret

00000cd6 <prvResetNextTaskUnblockTime>:

static void prvResetNextTaskUnblockTime( void )
{
TCB_t *pxTCB;

	if( listLIST_IS_EMPTY( pxDelayedTaskList ) != pdFALSE )
     cd6:	e0 91 19 05 	lds	r30, 0x0519
     cda:	f0 91 1a 05 	lds	r31, 0x051A
     cde:	80 81       	ld	r24, Z
     ce0:	81 11       	cpse	r24, r1
     ce2:	07 c0       	rjmp	.+14     	; 0xcf2 <prvResetNextTaskUnblockTime+0x1c>
	{
		/* The new current delayed list is empty.  Set xNextTaskUnblockTime to
		the maximum possible value so it is	extremely unlikely that the
		if( xTickCount >= xNextTaskUnblockTime ) test will pass until
		there is an item in the delayed list. */
		xNextTaskUnblockTime = portMAX_DELAY;
     ce4:	8f ef       	ldi	r24, 0xFF	; 255
     ce6:	9f ef       	ldi	r25, 0xFF	; 255
     ce8:	90 93 fa 04 	sts	0x04FA, r25
     cec:	80 93 f9 04 	sts	0x04F9, r24
     cf0:	08 95       	ret
	{
		/* The new current delayed list is not empty, get the value of
		the item at the head of the delayed list.  This is the time at
		which the task at the head of the delayed list should be removed
		from the Blocked state. */
		( pxTCB ) = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxDelayedTaskList );
     cf2:	e0 91 19 05 	lds	r30, 0x0519
     cf6:	f0 91 1a 05 	lds	r31, 0x051A
     cfa:	05 80       	ldd	r0, Z+5	; 0x05
     cfc:	f6 81       	ldd	r31, Z+6	; 0x06
     cfe:	e0 2d       	mov	r30, r0
		xNextTaskUnblockTime = listGET_LIST_ITEM_VALUE( &( ( pxTCB )->xGenericListItem ) );
     d00:	06 80       	ldd	r0, Z+6	; 0x06
     d02:	f7 81       	ldd	r31, Z+7	; 0x07
     d04:	e0 2d       	mov	r30, r0
     d06:	82 81       	ldd	r24, Z+2	; 0x02
     d08:	93 81       	ldd	r25, Z+3	; 0x03
     d0a:	90 93 fa 04 	sts	0x04FA, r25
     d0e:	80 93 f9 04 	sts	0x04F9, r24
     d12:	08 95       	ret

00000d14 <prvAddCurrentTaskToDelayedList>:
	#endif /* vTaskDelete */
}
/*-----------------------------------------------------------*/

static void prvAddCurrentTaskToDelayedList( const TickType_t xTimeToWake )
{
     d14:	cf 93       	push	r28
     d16:	df 93       	push	r29
     d18:	ec 01       	movw	r28, r24
	/* The list item will be inserted in wake time order. */
	listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xGenericListItem ), xTimeToWake );
     d1a:	e0 91 f6 04 	lds	r30, 0x04F6
     d1e:	f0 91 f7 04 	lds	r31, 0x04F7
     d22:	93 83       	std	Z+3, r25	; 0x03
     d24:	82 83       	std	Z+2, r24	; 0x02

	if( xTimeToWake < xTickCount )
     d26:	80 91 01 05 	lds	r24, 0x0501
     d2a:	90 91 02 05 	lds	r25, 0x0502
     d2e:	c8 17       	cp	r28, r24
     d30:	d9 07       	cpc	r29, r25
     d32:	68 f4       	brcc	.+26     	; 0xd4e <prvAddCurrentTaskToDelayedList+0x3a>
	{
		/* Wake time has overflowed.  Place this item in the overflow list. */
		vListInsert( pxOverflowDelayedTaskList, &( pxCurrentTCB->xGenericListItem ) );
     d34:	60 91 f6 04 	lds	r22, 0x04F6
     d38:	70 91 f7 04 	lds	r23, 0x04F7
     d3c:	80 91 17 05 	lds	r24, 0x0517
     d40:	90 91 18 05 	lds	r25, 0x0518
     d44:	6e 5f       	subi	r22, 0xFE	; 254
     d46:	7f 4f       	sbci	r23, 0xFF	; 255
     d48:	0e 94 34 01 	call	0x268	; 0x268 <vListInsert>
     d4c:	17 c0       	rjmp	.+46     	; 0xd7c <prvAddCurrentTaskToDelayedList+0x68>
	}
	else
	{
		/* The wake time has not overflowed, so the current block list is used. */
		vListInsert( pxDelayedTaskList, &( pxCurrentTCB->xGenericListItem ) );
     d4e:	60 91 f6 04 	lds	r22, 0x04F6
     d52:	70 91 f7 04 	lds	r23, 0x04F7
     d56:	80 91 19 05 	lds	r24, 0x0519
     d5a:	90 91 1a 05 	lds	r25, 0x051A
     d5e:	6e 5f       	subi	r22, 0xFE	; 254
     d60:	7f 4f       	sbci	r23, 0xFF	; 255
     d62:	0e 94 34 01 	call	0x268	; 0x268 <vListInsert>

		/* If the task entering the blocked state was placed at the head of the
		list of blocked tasks then xNextTaskUnblockTime needs to be updated
		too. */
		if( xTimeToWake < xNextTaskUnblockTime )
     d66:	80 91 f9 04 	lds	r24, 0x04F9
     d6a:	90 91 fa 04 	lds	r25, 0x04FA
     d6e:	c8 17       	cp	r28, r24
     d70:	d9 07       	cpc	r29, r25
     d72:	20 f4       	brcc	.+8      	; 0xd7c <prvAddCurrentTaskToDelayedList+0x68>
		{
			xNextTaskUnblockTime = xTimeToWake;
     d74:	d0 93 fa 04 	sts	0x04FA, r29
     d78:	c0 93 f9 04 	sts	0x04F9, r28
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
}
     d7c:	df 91       	pop	r29
     d7e:	cf 91       	pop	r28
     d80:	08 95       	ret

00000d82 <xTaskGenericCreate>:

#endif
/*-----------------------------------------------------------*/

BaseType_t xTaskGenericCreate( TaskFunction_t pxTaskCode, const char * const pcName, const uint16_t usStackDepth, void * const pvParameters, UBaseType_t uxPriority, TaskHandle_t * const pxCreatedTask, StackType_t * const puxStackBuffer, const MemoryRegion_t * const xRegions ) /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
{
     d82:	4f 92       	push	r4
     d84:	5f 92       	push	r5
     d86:	6f 92       	push	r6
     d88:	7f 92       	push	r7
     d8a:	8f 92       	push	r8
     d8c:	9f 92       	push	r9
     d8e:	af 92       	push	r10
     d90:	bf 92       	push	r11
     d92:	cf 92       	push	r12
     d94:	df 92       	push	r13
     d96:	ef 92       	push	r14
     d98:	ff 92       	push	r15
     d9a:	0f 93       	push	r16
     d9c:	1f 93       	push	r17
     d9e:	cf 93       	push	r28
     da0:	df 93       	push	r29
     da2:	4c 01       	movw	r8, r24
     da4:	5b 01       	movw	r10, r22
     da6:	2a 01       	movw	r4, r20
     da8:	39 01       	movw	r6, r18
	#else /* portSTACK_GROWTH */
	{
	StackType_t *pxStack;

		/* Allocate space for the stack used by the task being created. */
		pxStack = ( StackType_t * ) pvPortMallocAligned( ( ( ( size_t ) usStackDepth ) * sizeof( StackType_t ) ), puxStackBuffer ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
     daa:	c1 14       	cp	r12, r1
     dac:	d1 04       	cpc	r13, r1
     dae:	39 f4       	brne	.+14     	; 0xdbe <xTaskGenericCreate+0x3c>
     db0:	ca 01       	movw	r24, r20
     db2:	0e 94 ee 02 	call	0x5dc	; 0x5dc <pvPortMalloc>
     db6:	6c 01       	movw	r12, r24

		if( pxStack != NULL )
     db8:	00 97       	sbiw	r24, 0x00	; 0
     dba:	09 f4       	brne	.+2      	; 0xdbe <xTaskGenericCreate+0x3c>
     dbc:	d9 c0       	rjmp	.+434    	; 0xf70 <xTaskGenericCreate+0x1ee>
		{
			/* Allocate space for the TCB.  Where the memory comes from depends
			on the implementation of the port malloc function. */
			pxNewTCB = ( TCB_t * ) pvPortMalloc( sizeof( TCB_t ) );
     dbe:	86 e2       	ldi	r24, 0x26	; 38
     dc0:	90 e0       	ldi	r25, 0x00	; 0
     dc2:	0e 94 ee 02 	call	0x5dc	; 0x5dc <pvPortMalloc>
     dc6:	ec 01       	movw	r28, r24

			if( pxNewTCB != NULL )
     dc8:	00 97       	sbiw	r24, 0x00	; 0
     dca:	71 f0       	breq	.+28     	; 0xde8 <xTaskGenericCreate+0x66>
			{
				/* Store the stack location in the TCB. */
				pxNewTCB->pxStack = pxStack;
     dcc:	d8 8e       	std	Y+24, r13	; 0x18
     dce:	cf 8a       	std	Y+23, r12	; 0x17
		stack grows from high memory to low (as per the 80x86) or vice versa.
		portSTACK_GROWTH is used to make the result positive or negative as
		required by the port. */
		#if( portSTACK_GROWTH < 0 )
		{
			pxTopOfStack = pxNewTCB->pxStack + ( usStackDepth - ( uint16_t ) 1 );
     dd0:	81 e0       	ldi	r24, 0x01	; 1
     dd2:	48 1a       	sub	r4, r24
     dd4:	51 08       	sbc	r5, r1
     dd6:	c4 0c       	add	r12, r4
     dd8:	d5 1c       	adc	r13, r5
UBaseType_t x;

	/* Store the task name in the TCB. */
	for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
	{
		pxTCB->pcTaskName[ x ] = pcName[ x ];
     dda:	d5 01       	movw	r26, r10
     ddc:	8c 91       	ld	r24, X
     dde:	89 8f       	std	Y+25, r24	; 0x19

		/* Don't copy all configMAX_TASK_NAME_LEN if the string is shorter than
		configMAX_TASK_NAME_LEN characters just in case the memory after the
		string is not accessible (extremely unlikely). */
		if( pcName[ x ] == 0x00 )
     de0:	8c 91       	ld	r24, X
     de2:	81 11       	cpse	r24, r1
     de4:	05 c0       	rjmp	.+10     	; 0xdf0 <xTaskGenericCreate+0x6e>
     de6:	15 c0       	rjmp	.+42     	; 0xe12 <xTaskGenericCreate+0x90>
			}
			else
			{
				/* The stack cannot be used as the TCB was not created.  Free it
				again. */
				vPortFree( pxStack );
     de8:	c6 01       	movw	r24, r12
     dea:	0e 94 23 03 	call	0x646	; 0x646 <vPortFree>
     dee:	c0 c0       	rjmp	.+384    	; 0xf70 <xTaskGenericCreate+0x1ee>
     df0:	ae 01       	movw	r20, r28
     df2:	46 5e       	subi	r20, 0xE6	; 230
     df4:	5f 4f       	sbci	r21, 0xFF	; 255
     df6:	f5 01       	movw	r30, r10
     df8:	31 96       	adiw	r30, 0x01	; 1
		pxTCB->pcTaskName[ x ] = pcName[ x ];

		/* Don't copy all configMAX_TASK_NAME_LEN if the string is shorter than
		configMAX_TASK_NAME_LEN characters just in case the memory after the
		string is not accessible (extremely unlikely). */
		if( pcName[ x ] == 0x00 )
     dfa:	27 e0       	ldi	r18, 0x07	; 7
     dfc:	cf 01       	movw	r24, r30
UBaseType_t x;

	/* Store the task name in the TCB. */
	for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
	{
		pxTCB->pcTaskName[ x ] = pcName[ x ];
     dfe:	31 91       	ld	r19, Z+
     e00:	da 01       	movw	r26, r20
     e02:	3d 93       	st	X+, r19
     e04:	ad 01       	movw	r20, r26

		/* Don't copy all configMAX_TASK_NAME_LEN if the string is shorter than
		configMAX_TASK_NAME_LEN characters just in case the memory after the
		string is not accessible (extremely unlikely). */
		if( pcName[ x ] == 0x00 )
     e06:	dc 01       	movw	r26, r24
     e08:	8c 91       	ld	r24, X
     e0a:	88 23       	and	r24, r24
     e0c:	11 f0       	breq	.+4      	; 0xe12 <xTaskGenericCreate+0x90>
     e0e:	21 50       	subi	r18, 0x01	; 1
static void prvInitialiseTCBVariables( TCB_t * const pxTCB, const char * const pcName, UBaseType_t uxPriority, const MemoryRegion_t * const xRegions, const uint16_t usStackDepth ) /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
{
UBaseType_t x;

	/* Store the task name in the TCB. */
	for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
     e10:	a9 f7       	brne	.-22     	; 0xdfc <xTaskGenericCreate+0x7a>
		}
	}

	/* Ensure the name string is terminated in the case that the string length
	was greater or equal to configMAX_TASK_NAME_LEN. */
	pxTCB->pcTaskName[ configMAX_TASK_NAME_LEN - 1 ] = '\0';
     e12:	18 a2       	std	Y+32, r1	; 0x20
     e14:	10 2f       	mov	r17, r16
     e16:	04 30       	cpi	r16, 0x04	; 4
     e18:	08 f0       	brcs	.+2      	; 0xe1c <xTaskGenericCreate+0x9a>
     e1a:	13 e0       	ldi	r17, 0x03	; 3
	else
	{
		mtCOVERAGE_TEST_MARKER();
	}

	pxTCB->uxPriority = uxPriority;
     e1c:	1e 8b       	std	Y+22, r17	; 0x16
		pxTCB->uxBasePriority = uxPriority;
		pxTCB->uxMutexesHeld = 0;
	}
	#endif /* configUSE_MUTEXES */

	vListInitialiseItem( &( pxTCB->xGenericListItem ) );
     e1e:	5e 01       	movw	r10, r28
     e20:	b2 e0       	ldi	r27, 0x02	; 2
     e22:	ab 0e       	add	r10, r27
     e24:	b1 1c       	adc	r11, r1
     e26:	c5 01       	movw	r24, r10
     e28:	0e 94 0f 01 	call	0x21e	; 0x21e <vListInitialiseItem>
	vListInitialiseItem( &( pxTCB->xEventListItem ) );
     e2c:	ce 01       	movw	r24, r28
     e2e:	0c 96       	adiw	r24, 0x0c	; 12
     e30:	0e 94 0f 01 	call	0x21e	; 0x21e <vListInitialiseItem>

	/* Set the pxTCB as a link back from the ListItem_t.  This is so we can get
	back to	the containing TCB from a generic item in a list. */
	listSET_LIST_ITEM_OWNER( &( pxTCB->xGenericListItem ), pxTCB );
     e34:	d9 87       	std	Y+9, r29	; 0x09
     e36:	c8 87       	std	Y+8, r28	; 0x08

	/* Event lists are always in priority order. */
	listSET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ), ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) uxPriority ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
     e38:	84 e0       	ldi	r24, 0x04	; 4
     e3a:	90 e0       	ldi	r25, 0x00	; 0
     e3c:	81 1b       	sub	r24, r17
     e3e:	91 09       	sbc	r25, r1
     e40:	9d 87       	std	Y+13, r25	; 0x0d
     e42:	8c 87       	std	Y+12, r24	; 0x0c
	listSET_LIST_ITEM_OWNER( &( pxTCB->xEventListItem ), pxTCB );
     e44:	db 8b       	std	Y+19, r29	; 0x13
     e46:	ca 8b       	std	Y+18, r28	; 0x12
	}
	#endif

	#if ( configUSE_TASK_NOTIFICATIONS == 1 )
	{
		pxTCB->ulNotifiedValue = 0;
     e48:	19 a2       	std	Y+33, r1	; 0x21
     e4a:	1a a2       	std	Y+34, r1	; 0x22
     e4c:	1b a2       	std	Y+35, r1	; 0x23
     e4e:	1c a2       	std	Y+36, r1	; 0x24
		pxTCB->eNotifyState = eNotWaitingNotification;
     e50:	1d a2       	std	Y+37, r1	; 0x25
		{
			pxNewTCB->pxTopOfStack = pxPortInitialiseStack( pxTopOfStack, pxTaskCode, pvParameters, xRunPrivileged );
		}
		#else /* portUSING_MPU_WRAPPERS */
		{
			pxNewTCB->pxTopOfStack = pxPortInitialiseStack( pxTopOfStack, pxTaskCode, pvParameters );
     e52:	a3 01       	movw	r20, r6
     e54:	b4 01       	movw	r22, r8
     e56:	c6 01       	movw	r24, r12
     e58:	0e 94 8b 01 	call	0x316	; 0x316 <pxPortInitialiseStack>
     e5c:	99 83       	std	Y+1, r25	; 0x01
     e5e:	88 83       	st	Y, r24
		}
		#endif /* portUSING_MPU_WRAPPERS */

		if( ( void * ) pxCreatedTask != NULL )
     e60:	e1 14       	cp	r14, r1
     e62:	f1 04       	cpc	r15, r1
     e64:	19 f0       	breq	.+6      	; 0xe6c <xTaskGenericCreate+0xea>
		{
			/* Pass the TCB out - in an anonymous way.  The calling function/
			task can use this as a handle to delete the task later if
			required.*/
			*pxCreatedTask = ( TaskHandle_t ) pxNewTCB;
     e66:	f7 01       	movw	r30, r14
     e68:	d1 83       	std	Z+1, r29	; 0x01
     e6a:	c0 83       	st	Z, r28
			mtCOVERAGE_TEST_MARKER();
		}

		/* Ensure interrupts don't access the task lists while they are being
		updated. */
		taskENTER_CRITICAL();
     e6c:	0f b6       	in	r0, 0x3f	; 63
     e6e:	f8 94       	cli
     e70:	0f 92       	push	r0
		{
			uxCurrentNumberOfTasks++;
     e72:	80 91 03 05 	lds	r24, 0x0503
     e76:	8f 5f       	subi	r24, 0xFF	; 255
     e78:	80 93 03 05 	sts	0x0503, r24
			if( pxCurrentTCB == NULL )
     e7c:	80 91 f6 04 	lds	r24, 0x04F6
     e80:	90 91 f7 04 	lds	r25, 0x04F7
     e84:	89 2b       	or	r24, r25
     e86:	a9 f5       	brne	.+106    	; 0xef2 <xTaskGenericCreate+0x170>
			{
				/* There are no other tasks, or all the other tasks are in
				the suspended state - make this the current task. */
				pxCurrentTCB =  pxNewTCB;
     e88:	d0 93 f7 04 	sts	0x04F7, r29
     e8c:	c0 93 f6 04 	sts	0x04F6, r28

				if( uxCurrentNumberOfTasks == ( UBaseType_t ) 1 )
     e90:	80 91 03 05 	lds	r24, 0x0503
     e94:	81 30       	cpi	r24, 0x01	; 1
     e96:	e1 f5       	brne	.+120    	; 0xf10 <xTaskGenericCreate+0x18e>
{
UBaseType_t uxPriority;

	for( uxPriority = ( UBaseType_t ) 0U; uxPriority < ( UBaseType_t ) configMAX_PRIORITIES; uxPriority++ )
	{
		vListInitialise( &( pxReadyTasksLists[ uxPriority ] ) );
     e98:	8d e2       	ldi	r24, 0x2D	; 45
     e9a:	95 e0       	ldi	r25, 0x05	; 5
     e9c:	0e 94 01 01 	call	0x202	; 0x202 <vListInitialise>
     ea0:	86 e3       	ldi	r24, 0x36	; 54
     ea2:	95 e0       	ldi	r25, 0x05	; 5
     ea4:	0e 94 01 01 	call	0x202	; 0x202 <vListInitialise>
     ea8:	8f e3       	ldi	r24, 0x3F	; 63
     eaa:	95 e0       	ldi	r25, 0x05	; 5
     eac:	0e 94 01 01 	call	0x202	; 0x202 <vListInitialise>
     eb0:	88 e4       	ldi	r24, 0x48	; 72
     eb2:	95 e0       	ldi	r25, 0x05	; 5
     eb4:	0e 94 01 01 	call	0x202	; 0x202 <vListInitialise>
	}

	vListInitialise( &xDelayedTaskList1 );
     eb8:	84 e2       	ldi	r24, 0x24	; 36
     eba:	95 e0       	ldi	r25, 0x05	; 5
     ebc:	0e 94 01 01 	call	0x202	; 0x202 <vListInitialise>
	vListInitialise( &xDelayedTaskList2 );
     ec0:	8b e1       	ldi	r24, 0x1B	; 27
     ec2:	95 e0       	ldi	r25, 0x05	; 5
     ec4:	0e 94 01 01 	call	0x202	; 0x202 <vListInitialise>
	vListInitialise( &xPendingReadyList );
     ec8:	8e e0       	ldi	r24, 0x0E	; 14
     eca:	95 e0       	ldi	r25, 0x05	; 5
     ecc:	0e 94 01 01 	call	0x202	; 0x202 <vListInitialise>

	#if ( INCLUDE_vTaskDelete == 1 )
	{
		vListInitialise( &xTasksWaitingTermination );
     ed0:	85 e0       	ldi	r24, 0x05	; 5
     ed2:	95 e0       	ldi	r25, 0x05	; 5
     ed4:	0e 94 01 01 	call	0x202	; 0x202 <vListInitialise>
	}
	#endif /* INCLUDE_vTaskSuspend */

	/* Start with pxDelayedTaskList using list1 and the pxOverflowDelayedTaskList
	using list2. */
	pxDelayedTaskList = &xDelayedTaskList1;
     ed8:	84 e2       	ldi	r24, 0x24	; 36
     eda:	95 e0       	ldi	r25, 0x05	; 5
     edc:	90 93 1a 05 	sts	0x051A, r25
     ee0:	80 93 19 05 	sts	0x0519, r24
	pxOverflowDelayedTaskList = &xDelayedTaskList2;
     ee4:	8b e1       	ldi	r24, 0x1B	; 27
     ee6:	95 e0       	ldi	r25, 0x05	; 5
     ee8:	90 93 18 05 	sts	0x0518, r25
     eec:	80 93 17 05 	sts	0x0517, r24
     ef0:	0f c0       	rjmp	.+30     	; 0xf10 <xTaskGenericCreate+0x18e>
			else
			{
				/* If the scheduler is not already running, make this task the
				current task if it is the highest priority task to be created
				so far. */
				if( xSchedulerRunning == pdFALSE )
     ef2:	80 91 ff 04 	lds	r24, 0x04FF
     ef6:	81 11       	cpse	r24, r1
     ef8:	0b c0       	rjmp	.+22     	; 0xf10 <xTaskGenericCreate+0x18e>
				{
					if( pxCurrentTCB->uxPriority <= uxPriority )
     efa:	e0 91 f6 04 	lds	r30, 0x04F6
     efe:	f0 91 f7 04 	lds	r31, 0x04F7
     f02:	86 89       	ldd	r24, Z+22	; 0x16
     f04:	08 17       	cp	r16, r24
     f06:	20 f0       	brcs	.+8      	; 0xf10 <xTaskGenericCreate+0x18e>
					{
						pxCurrentTCB = pxNewTCB;
     f08:	d0 93 f7 04 	sts	0x04F7, r29
     f0c:	c0 93 f6 04 	sts	0x04F6, r28
				{
					mtCOVERAGE_TEST_MARKER();
				}
			}

			uxTaskNumber++;
     f10:	80 91 fb 04 	lds	r24, 0x04FB
     f14:	8f 5f       	subi	r24, 0xFF	; 255
     f16:	80 93 fb 04 	sts	0x04FB, r24
				pxNewTCB->uxTCBNumber = uxTaskNumber;
			}
			#endif /* configUSE_TRACE_FACILITY */
			traceTASK_CREATE( pxNewTCB );

			prvAddTaskToReadyList( pxNewTCB );
     f1a:	8e 89       	ldd	r24, Y+22	; 0x16
     f1c:	90 91 00 05 	lds	r25, 0x0500
     f20:	98 17       	cp	r25, r24
     f22:	10 f4       	brcc	.+4      	; 0xf28 <xTaskGenericCreate+0x1a6>
     f24:	80 93 00 05 	sts	0x0500, r24
     f28:	90 e0       	ldi	r25, 0x00	; 0
     f2a:	9c 01       	movw	r18, r24
     f2c:	22 0f       	add	r18, r18
     f2e:	33 1f       	adc	r19, r19
     f30:	22 0f       	add	r18, r18
     f32:	33 1f       	adc	r19, r19
     f34:	22 0f       	add	r18, r18
     f36:	33 1f       	adc	r19, r19
     f38:	82 0f       	add	r24, r18
     f3a:	93 1f       	adc	r25, r19
     f3c:	b5 01       	movw	r22, r10
     f3e:	83 5d       	subi	r24, 0xD3	; 211
     f40:	9a 4f       	sbci	r25, 0xFA	; 250
     f42:	0e 94 13 01 	call	0x226	; 0x226 <vListInsertEnd>

			xReturn = pdPASS;
			portSETUP_TCB( pxNewTCB );
		}
		taskEXIT_CRITICAL();
     f46:	0f 90       	pop	r0
     f48:	0f be       	out	0x3f, r0	; 63
		traceTASK_CREATE_FAILED();
	}

	if( xReturn == pdPASS )
	{
		if( xSchedulerRunning != pdFALSE )
     f4a:	80 91 ff 04 	lds	r24, 0x04FF
     f4e:	88 23       	and	r24, r24
     f50:	59 f0       	breq	.+22     	; 0xf68 <xTaskGenericCreate+0x1e6>
		{
			/* If the created task is of a higher priority than the current task
			then it should run now. */
			if( pxCurrentTCB->uxPriority < uxPriority )
     f52:	e0 91 f6 04 	lds	r30, 0x04F6
     f56:	f0 91 f7 04 	lds	r31, 0x04F7
     f5a:	86 89       	ldd	r24, Z+22	; 0x16
     f5c:	80 17       	cp	r24, r16
     f5e:	30 f4       	brcc	.+12     	; 0xf6c <xTaskGenericCreate+0x1ea>
			{
				taskYIELD_IF_USING_PREEMPTION();
     f60:	0e 94 36 02 	call	0x46c	; 0x46c <vPortYield>
			#endif /* configUSE_TRACE_FACILITY */
			traceTASK_CREATE( pxNewTCB );

			prvAddTaskToReadyList( pxNewTCB );

			xReturn = pdPASS;
     f64:	81 e0       	ldi	r24, 0x01	; 1
     f66:	05 c0       	rjmp	.+10     	; 0xf72 <xTaskGenericCreate+0x1f0>
     f68:	81 e0       	ldi	r24, 0x01	; 1
     f6a:	03 c0       	rjmp	.+6      	; 0xf72 <xTaskGenericCreate+0x1f0>
     f6c:	81 e0       	ldi	r24, 0x01	; 1
     f6e:	01 c0       	rjmp	.+2      	; 0xf72 <xTaskGenericCreate+0x1f0>
		}
		taskEXIT_CRITICAL();
	}
	else
	{
		xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;
     f70:	8f ef       	ldi	r24, 0xFF	; 255
			mtCOVERAGE_TEST_MARKER();
		}
	}

	return xReturn;
}
     f72:	df 91       	pop	r29
     f74:	cf 91       	pop	r28
     f76:	1f 91       	pop	r17
     f78:	0f 91       	pop	r16
     f7a:	ff 90       	pop	r15
     f7c:	ef 90       	pop	r14
     f7e:	df 90       	pop	r13
     f80:	cf 90       	pop	r12
     f82:	bf 90       	pop	r11
     f84:	af 90       	pop	r10
     f86:	9f 90       	pop	r9
     f88:	8f 90       	pop	r8
     f8a:	7f 90       	pop	r7
     f8c:	6f 90       	pop	r6
     f8e:	5f 90       	pop	r5
     f90:	4f 90       	pop	r4
     f92:	08 95       	ret

00000f94 <vTaskDelete>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskDelete == 1 )

	void vTaskDelete( TaskHandle_t xTaskToDelete )
	{
     f94:	0f 93       	push	r16
     f96:	1f 93       	push	r17
     f98:	cf 93       	push	r28
     f9a:	df 93       	push	r29
     f9c:	ec 01       	movw	r28, r24
	TCB_t *pxTCB;

		taskENTER_CRITICAL();
     f9e:	0f b6       	in	r0, 0x3f	; 63
     fa0:	f8 94       	cli
     fa2:	0f 92       	push	r0
		{
			/* If null is passed in here then it is the calling task that is
			being deleted. */
			pxTCB = prvGetTCBFromHandle( xTaskToDelete );
     fa4:	00 97       	sbiw	r24, 0x00	; 0
     fa6:	21 f4       	brne	.+8      	; 0xfb0 <vTaskDelete+0x1c>
     fa8:	c0 91 f6 04 	lds	r28, 0x04F6
     fac:	d0 91 f7 04 	lds	r29, 0x04F7

			/* Remove task from the ready list and place in the	termination list.
			This will stop the task from be scheduled.  The idle task will check
			the termination list and free up any memory allocated by the
			scheduler for the TCB and stack. */
			if( uxListRemove( &( pxTCB->xGenericListItem ) ) == ( UBaseType_t ) 0 )
     fb0:	8e 01       	movw	r16, r28
     fb2:	0e 5f       	subi	r16, 0xFE	; 254
     fb4:	1f 4f       	sbci	r17, 0xFF	; 255
     fb6:	c8 01       	movw	r24, r16
     fb8:	0e 94 65 01 	call	0x2ca	; 0x2ca <uxListRemove>
			{
				mtCOVERAGE_TEST_MARKER();
			}

			/* Is the task waiting on an event also? */
			if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
     fbc:	8c 89       	ldd	r24, Y+20	; 0x14
     fbe:	9d 89       	ldd	r25, Y+21	; 0x15
     fc0:	89 2b       	or	r24, r25
     fc2:	21 f0       	breq	.+8      	; 0xfcc <vTaskDelete+0x38>
			{
				( void ) uxListRemove( &( pxTCB->xEventListItem ) );
     fc4:	ce 01       	movw	r24, r28
     fc6:	0c 96       	adiw	r24, 0x0c	; 12
     fc8:	0e 94 65 01 	call	0x2ca	; 0x2ca <uxListRemove>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}

			vListInsertEnd( &xTasksWaitingTermination, &( pxTCB->xGenericListItem ) );
     fcc:	b8 01       	movw	r22, r16
     fce:	85 e0       	ldi	r24, 0x05	; 5
     fd0:	95 e0       	ldi	r25, 0x05	; 5
     fd2:	0e 94 13 01 	call	0x226	; 0x226 <vListInsertEnd>

			/* Increment the ucTasksDeleted variable so the idle task knows
			there is a task that has been deleted and that it should therefore
			check the xTasksWaitingTermination list. */
			++uxTasksDeleted;
     fd6:	80 91 04 05 	lds	r24, 0x0504
     fda:	8f 5f       	subi	r24, 0xFF	; 255
     fdc:	80 93 04 05 	sts	0x0504, r24

			/* Increment the uxTaskNumberVariable also so kernel aware debuggers
			can detect that the task lists need re-generating. */
			uxTaskNumber++;
     fe0:	80 91 fb 04 	lds	r24, 0x04FB
     fe4:	8f 5f       	subi	r24, 0xFF	; 255
     fe6:	80 93 fb 04 	sts	0x04FB, r24

			traceTASK_DELETE( pxTCB );
		}
		taskEXIT_CRITICAL();
     fea:	0f 90       	pop	r0
     fec:	0f be       	out	0x3f, r0	; 63

		/* Force a reschedule if it is the currently running task that has just
		been deleted. */
		if( xSchedulerRunning != pdFALSE )
     fee:	80 91 ff 04 	lds	r24, 0x04FF
     ff2:	88 23       	and	r24, r24
     ff4:	89 f0       	breq	.+34     	; 0x1018 <vTaskDelete+0x84>
		{
			if( pxTCB == pxCurrentTCB )
     ff6:	80 91 f6 04 	lds	r24, 0x04F6
     ffa:	90 91 f7 04 	lds	r25, 0x04F7
     ffe:	c8 17       	cp	r28, r24
    1000:	d9 07       	cpc	r29, r25
    1002:	19 f4       	brne	.+6      	; 0x100a <vTaskDelete+0x76>
				in which Windows specific clean up operations are performed,
				after which it is not possible to yield away from this task -
				hence xYieldPending is used to latch that a context switch is
				required. */
				portPRE_TASK_DELETE_HOOK( pxTCB, &xYieldPending );
				portYIELD_WITHIN_API();
    1004:	0e 94 36 02 	call	0x46c	; 0x46c <vPortYield>
    1008:	07 c0       	rjmp	.+14     	; 0x1018 <vTaskDelete+0x84>
			}
			else
			{
				/* Reset the next expected unblock time in case it referred to
				the task that has just been deleted. */
				taskENTER_CRITICAL();
    100a:	0f b6       	in	r0, 0x3f	; 63
    100c:	f8 94       	cli
    100e:	0f 92       	push	r0
				{
					prvResetNextTaskUnblockTime();
    1010:	0e 94 6b 06 	call	0xcd6	; 0xcd6 <prvResetNextTaskUnblockTime>
				}
				taskEXIT_CRITICAL();
    1014:	0f 90       	pop	r0
    1016:	0f be       	out	0x3f, r0	; 63
			}
		}
	}
    1018:	df 91       	pop	r29
    101a:	cf 91       	pop	r28
    101c:	1f 91       	pop	r17
    101e:	0f 91       	pop	r16
    1020:	08 95       	ret

00001022 <vTaskStartScheduler>:

#endif /* ( ( INCLUDE_xTaskResumeFromISR == 1 ) && ( INCLUDE_vTaskSuspend == 1 ) ) */
/*-----------------------------------------------------------*/

void vTaskStartScheduler( void )
{
    1022:	af 92       	push	r10
    1024:	bf 92       	push	r11
    1026:	cf 92       	push	r12
    1028:	df 92       	push	r13
    102a:	ef 92       	push	r14
    102c:	ff 92       	push	r15
    102e:	0f 93       	push	r16
		xReturn = xTaskCreate( prvIdleTask, "IDLE", tskIDLE_STACK_SIZE, ( void * ) NULL, ( tskIDLE_PRIORITY | portPRIVILEGE_BIT ), &xIdleTaskHandle ); /*lint !e961 MISRA exception, justified as it is not a redundant explicit cast to all supported compilers. */
	}
	#else
	{
		/* Create the idle task without storing its handle. */
		xReturn = xTaskCreate( prvIdleTask, "IDLE", tskIDLE_STACK_SIZE, ( void * ) NULL, ( tskIDLE_PRIORITY | portPRIVILEGE_BIT ), NULL );  /*lint !e961 MISRA exception, justified as it is not a redundant explicit cast to all supported compilers. */
    1030:	a1 2c       	mov	r10, r1
    1032:	b1 2c       	mov	r11, r1
    1034:	c1 2c       	mov	r12, r1
    1036:	d1 2c       	mov	r13, r1
    1038:	e1 2c       	mov	r14, r1
    103a:	f1 2c       	mov	r15, r1
    103c:	00 e0       	ldi	r16, 0x00	; 0
    103e:	20 e0       	ldi	r18, 0x00	; 0
    1040:	30 e0       	ldi	r19, 0x00	; 0
    1042:	45 e5       	ldi	r20, 0x55	; 85
    1044:	50 e0       	ldi	r21, 0x00	; 0
    1046:	64 e0       	ldi	r22, 0x04	; 4
    1048:	71 e0       	ldi	r23, 0x01	; 1
    104a:	85 e0       	ldi	r24, 0x05	; 5
    104c:	9a e0       	ldi	r25, 0x0A	; 10
    104e:	0e 94 c1 06 	call	0xd82	; 0xd82 <xTaskGenericCreate>
			mtCOVERAGE_TEST_MARKER();
		}
	}
	#endif /* configUSE_TIMERS */

	if( xReturn == pdPASS )
    1052:	81 30       	cpi	r24, 0x01	; 1
    1054:	81 f4       	brne	.+32     	; 0x1076 <vTaskStartScheduler+0x54>
		/* Interrupts are turned off here, to ensure a tick does not occur
		before or during the call to xPortStartScheduler().  The stacks of
		the created tasks contain a status word with interrupts switched on
		so interrupts will automatically get re-enabled when the first task
		starts to run. */
		portDISABLE_INTERRUPTS();
    1056:	f8 94       	cli
			structure specific to the task that will run first. */
			_impure_ptr = &( pxCurrentTCB->xNewLib_reent );
		}
		#endif /* configUSE_NEWLIB_REENTRANT */

		xNextTaskUnblockTime = portMAX_DELAY;
    1058:	8f ef       	ldi	r24, 0xFF	; 255
    105a:	9f ef       	ldi	r25, 0xFF	; 255
    105c:	90 93 fa 04 	sts	0x04FA, r25
    1060:	80 93 f9 04 	sts	0x04F9, r24
		xSchedulerRunning = pdTRUE;
    1064:	81 e0       	ldi	r24, 0x01	; 1
    1066:	80 93 ff 04 	sts	0x04FF, r24
		xTickCount = ( TickType_t ) 0U;
    106a:	10 92 02 05 	sts	0x0502, r1
    106e:	10 92 01 05 	sts	0x0501, r1
		the run time counter time base. */
		portCONFIGURE_TIMER_FOR_RUN_TIME_STATS();

		/* Setting up the timer tick is hardware specific and thus in the
		portable interface. */
		if( xPortStartScheduler() != pdFALSE )
    1072:	0e 94 f7 01 	call	0x3ee	; 0x3ee <xPortStartScheduler>
		/* This line will only be reached if the kernel could not be started,
		because there was not enough FreeRTOS heap to create the idle task
		or the timer task. */
		configASSERT( xReturn );
	}
}
    1076:	0f 91       	pop	r16
    1078:	ff 90       	pop	r15
    107a:	ef 90       	pop	r14
    107c:	df 90       	pop	r13
    107e:	cf 90       	pop	r12
    1080:	bf 90       	pop	r11
    1082:	af 90       	pop	r10
    1084:	08 95       	ret

00001086 <vTaskEndScheduler>:
void vTaskEndScheduler( void )
{
	/* Stop the scheduler interrupts and call the portable scheduler end
	routine so the original ISRs can be restored if necessary.  The port
	layer must ensure interrupts enable	bit is left in the correct state. */
	portDISABLE_INTERRUPTS();
    1086:	f8 94       	cli
	xSchedulerRunning = pdFALSE;
    1088:	10 92 ff 04 	sts	0x04FF, r1
	vPortEndScheduler();
    108c:	0e 94 35 02 	call	0x46a	; 0x46a <vPortEndScheduler>
    1090:	08 95       	ret

00001092 <vTaskSuspendAll>:
{
	/* A critical section is not required as the variable is of type
	BaseType_t.  Please read Richard Barry's reply in the following link to a
	post in the FreeRTOS support forum before reporting this as a bug! -
	http://goo.gl/wu4acr */
	++uxSchedulerSuspended;
    1092:	80 91 f8 04 	lds	r24, 0x04F8
    1096:	8f 5f       	subi	r24, 0xFF	; 255
    1098:	80 93 f8 04 	sts	0x04F8, r24
    109c:	08 95       	ret

0000109e <xTaskGetTickCount>:
TickType_t xTaskGetTickCount( void )
{
TickType_t xTicks;

	/* Critical section required if running on a 16 bit processor. */
	portTICK_TYPE_ENTER_CRITICAL();
    109e:	0f b6       	in	r0, 0x3f	; 63
    10a0:	f8 94       	cli
    10a2:	0f 92       	push	r0
	{
		xTicks = xTickCount;
    10a4:	80 91 01 05 	lds	r24, 0x0501
    10a8:	90 91 02 05 	lds	r25, 0x0502
	}
	portTICK_TYPE_EXIT_CRITICAL();
    10ac:	0f 90       	pop	r0
    10ae:	0f be       	out	0x3f, r0	; 63

	return xTicks;
}
    10b0:	08 95       	ret

000010b2 <xTaskGetTickCountFromISR>:
	link: http://www.freertos.org/RTOS-Cortex-M3-M4.html */
	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

	uxSavedInterruptStatus = portTICK_TYPE_SET_INTERRUPT_MASK_FROM_ISR();
	{
		xReturn = xTickCount;
    10b2:	80 91 01 05 	lds	r24, 0x0501
    10b6:	90 91 02 05 	lds	r25, 0x0502
	}
	portTICK_TYPE_CLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
    10ba:	08 95       	ret

000010bc <uxTaskGetNumberOfTasks>:

UBaseType_t uxTaskGetNumberOfTasks( void )
{
	/* A critical section is not required because the variables are of type
	BaseType_t. */
	return uxCurrentNumberOfTasks;
    10bc:	80 91 03 05 	lds	r24, 0x0503
}
    10c0:	08 95       	ret

000010c2 <xTaskIncrementTick>:

#endif /* configUSE_TICKLESS_IDLE */
/*----------------------------------------------------------*/

BaseType_t xTaskIncrementTick( void )
{
    10c2:	cf 92       	push	r12
    10c4:	df 92       	push	r13
    10c6:	ef 92       	push	r14
    10c8:	ff 92       	push	r15
    10ca:	0f 93       	push	r16
    10cc:	1f 93       	push	r17
    10ce:	cf 93       	push	r28
    10d0:	df 93       	push	r29

	/* Called by the portable layer each time a tick interrupt occurs.
	Increments the tick then checks to see if the new tick value will cause any
	tasks to be unblocked. */
	traceTASK_INCREMENT_TICK( xTickCount );
	if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    10d2:	80 91 f8 04 	lds	r24, 0x04F8
    10d6:	81 11       	cpse	r24, r1
    10d8:	9a c0       	rjmp	.+308    	; 0x120e <__stack+0x10f>
	{
		/* Increment the RTOS tick, switching the delayed and overflowed
		delayed lists if it wraps to 0. */
		++xTickCount;
    10da:	80 91 01 05 	lds	r24, 0x0501
    10de:	90 91 02 05 	lds	r25, 0x0502
    10e2:	01 96       	adiw	r24, 0x01	; 1
    10e4:	90 93 02 05 	sts	0x0502, r25
    10e8:	80 93 01 05 	sts	0x0501, r24

		{
			/* Minor optimisation.  The tick count cannot change in this
			block. */
			const TickType_t xConstTickCount = xTickCount;
    10ec:	e0 90 01 05 	lds	r14, 0x0501
    10f0:	f0 90 02 05 	lds	r15, 0x0502

			if( xConstTickCount == ( TickType_t ) 0U )
    10f4:	e1 14       	cp	r14, r1
    10f6:	f1 04       	cpc	r15, r1
    10f8:	b9 f4       	brne	.+46     	; 0x1128 <__stack+0x29>
			{
				taskSWITCH_DELAYED_LISTS();
    10fa:	80 91 19 05 	lds	r24, 0x0519
    10fe:	90 91 1a 05 	lds	r25, 0x051A
    1102:	20 91 17 05 	lds	r18, 0x0517
    1106:	30 91 18 05 	lds	r19, 0x0518
    110a:	30 93 1a 05 	sts	0x051A, r19
    110e:	20 93 19 05 	sts	0x0519, r18
    1112:	90 93 18 05 	sts	0x0518, r25
    1116:	80 93 17 05 	sts	0x0517, r24
    111a:	80 91 fc 04 	lds	r24, 0x04FC
    111e:	8f 5f       	subi	r24, 0xFF	; 255
    1120:	80 93 fc 04 	sts	0x04FC, r24
    1124:	0e 94 6b 06 	call	0xcd6	; 0xcd6 <prvResetNextTaskUnblockTime>

			/* See if this tick has made a timeout expire.  Tasks are stored in
			the	queue in the order of their wake time - meaning once one task
			has been found whose block time has not expired there is no need to
			look any further down the list. */
			if( xConstTickCount >= xNextTaskUnblockTime )
    1128:	80 91 f9 04 	lds	r24, 0x04F9
    112c:	90 91 fa 04 	lds	r25, 0x04FA
    1130:	e8 16       	cp	r14, r24
    1132:	f9 06       	cpc	r15, r25
    1134:	08 f4       	brcc	.+2      	; 0x1138 <__stack+0x39>
    1136:	54 c0       	rjmp	.+168    	; 0x11e0 <__stack+0xe1>
    1138:	d1 2c       	mov	r13, r1
							only be performed if the unblocked task has a
							priority that is equal to or higher than the
							currently executing task. */
							if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
							{
								xSwitchRequired = pdTRUE;
    113a:	cc 24       	eor	r12, r12
    113c:	c3 94       	inc	r12
    113e:	01 c0       	rjmp	.+2      	; 0x1142 <__stack+0x43>
    1140:	dc 2c       	mov	r13, r12
			look any further down the list. */
			if( xConstTickCount >= xNextTaskUnblockTime )
			{
				for( ;; )
				{
					if( listLIST_IS_EMPTY( pxDelayedTaskList ) != pdFALSE )
    1142:	e0 91 19 05 	lds	r30, 0x0519
    1146:	f0 91 1a 05 	lds	r31, 0x051A
    114a:	80 81       	ld	r24, Z
    114c:	81 11       	cpse	r24, r1
    114e:	07 c0       	rjmp	.+14     	; 0x115e <__stack+0x5f>
						/* The delayed list is empty.  Set xNextTaskUnblockTime
						to the maximum possible value so it is extremely
						unlikely that the
						if( xTickCount >= xNextTaskUnblockTime ) test will pass
						next time through. */
						xNextTaskUnblockTime = portMAX_DELAY;
    1150:	8f ef       	ldi	r24, 0xFF	; 255
    1152:	9f ef       	ldi	r25, 0xFF	; 255
    1154:	90 93 fa 04 	sts	0x04FA, r25
    1158:	80 93 f9 04 	sts	0x04F9, r24
						break;
    115c:	42 c0       	rjmp	.+132    	; 0x11e2 <__stack+0xe3>
					{
						/* The delayed list is not empty, get the value of the
						item at the head of the delayed list.  This is the time
						at which the task at the head of the delayed list must
						be removed from the Blocked state. */
						pxTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxDelayedTaskList );
    115e:	e0 91 19 05 	lds	r30, 0x0519
    1162:	f0 91 1a 05 	lds	r31, 0x051A
    1166:	05 80       	ldd	r0, Z+5	; 0x05
    1168:	f6 81       	ldd	r31, Z+6	; 0x06
    116a:	e0 2d       	mov	r30, r0
    116c:	c6 81       	ldd	r28, Z+6	; 0x06
    116e:	d7 81       	ldd	r29, Z+7	; 0x07
						xItemValue = listGET_LIST_ITEM_VALUE( &( pxTCB->xGenericListItem ) );
    1170:	2a 81       	ldd	r18, Y+2	; 0x02
    1172:	3b 81       	ldd	r19, Y+3	; 0x03

						if( xConstTickCount < xItemValue )
    1174:	e2 16       	cp	r14, r18
    1176:	f3 06       	cpc	r15, r19
    1178:	28 f4       	brcc	.+10     	; 0x1184 <__stack+0x85>
							/* It is not time to unblock this item yet, but the
							item value is the time at which the task at the head
							of the blocked list must be removed from the Blocked
							state -	so record the item value in
							xNextTaskUnblockTime. */
							xNextTaskUnblockTime = xItemValue;
    117a:	30 93 fa 04 	sts	0x04FA, r19
    117e:	20 93 f9 04 	sts	0x04F9, r18
							break;
    1182:	2f c0       	rjmp	.+94     	; 0x11e2 <__stack+0xe3>
						{
							mtCOVERAGE_TEST_MARKER();
						}

						/* It is time to remove the item from the Blocked state. */
						( void ) uxListRemove( &( pxTCB->xGenericListItem ) );
    1184:	8e 01       	movw	r16, r28
    1186:	0e 5f       	subi	r16, 0xFE	; 254
    1188:	1f 4f       	sbci	r17, 0xFF	; 255
    118a:	c8 01       	movw	r24, r16
    118c:	0e 94 65 01 	call	0x2ca	; 0x2ca <uxListRemove>

						/* Is the task waiting on an event also?  If so remove
						it from the event list. */
						if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
    1190:	8c 89       	ldd	r24, Y+20	; 0x14
    1192:	9d 89       	ldd	r25, Y+21	; 0x15
    1194:	89 2b       	or	r24, r25
    1196:	21 f0       	breq	.+8      	; 0x11a0 <__stack+0xa1>
						{
							( void ) uxListRemove( &( pxTCB->xEventListItem ) );
    1198:	ce 01       	movw	r24, r28
    119a:	0c 96       	adiw	r24, 0x0c	; 12
    119c:	0e 94 65 01 	call	0x2ca	; 0x2ca <uxListRemove>
							mtCOVERAGE_TEST_MARKER();
						}

						/* Place the unblocked task into the appropriate ready
						list. */
						prvAddTaskToReadyList( pxTCB );
    11a0:	2e 89       	ldd	r18, Y+22	; 0x16
    11a2:	80 91 00 05 	lds	r24, 0x0500
    11a6:	82 17       	cp	r24, r18
    11a8:	10 f4       	brcc	.+4      	; 0x11ae <__stack+0xaf>
    11aa:	20 93 00 05 	sts	0x0500, r18
    11ae:	30 e0       	ldi	r19, 0x00	; 0
    11b0:	c9 01       	movw	r24, r18
    11b2:	88 0f       	add	r24, r24
    11b4:	99 1f       	adc	r25, r25
    11b6:	88 0f       	add	r24, r24
    11b8:	99 1f       	adc	r25, r25
    11ba:	88 0f       	add	r24, r24
    11bc:	99 1f       	adc	r25, r25
    11be:	82 0f       	add	r24, r18
    11c0:	93 1f       	adc	r25, r19
    11c2:	b8 01       	movw	r22, r16
    11c4:	83 5d       	subi	r24, 0xD3	; 211
    11c6:	9a 4f       	sbci	r25, 0xFA	; 250
    11c8:	0e 94 13 01 	call	0x226	; 0x226 <vListInsertEnd>
						{
							/* Preemption is on, but a context switch should
							only be performed if the unblocked task has a
							priority that is equal to or higher than the
							currently executing task. */
							if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
    11cc:	e0 91 f6 04 	lds	r30, 0x04F6
    11d0:	f0 91 f7 04 	lds	r31, 0x04F7
    11d4:	9e 89       	ldd	r25, Y+22	; 0x16
    11d6:	86 89       	ldd	r24, Z+22	; 0x16
    11d8:	98 17       	cp	r25, r24
    11da:	08 f0       	brcs	.+2      	; 0x11de <__stack+0xdf>
    11dc:	b1 cf       	rjmp	.-158    	; 0x1140 <__stack+0x41>
    11de:	b1 cf       	rjmp	.-158    	; 0x1142 <__stack+0x43>

BaseType_t xTaskIncrementTick( void )
{
TCB_t * pxTCB;
TickType_t xItemValue;
BaseType_t xSwitchRequired = pdFALSE;
    11e0:	d1 2c       	mov	r13, r1
		/* Tasks of equal priority to the currently running task will share
		processing time (time slice) if preemption is on, and the application
		writer has not explicitly turned time slicing off. */
		#if ( ( configUSE_PREEMPTION == 1 ) && ( configUSE_TIME_SLICING == 1 ) )
		{
			if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ pxCurrentTCB->uxPriority ] ) ) > ( UBaseType_t ) 1 )
    11e2:	e0 91 f6 04 	lds	r30, 0x04F6
    11e6:	f0 91 f7 04 	lds	r31, 0x04F7
    11ea:	86 89       	ldd	r24, Z+22	; 0x16
    11ec:	90 e0       	ldi	r25, 0x00	; 0
    11ee:	fc 01       	movw	r30, r24
    11f0:	ee 0f       	add	r30, r30
    11f2:	ff 1f       	adc	r31, r31
    11f4:	ee 0f       	add	r30, r30
    11f6:	ff 1f       	adc	r31, r31
    11f8:	ee 0f       	add	r30, r30
    11fa:	ff 1f       	adc	r31, r31
    11fc:	8e 0f       	add	r24, r30
    11fe:	9f 1f       	adc	r25, r31
    1200:	fc 01       	movw	r30, r24
    1202:	e3 5d       	subi	r30, 0xD3	; 211
    1204:	fa 4f       	sbci	r31, 0xFA	; 250
    1206:	80 81       	ld	r24, Z
    1208:	82 30       	cpi	r24, 0x02	; 2
    120a:	40 f4       	brcc	.+16     	; 0x121c <__stack+0x11d>
    120c:	09 c0       	rjmp	.+18     	; 0x1220 <__stack+0x121>
		}
		#endif /* configUSE_TICK_HOOK */
	}
	else
	{
		++uxPendedTicks;
    120e:	80 91 fe 04 	lds	r24, 0x04FE
    1212:	8f 5f       	subi	r24, 0xFF	; 255
    1214:	80 93 fe 04 	sts	0x04FE, r24

BaseType_t xTaskIncrementTick( void )
{
TCB_t * pxTCB;
TickType_t xItemValue;
BaseType_t xSwitchRequired = pdFALSE;
    1218:	d1 2c       	mov	r13, r1
    121a:	02 c0       	rjmp	.+4      	; 0x1220 <__stack+0x121>
		writer has not explicitly turned time slicing off. */
		#if ( ( configUSE_PREEMPTION == 1 ) && ( configUSE_TIME_SLICING == 1 ) )
		{
			if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ pxCurrentTCB->uxPriority ] ) ) > ( UBaseType_t ) 1 )
			{
				xSwitchRequired = pdTRUE;
    121c:	dd 24       	eor	r13, r13
    121e:	d3 94       	inc	r13
		#endif
	}

	#if ( configUSE_PREEMPTION == 1 )
	{
		if( xYieldPending != pdFALSE )
    1220:	80 91 fd 04 	lds	r24, 0x04FD
    1224:	88 23       	and	r24, r24
    1226:	11 f0       	breq	.+4      	; 0x122c <__stack+0x12d>
		{
			xSwitchRequired = pdTRUE;
    1228:	dd 24       	eor	r13, r13
    122a:	d3 94       	inc	r13
		}
	}
	#endif /* configUSE_PREEMPTION */

	return xSwitchRequired;
}
    122c:	8d 2d       	mov	r24, r13
    122e:	df 91       	pop	r29
    1230:	cf 91       	pop	r28
    1232:	1f 91       	pop	r17
    1234:	0f 91       	pop	r16
    1236:	ff 90       	pop	r15
    1238:	ef 90       	pop	r14
    123a:	df 90       	pop	r13
    123c:	cf 90       	pop	r12
    123e:	08 95       	ret

00001240 <xTaskResumeAll>:

#endif /* configUSE_TICKLESS_IDLE */
/*----------------------------------------------------------*/

BaseType_t xTaskResumeAll( void )
{
    1240:	df 92       	push	r13
    1242:	ef 92       	push	r14
    1244:	ff 92       	push	r15
    1246:	0f 93       	push	r16
    1248:	1f 93       	push	r17
    124a:	cf 93       	push	r28
    124c:	df 93       	push	r29
	/* It is possible that an ISR caused a task to be removed from an event
	list while the scheduler was suspended.  If this was the case then the
	removed task will have been added to the xPendingReadyList.  Once the
	scheduler has been resumed it is safe to move all the pending ready
	tasks from this list into their appropriate ready list. */
	taskENTER_CRITICAL();
    124e:	0f b6       	in	r0, 0x3f	; 63
    1250:	f8 94       	cli
    1252:	0f 92       	push	r0
	{
		--uxSchedulerSuspended;
    1254:	80 91 f8 04 	lds	r24, 0x04F8
    1258:	81 50       	subi	r24, 0x01	; 1
    125a:	80 93 f8 04 	sts	0x04F8, r24

		if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    125e:	80 91 f8 04 	lds	r24, 0x04F8
    1262:	81 11       	cpse	r24, r1
    1264:	61 c0       	rjmp	.+194    	; 0x1328 <xTaskResumeAll+0xe8>
		{
			if( uxCurrentNumberOfTasks > ( UBaseType_t ) 0U )
    1266:	80 91 03 05 	lds	r24, 0x0503
    126a:	88 23       	and	r24, r24
    126c:	09 f4       	brne	.+2      	; 0x1270 <xTaskResumeAll+0x30>
    126e:	5e c0       	rjmp	.+188    	; 0x132c <xTaskResumeAll+0xec>
			{
				/* Move any readied tasks from the pending list into the
				appropriate ready list. */
				while( listLIST_IS_EMPTY( &xPendingReadyList ) == pdFALSE )
    1270:	0f 2e       	mov	r0, r31
    1272:	fe e0       	ldi	r31, 0x0E	; 14
    1274:	ef 2e       	mov	r14, r31
    1276:	f5 e0       	ldi	r31, 0x05	; 5
    1278:	ff 2e       	mov	r15, r31
    127a:	f0 2d       	mov	r31, r0

					/* If the moved task has a priority higher than the current
					task then a yield must be performed. */
					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
					{
						xYieldPending = pdTRUE;
    127c:	dd 24       	eor	r13, r13
    127e:	d3 94       	inc	r13
    1280:	30 c0       	rjmp	.+96     	; 0x12e2 <xTaskResumeAll+0xa2>
			{
				/* Move any readied tasks from the pending list into the
				appropriate ready list. */
				while( listLIST_IS_EMPTY( &xPendingReadyList ) == pdFALSE )
				{
					pxTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( ( &xPendingReadyList ) );
    1282:	e0 91 13 05 	lds	r30, 0x0513
    1286:	f0 91 14 05 	lds	r31, 0x0514
    128a:	c6 81       	ldd	r28, Z+6	; 0x06
    128c:	d7 81       	ldd	r29, Z+7	; 0x07
					( void ) uxListRemove( &( pxTCB->xEventListItem ) );
    128e:	ce 01       	movw	r24, r28
    1290:	0c 96       	adiw	r24, 0x0c	; 12
    1292:	0e 94 65 01 	call	0x2ca	; 0x2ca <uxListRemove>
					( void ) uxListRemove( &( pxTCB->xGenericListItem ) );
    1296:	8e 01       	movw	r16, r28
    1298:	0e 5f       	subi	r16, 0xFE	; 254
    129a:	1f 4f       	sbci	r17, 0xFF	; 255
    129c:	c8 01       	movw	r24, r16
    129e:	0e 94 65 01 	call	0x2ca	; 0x2ca <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    12a2:	8e 89       	ldd	r24, Y+22	; 0x16
    12a4:	90 91 00 05 	lds	r25, 0x0500
    12a8:	98 17       	cp	r25, r24
    12aa:	10 f4       	brcc	.+4      	; 0x12b0 <xTaskResumeAll+0x70>
    12ac:	80 93 00 05 	sts	0x0500, r24
    12b0:	90 e0       	ldi	r25, 0x00	; 0
    12b2:	9c 01       	movw	r18, r24
    12b4:	22 0f       	add	r18, r18
    12b6:	33 1f       	adc	r19, r19
    12b8:	22 0f       	add	r18, r18
    12ba:	33 1f       	adc	r19, r19
    12bc:	22 0f       	add	r18, r18
    12be:	33 1f       	adc	r19, r19
    12c0:	82 0f       	add	r24, r18
    12c2:	93 1f       	adc	r25, r19
    12c4:	b8 01       	movw	r22, r16
    12c6:	83 5d       	subi	r24, 0xD3	; 211
    12c8:	9a 4f       	sbci	r25, 0xFA	; 250
    12ca:	0e 94 13 01 	call	0x226	; 0x226 <vListInsertEnd>

					/* If the moved task has a priority higher than the current
					task then a yield must be performed. */
					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
    12ce:	e0 91 f6 04 	lds	r30, 0x04F6
    12d2:	f0 91 f7 04 	lds	r31, 0x04F7
    12d6:	9e 89       	ldd	r25, Y+22	; 0x16
    12d8:	86 89       	ldd	r24, Z+22	; 0x16
    12da:	98 17       	cp	r25, r24
    12dc:	10 f0       	brcs	.+4      	; 0x12e2 <xTaskResumeAll+0xa2>
					{
						xYieldPending = pdTRUE;
    12de:	d0 92 fd 04 	sts	0x04FD, r13
		{
			if( uxCurrentNumberOfTasks > ( UBaseType_t ) 0U )
			{
				/* Move any readied tasks from the pending list into the
				appropriate ready list. */
				while( listLIST_IS_EMPTY( &xPendingReadyList ) == pdFALSE )
    12e2:	f7 01       	movw	r30, r14
    12e4:	80 81       	ld	r24, Z
    12e6:	81 11       	cpse	r24, r1
    12e8:	cc cf       	rjmp	.-104    	; 0x1282 <xTaskResumeAll+0x42>

				/* If any ticks occurred while the scheduler was suspended then
				they should be processed now.  This ensures the tick count does
				not	slip, and that any delayed tasks are resumed at the correct
				time. */
				if( uxPendedTicks > ( UBaseType_t ) 0U )
    12ea:	80 91 fe 04 	lds	r24, 0x04FE
    12ee:	88 23       	and	r24, r24
    12f0:	99 f0       	breq	.+38     	; 0x1318 <xTaskResumeAll+0xd8>
				{
					while( uxPendedTicks > ( UBaseType_t ) 0U )
    12f2:	80 91 fe 04 	lds	r24, 0x04FE
    12f6:	88 23       	and	r24, r24
    12f8:	79 f0       	breq	.+30     	; 0x1318 <xTaskResumeAll+0xd8>
					{
						if( xTaskIncrementTick() != pdFALSE )
						{
							xYieldPending = pdTRUE;
    12fa:	c1 e0       	ldi	r28, 0x01	; 1
				time. */
				if( uxPendedTicks > ( UBaseType_t ) 0U )
				{
					while( uxPendedTicks > ( UBaseType_t ) 0U )
					{
						if( xTaskIncrementTick() != pdFALSE )
    12fc:	0e 94 61 08 	call	0x10c2	; 0x10c2 <xTaskIncrementTick>
    1300:	81 11       	cpse	r24, r1
						{
							xYieldPending = pdTRUE;
    1302:	c0 93 fd 04 	sts	0x04FD, r28
						}
						else
						{
							mtCOVERAGE_TEST_MARKER();
						}
						--uxPendedTicks;
    1306:	80 91 fe 04 	lds	r24, 0x04FE
    130a:	81 50       	subi	r24, 0x01	; 1
    130c:	80 93 fe 04 	sts	0x04FE, r24
				they should be processed now.  This ensures the tick count does
				not	slip, and that any delayed tasks are resumed at the correct
				time. */
				if( uxPendedTicks > ( UBaseType_t ) 0U )
				{
					while( uxPendedTicks > ( UBaseType_t ) 0U )
    1310:	80 91 fe 04 	lds	r24, 0x04FE
    1314:	81 11       	cpse	r24, r1
    1316:	f2 cf       	rjmp	.-28     	; 0x12fc <xTaskResumeAll+0xbc>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}

				if( xYieldPending == pdTRUE )
    1318:	80 91 fd 04 	lds	r24, 0x04FD
    131c:	81 30       	cpi	r24, 0x01	; 1
    131e:	41 f4       	brne	.+16     	; 0x1330 <xTaskResumeAll+0xf0>
					#if( configUSE_PREEMPTION != 0 )
					{
						xAlreadyYielded = pdTRUE;
					}
					#endif
					taskYIELD_IF_USING_PREEMPTION();
    1320:	0e 94 36 02 	call	0x46c	; 0x46c <vPortYield>

				if( xYieldPending == pdTRUE )
				{
					#if( configUSE_PREEMPTION != 0 )
					{
						xAlreadyYielded = pdTRUE;
    1324:	81 e0       	ldi	r24, 0x01	; 1
    1326:	05 c0       	rjmp	.+10     	; 0x1332 <xTaskResumeAll+0xf2>
/*----------------------------------------------------------*/

BaseType_t xTaskResumeAll( void )
{
TCB_t *pxTCB;
BaseType_t xAlreadyYielded = pdFALSE;
    1328:	80 e0       	ldi	r24, 0x00	; 0
    132a:	03 c0       	rjmp	.+6      	; 0x1332 <xTaskResumeAll+0xf2>
    132c:	80 e0       	ldi	r24, 0x00	; 0
    132e:	01 c0       	rjmp	.+2      	; 0x1332 <xTaskResumeAll+0xf2>
    1330:	80 e0       	ldi	r24, 0x00	; 0
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
	taskEXIT_CRITICAL();
    1332:	0f 90       	pop	r0
    1334:	0f be       	out	0x3f, r0	; 63

	return xAlreadyYielded;
}
    1336:	df 91       	pop	r29
    1338:	cf 91       	pop	r28
    133a:	1f 91       	pop	r17
    133c:	0f 91       	pop	r16
    133e:	ff 90       	pop	r15
    1340:	ef 90       	pop	r14
    1342:	df 90       	pop	r13
    1344:	08 95       	ret

00001346 <vTaskDelayUntil>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskDelayUntil == 1 )

	void vTaskDelayUntil( TickType_t * const pxPreviousWakeTime, const TickType_t xTimeIncrement )
	{
    1346:	0f 93       	push	r16
    1348:	1f 93       	push	r17
    134a:	cf 93       	push	r28
    134c:	df 93       	push	r29
    134e:	8c 01       	movw	r16, r24
    1350:	eb 01       	movw	r28, r22

		configASSERT( pxPreviousWakeTime );
		configASSERT( ( xTimeIncrement > 0U ) );
		configASSERT( uxSchedulerSuspended == 0 );

		vTaskSuspendAll();
    1352:	0e 94 49 08 	call	0x1092	; 0x1092 <vTaskSuspendAll>
		{
			/* Minor optimisation.  The tick count cannot change in this
			block. */
			const TickType_t xConstTickCount = xTickCount;
    1356:	80 91 01 05 	lds	r24, 0x0501
    135a:	90 91 02 05 	lds	r25, 0x0502

			/* Generate the tick time at which the task wants to wake. */
			xTimeToWake = *pxPreviousWakeTime + xTimeIncrement;
    135e:	f8 01       	movw	r30, r16
    1360:	20 81       	ld	r18, Z
    1362:	31 81       	ldd	r19, Z+1	; 0x01
    1364:	c2 0f       	add	r28, r18
    1366:	d3 1f       	adc	r29, r19

			if( xConstTickCount < *pxPreviousWakeTime )
    1368:	82 17       	cp	r24, r18
    136a:	93 07       	cpc	r25, r19
    136c:	48 f4       	brcc	.+18     	; 0x1380 <vTaskDelayUntil+0x3a>
				/* The tick count has overflowed since this function was
				lasted called.  In this case the only time we should ever
				actually delay is if the wake time has also	overflowed,
				and the wake time is greater than the tick time.  When this
				is the case it is as if neither time had overflowed. */
				if( ( xTimeToWake < *pxPreviousWakeTime ) && ( xTimeToWake > xConstTickCount ) )
    136e:	c2 17       	cp	r28, r18
    1370:	d3 07       	cpc	r29, r19
    1372:	10 f5       	brcc	.+68     	; 0x13b8 <vTaskDelayUntil+0x72>
					mtCOVERAGE_TEST_MARKER();
				}
			}

			/* Update the wake time ready for the next call. */
			*pxPreviousWakeTime = xTimeToWake;
    1374:	d1 83       	std	Z+1, r29	; 0x01
    1376:	c0 83       	st	Z, r28

			if( xShouldDelay != pdFALSE )
    1378:	8c 17       	cp	r24, r28
    137a:	9d 07       	cpc	r25, r29
    137c:	90 f4       	brcc	.+36     	; 0x13a2 <vTaskDelayUntil+0x5c>
    137e:	07 c0       	rjmp	.+14     	; 0x138e <vTaskDelayUntil+0x48>
			else
			{
				/* The tick time has not overflowed.  In this case we will
				delay if either the wake time has overflowed, and/or the
				tick time is less than the wake time. */
				if( ( xTimeToWake < *pxPreviousWakeTime ) || ( xTimeToWake > xConstTickCount ) )
    1380:	c2 17       	cp	r28, r18
    1382:	d3 07       	cpc	r29, r19
    1384:	a8 f0       	brcs	.+42     	; 0x13b0 <vTaskDelayUntil+0x6a>
    1386:	8c 17       	cp	r24, r28
    1388:	9d 07       	cpc	r25, r29
    138a:	90 f0       	brcs	.+36     	; 0x13b0 <vTaskDelayUntil+0x6a>
    138c:	15 c0       	rjmp	.+42     	; 0x13b8 <vTaskDelayUntil+0x72>
			{
				traceTASK_DELAY_UNTIL();

				/* Remove the task from the ready list before adding it to the
				blocked list as the same list item is used for both lists. */
				if( uxListRemove( &( pxCurrentTCB->xGenericListItem ) ) == ( UBaseType_t ) 0 )
    138e:	80 91 f6 04 	lds	r24, 0x04F6
    1392:	90 91 f7 04 	lds	r25, 0x04F7
    1396:	02 96       	adiw	r24, 0x02	; 2
    1398:	0e 94 65 01 	call	0x2ca	; 0x2ca <uxListRemove>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}

				prvAddCurrentTaskToDelayedList( xTimeToWake );
    139c:	ce 01       	movw	r24, r28
    139e:	0e 94 8a 06 	call	0xd14	; 0xd14 <prvAddCurrentTaskToDelayedList>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		xAlreadyYielded = xTaskResumeAll();
    13a2:	0e 94 20 09 	call	0x1240	; 0x1240 <xTaskResumeAll>

		/* Force a reschedule if xTaskResumeAll has not already done so, we may
		have put ourselves to sleep. */
		if( xAlreadyYielded == pdFALSE )
    13a6:	81 11       	cpse	r24, r1
    13a8:	0b c0       	rjmp	.+22     	; 0x13c0 <vTaskDelayUntil+0x7a>
		{
			portYIELD_WITHIN_API();
    13aa:	0e 94 36 02 	call	0x46c	; 0x46c <vPortYield>
    13ae:	08 c0       	rjmp	.+16     	; 0x13c0 <vTaskDelayUntil+0x7a>
					mtCOVERAGE_TEST_MARKER();
				}
			}

			/* Update the wake time ready for the next call. */
			*pxPreviousWakeTime = xTimeToWake;
    13b0:	f8 01       	movw	r30, r16
    13b2:	d1 83       	std	Z+1, r29	; 0x01
    13b4:	c0 83       	st	Z, r28
    13b6:	eb cf       	rjmp	.-42     	; 0x138e <vTaskDelayUntil+0x48>
    13b8:	f8 01       	movw	r30, r16
    13ba:	d1 83       	std	Z+1, r29	; 0x01
    13bc:	c0 83       	st	Z, r28
    13be:	f1 cf       	rjmp	.-30     	; 0x13a2 <vTaskDelayUntil+0x5c>
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
    13c0:	df 91       	pop	r29
    13c2:	cf 91       	pop	r28
    13c4:	1f 91       	pop	r17
    13c6:	0f 91       	pop	r16
    13c8:	08 95       	ret

000013ca <vTaskDelay>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskDelay == 1 )

	void vTaskDelay( const TickType_t xTicksToDelay )
	{
    13ca:	cf 93       	push	r28
    13cc:	df 93       	push	r29
    13ce:	ec 01       	movw	r28, r24
	TickType_t xTimeToWake;
	BaseType_t xAlreadyYielded = pdFALSE;


		/* A delay time of zero just forces a reschedule. */
		if( xTicksToDelay > ( TickType_t ) 0U )
    13d0:	00 97       	sbiw	r24, 0x00	; 0
    13d2:	b1 f0       	breq	.+44     	; 0x1400 <vTaskDelay+0x36>
		{
			configASSERT( uxSchedulerSuspended == 0 );
			vTaskSuspendAll();
    13d4:	0e 94 49 08 	call	0x1092	; 0x1092 <vTaskSuspendAll>
				This task cannot be in an event list as it is the currently
				executing task. */

				/* Calculate the time to wake - this may overflow but this is
				not a problem. */
				xTimeToWake = xTickCount + xTicksToDelay;
    13d8:	80 91 01 05 	lds	r24, 0x0501
    13dc:	90 91 02 05 	lds	r25, 0x0502
    13e0:	c8 0f       	add	r28, r24
    13e2:	d9 1f       	adc	r29, r25

				/* We must remove ourselves from the ready list before adding
				ourselves to the blocked list as the same list item is used for
				both lists. */
				if( uxListRemove( &( pxCurrentTCB->xGenericListItem ) ) == ( UBaseType_t ) 0 )
    13e4:	80 91 f6 04 	lds	r24, 0x04F6
    13e8:	90 91 f7 04 	lds	r25, 0x04F7
    13ec:	02 96       	adiw	r24, 0x02	; 2
    13ee:	0e 94 65 01 	call	0x2ca	; 0x2ca <uxListRemove>
				}
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}
				prvAddCurrentTaskToDelayedList( xTimeToWake );
    13f2:	ce 01       	movw	r24, r28
    13f4:	0e 94 8a 06 	call	0xd14	; 0xd14 <prvAddCurrentTaskToDelayedList>
			}
			xAlreadyYielded = xTaskResumeAll();
    13f8:	0e 94 20 09 	call	0x1240	; 0x1240 <xTaskResumeAll>
			mtCOVERAGE_TEST_MARKER();
		}

		/* Force a reschedule if xTaskResumeAll has not already done so, we may
		have put ourselves to sleep. */
		if( xAlreadyYielded == pdFALSE )
    13fc:	81 11       	cpse	r24, r1
    13fe:	02 c0       	rjmp	.+4      	; 0x1404 <vTaskDelay+0x3a>
		{
			portYIELD_WITHIN_API();
    1400:	0e 94 36 02 	call	0x46c	; 0x46c <vPortYield>
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
    1404:	df 91       	pop	r29
    1406:	cf 91       	pop	r28
    1408:	08 95       	ret

0000140a <prvIdleTask>:

			A critical region is not required here as we are just reading from
			the list, and an occasional incorrect value will not matter.  If
			the ready list at the idle priority contains more than one task
			then a task other than the idle task is ready to execute. */
			if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ tskIDLE_PRIORITY ] ) ) > ( UBaseType_t ) 1 )
    140a:	0f 2e       	mov	r0, r31
    140c:	fd e2       	ldi	r31, 0x2D	; 45
    140e:	ef 2e       	mov	r14, r31
    1410:	f5 e0       	ldi	r31, 0x05	; 5
    1412:	ff 2e       	mov	r15, r31
    1414:	f0 2d       	mov	r31, r0
		too often in the idle task. */
		while( uxTasksDeleted > ( UBaseType_t ) 0U )
		{
			vTaskSuspendAll();
			{
				xListIsEmpty = listLIST_IS_EMPTY( &xTasksWaitingTermination );
    1416:	c5 e0       	ldi	r28, 0x05	; 5
    1418:	d5 e0       	ldi	r29, 0x05	; 5
    141a:	28 c0       	rjmp	.+80     	; 0x146c <prvIdleTask+0x62>

		/* ucTasksDeleted is used to prevent vTaskSuspendAll() being called
		too often in the idle task. */
		while( uxTasksDeleted > ( UBaseType_t ) 0U )
		{
			vTaskSuspendAll();
    141c:	0e 94 49 08 	call	0x1092	; 0x1092 <vTaskSuspendAll>
			{
				xListIsEmpty = listLIST_IS_EMPTY( &xTasksWaitingTermination );
    1420:	18 81       	ld	r17, Y
			}
			( void ) xTaskResumeAll();
    1422:	0e 94 20 09 	call	0x1240	; 0x1240 <xTaskResumeAll>

			if( xListIsEmpty == pdFALSE )
    1426:	11 23       	and	r17, r17
    1428:	09 f1       	breq	.+66     	; 0x146c <prvIdleTask+0x62>
			{
				TCB_t *pxTCB;

				taskENTER_CRITICAL();
    142a:	0f b6       	in	r0, 0x3f	; 63
    142c:	f8 94       	cli
    142e:	0f 92       	push	r0
				{
					pxTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( ( &xTasksWaitingTermination ) );
    1430:	e0 91 0a 05 	lds	r30, 0x050A
    1434:	f0 91 0b 05 	lds	r31, 0x050B
    1438:	06 81       	ldd	r16, Z+6	; 0x06
    143a:	17 81       	ldd	r17, Z+7	; 0x07
					( void ) uxListRemove( &( pxTCB->xGenericListItem ) );
    143c:	c8 01       	movw	r24, r16
    143e:	02 96       	adiw	r24, 0x02	; 2
    1440:	0e 94 65 01 	call	0x2ca	; 0x2ca <uxListRemove>
					--uxCurrentNumberOfTasks;
    1444:	80 91 03 05 	lds	r24, 0x0503
    1448:	81 50       	subi	r24, 0x01	; 1
    144a:	80 93 03 05 	sts	0x0503, r24
					--uxTasksDeleted;
    144e:	80 91 04 05 	lds	r24, 0x0504
    1452:	81 50       	subi	r24, 0x01	; 1
    1454:	80 93 04 05 	sts	0x0504, r24
				}
				taskEXIT_CRITICAL();
    1458:	0f 90       	pop	r0
    145a:	0f be       	out	0x3f, r0	; 63
				vPortFreeAligned( pxTCB->pxStack );
			}
		}
		#else
		{
			vPortFreeAligned( pxTCB->pxStack );
    145c:	f8 01       	movw	r30, r16
    145e:	87 89       	ldd	r24, Z+23	; 0x17
    1460:	90 8d       	ldd	r25, Z+24	; 0x18
    1462:	0e 94 23 03 	call	0x646	; 0x646 <vPortFree>
		}
		#endif

		vPortFree( pxTCB );
    1466:	c8 01       	movw	r24, r16
    1468:	0e 94 23 03 	call	0x646	; 0x646 <vPortFree>
	{
		BaseType_t xListIsEmpty;

		/* ucTasksDeleted is used to prevent vTaskSuspendAll() being called
		too often in the idle task. */
		while( uxTasksDeleted > ( UBaseType_t ) 0U )
    146c:	80 91 04 05 	lds	r24, 0x0504
    1470:	81 11       	cpse	r24, r1
    1472:	d4 cf       	rjmp	.-88     	; 0x141c <prvIdleTask+0x12>

			A critical region is not required here as we are just reading from
			the list, and an occasional incorrect value will not matter.  If
			the ready list at the idle priority contains more than one task
			then a task other than the idle task is ready to execute. */
			if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ tskIDLE_PRIORITY ] ) ) > ( UBaseType_t ) 1 )
    1474:	f7 01       	movw	r30, r14
    1476:	80 81       	ld	r24, Z
    1478:	82 30       	cpi	r24, 0x02	; 2
    147a:	c0 f3       	brcs	.-16     	; 0x146c <prvIdleTask+0x62>
			{
				taskYIELD();
    147c:	0e 94 36 02 	call	0x46c	; 0x46c <vPortYield>
    1480:	f5 cf       	rjmp	.-22     	; 0x146c <prvIdleTask+0x62>

00001482 <vTaskSwitchContext>:
#endif /* configUSE_APPLICATION_TASK_TAG */
/*-----------------------------------------------------------*/

void vTaskSwitchContext( void )
{
	if( uxSchedulerSuspended != ( UBaseType_t ) pdFALSE )
    1482:	80 91 f8 04 	lds	r24, 0x04F8
    1486:	88 23       	and	r24, r24
    1488:	21 f0       	breq	.+8      	; 0x1492 <vTaskSwitchContext+0x10>
	{
		/* The scheduler is currently suspended - do not allow a context
		switch. */
		xYieldPending = pdTRUE;
    148a:	81 e0       	ldi	r24, 0x01	; 1
    148c:	80 93 fd 04 	sts	0x04FD, r24
    1490:	08 95       	ret
	}
	else
	{
		xYieldPending = pdFALSE;
    1492:	10 92 fd 04 	sts	0x04FD, r1
		/* Check for stack overflow, if configured. */
		taskCHECK_FOR_STACK_OVERFLOW();

		/* Select a new task to run using either the generic C or port
		optimised asm code. */
		taskSELECT_HIGHEST_PRIORITY_TASK();
    1496:	80 91 00 05 	lds	r24, 0x0500
    149a:	90 e0       	ldi	r25, 0x00	; 0
    149c:	fc 01       	movw	r30, r24
    149e:	ee 0f       	add	r30, r30
    14a0:	ff 1f       	adc	r31, r31
    14a2:	ee 0f       	add	r30, r30
    14a4:	ff 1f       	adc	r31, r31
    14a6:	ee 0f       	add	r30, r30
    14a8:	ff 1f       	adc	r31, r31
    14aa:	8e 0f       	add	r24, r30
    14ac:	9f 1f       	adc	r25, r31
    14ae:	fc 01       	movw	r30, r24
    14b0:	e3 5d       	subi	r30, 0xD3	; 211
    14b2:	fa 4f       	sbci	r31, 0xFA	; 250
    14b4:	80 81       	ld	r24, Z
    14b6:	81 11       	cpse	r24, r1
    14b8:	17 c0       	rjmp	.+46     	; 0x14e8 <vTaskSwitchContext+0x66>
    14ba:	80 91 00 05 	lds	r24, 0x0500
    14be:	81 50       	subi	r24, 0x01	; 1
    14c0:	80 93 00 05 	sts	0x0500, r24
    14c4:	80 91 00 05 	lds	r24, 0x0500
    14c8:	90 e0       	ldi	r25, 0x00	; 0
    14ca:	fc 01       	movw	r30, r24
    14cc:	ee 0f       	add	r30, r30
    14ce:	ff 1f       	adc	r31, r31
    14d0:	ee 0f       	add	r30, r30
    14d2:	ff 1f       	adc	r31, r31
    14d4:	ee 0f       	add	r30, r30
    14d6:	ff 1f       	adc	r31, r31
    14d8:	8e 0f       	add	r24, r30
    14da:	9f 1f       	adc	r25, r31
    14dc:	fc 01       	movw	r30, r24
    14de:	e3 5d       	subi	r30, 0xD3	; 211
    14e0:	fa 4f       	sbci	r31, 0xFA	; 250
    14e2:	80 81       	ld	r24, Z
    14e4:	88 23       	and	r24, r24
    14e6:	49 f3       	breq	.-46     	; 0x14ba <vTaskSwitchContext+0x38>
    14e8:	e0 91 00 05 	lds	r30, 0x0500
    14ec:	f0 e0       	ldi	r31, 0x00	; 0
    14ee:	cf 01       	movw	r24, r30
    14f0:	88 0f       	add	r24, r24
    14f2:	99 1f       	adc	r25, r25
    14f4:	88 0f       	add	r24, r24
    14f6:	99 1f       	adc	r25, r25
    14f8:	88 0f       	add	r24, r24
    14fa:	99 1f       	adc	r25, r25
    14fc:	e8 0f       	add	r30, r24
    14fe:	f9 1f       	adc	r31, r25
    1500:	e3 5d       	subi	r30, 0xD3	; 211
    1502:	fa 4f       	sbci	r31, 0xFA	; 250
    1504:	a1 81       	ldd	r26, Z+1	; 0x01
    1506:	b2 81       	ldd	r27, Z+2	; 0x02
    1508:	12 96       	adiw	r26, 0x02	; 2
    150a:	0d 90       	ld	r0, X+
    150c:	bc 91       	ld	r27, X
    150e:	a0 2d       	mov	r26, r0
    1510:	b2 83       	std	Z+2, r27	; 0x02
    1512:	a1 83       	std	Z+1, r26	; 0x01
    1514:	cf 01       	movw	r24, r30
    1516:	03 96       	adiw	r24, 0x03	; 3
    1518:	a8 17       	cp	r26, r24
    151a:	b9 07       	cpc	r27, r25
    151c:	31 f4       	brne	.+12     	; 0x152a <vTaskSwitchContext+0xa8>
    151e:	12 96       	adiw	r26, 0x02	; 2
    1520:	8d 91       	ld	r24, X+
    1522:	9c 91       	ld	r25, X
    1524:	13 97       	sbiw	r26, 0x03	; 3
    1526:	92 83       	std	Z+2, r25	; 0x02
    1528:	81 83       	std	Z+1, r24	; 0x01
    152a:	01 80       	ldd	r0, Z+1	; 0x01
    152c:	f2 81       	ldd	r31, Z+2	; 0x02
    152e:	e0 2d       	mov	r30, r0
    1530:	86 81       	ldd	r24, Z+6	; 0x06
    1532:	97 81       	ldd	r25, Z+7	; 0x07
    1534:	90 93 f7 04 	sts	0x04F7, r25
    1538:	80 93 f6 04 	sts	0x04F6, r24
    153c:	08 95       	ret

0000153e <vTaskPlaceOnEventList>:
	}
}
/*-----------------------------------------------------------*/

void vTaskPlaceOnEventList( List_t * const pxEventList, const TickType_t xTicksToWait )
{
    153e:	cf 93       	push	r28
    1540:	df 93       	push	r29
    1542:	eb 01       	movw	r28, r22

	/* Place the event list item of the TCB in the appropriate event list.
	This is placed in the list in priority order so the highest priority task
	is the first to be woken by the event.  The queue that contains the event
	list is locked, preventing simultaneous access from interrupts. */
	vListInsert( pxEventList, &( pxCurrentTCB->xEventListItem ) );
    1544:	60 91 f6 04 	lds	r22, 0x04F6
    1548:	70 91 f7 04 	lds	r23, 0x04F7
    154c:	64 5f       	subi	r22, 0xF4	; 244
    154e:	7f 4f       	sbci	r23, 0xFF	; 255
    1550:	0e 94 34 01 	call	0x268	; 0x268 <vListInsert>

	/* The task must be removed from from the ready list before it is added to
	the blocked list as the same list item is used for both lists.  Exclusive
	access to the ready lists guaranteed because the scheduler is locked. */
	if( uxListRemove( &( pxCurrentTCB->xGenericListItem ) ) == ( UBaseType_t ) 0 )
    1554:	80 91 f6 04 	lds	r24, 0x04F6
    1558:	90 91 f7 04 	lds	r25, 0x04F7
    155c:	02 96       	adiw	r24, 0x02	; 2
    155e:	0e 94 65 01 	call	0x2ca	; 0x2ca <uxListRemove>
	#else /* INCLUDE_vTaskSuspend */
	{
			/* Calculate the time at which the task should be woken if the event does
			not occur.  This may overflow but this doesn't matter, the scheduler
			will handle it. */
			xTimeToWake = xTickCount + xTicksToWait;
    1562:	80 91 01 05 	lds	r24, 0x0501
    1566:	90 91 02 05 	lds	r25, 0x0502
			prvAddCurrentTaskToDelayedList( xTimeToWake );
    156a:	8c 0f       	add	r24, r28
    156c:	9d 1f       	adc	r25, r29
    156e:	0e 94 8a 06 	call	0xd14	; 0xd14 <prvAddCurrentTaskToDelayedList>
	}
	#endif /* INCLUDE_vTaskSuspend */
}
    1572:	df 91       	pop	r29
    1574:	cf 91       	pop	r28
    1576:	08 95       	ret

00001578 <vTaskPlaceOnUnorderedEventList>:
/*-----------------------------------------------------------*/

void vTaskPlaceOnUnorderedEventList( List_t * pxEventList, const TickType_t xItemValue, const TickType_t xTicksToWait )
{
    1578:	cf 93       	push	r28
    157a:	df 93       	push	r29
    157c:	ea 01       	movw	r28, r20
	configASSERT( uxSchedulerSuspended != 0 );

	/* Store the item value in the event list item.  It is safe to access the
	event list item here as interrupts won't access the event list item of a
	task that is not in the Blocked state. */
	listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ), xItemValue | taskEVENT_LIST_ITEM_VALUE_IN_USE );
    157e:	e0 91 f6 04 	lds	r30, 0x04F6
    1582:	f0 91 f7 04 	lds	r31, 0x04F7
    1586:	70 68       	ori	r23, 0x80	; 128
    1588:	75 87       	std	Z+13, r23	; 0x0d
    158a:	64 87       	std	Z+12, r22	; 0x0c
	/* Place the event list item of the TCB at the end of the appropriate event
	list.  It is safe to access the event list here because it is part of an
	event group implementation - and interrupts don't access event groups
	directly (instead they access them indirectly by pending function calls to
	the task level). */
	vListInsertEnd( pxEventList, &( pxCurrentTCB->xEventListItem ) );
    158c:	60 91 f6 04 	lds	r22, 0x04F6
    1590:	70 91 f7 04 	lds	r23, 0x04F7
    1594:	64 5f       	subi	r22, 0xF4	; 244
    1596:	7f 4f       	sbci	r23, 0xFF	; 255
    1598:	0e 94 13 01 	call	0x226	; 0x226 <vListInsertEnd>

	/* The task must be removed from the ready list before it is added to the
	blocked list.  Exclusive access can be assured to the ready list as the
	scheduler is locked. */
	if( uxListRemove( &( pxCurrentTCB->xGenericListItem ) ) == ( UBaseType_t ) 0 )
    159c:	80 91 f6 04 	lds	r24, 0x04F6
    15a0:	90 91 f7 04 	lds	r25, 0x04F7
    15a4:	02 96       	adiw	r24, 0x02	; 2
    15a6:	0e 94 65 01 	call	0x2ca	; 0x2ca <uxListRemove>
	#else /* INCLUDE_vTaskSuspend */
	{
			/* Calculate the time at which the task should be woken if the event does
			not occur.  This may overflow but this doesn't matter, the kernel
			will manage it correctly. */
			xTimeToWake = xTickCount + xTicksToWait;
    15aa:	80 91 01 05 	lds	r24, 0x0501
    15ae:	90 91 02 05 	lds	r25, 0x0502
			prvAddCurrentTaskToDelayedList( xTimeToWake );
    15b2:	8c 0f       	add	r24, r28
    15b4:	9d 1f       	adc	r25, r29
    15b6:	0e 94 8a 06 	call	0xd14	; 0xd14 <prvAddCurrentTaskToDelayedList>
	}
	#endif /* INCLUDE_vTaskSuspend */
}
    15ba:	df 91       	pop	r29
    15bc:	cf 91       	pop	r28
    15be:	08 95       	ret

000015c0 <xTaskRemoveFromEventList>:

#endif /* configUSE_TIMERS */
/*-----------------------------------------------------------*/

BaseType_t xTaskRemoveFromEventList( const List_t * const pxEventList )
{
    15c0:	0f 93       	push	r16
    15c2:	1f 93       	push	r17
    15c4:	cf 93       	push	r28
    15c6:	df 93       	push	r29
	get called - the lock count on the queue will get modified instead.  This
	means exclusive access to the event list is guaranteed here.

	This function assumes that a check has already been made to ensure that
	pxEventList is not empty. */
	pxUnblockedTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxEventList );
    15c8:	dc 01       	movw	r26, r24
    15ca:	15 96       	adiw	r26, 0x05	; 5
    15cc:	ed 91       	ld	r30, X+
    15ce:	fc 91       	ld	r31, X
    15d0:	16 97       	sbiw	r26, 0x06	; 6
    15d2:	c6 81       	ldd	r28, Z+6	; 0x06
    15d4:	d7 81       	ldd	r29, Z+7	; 0x07
	configASSERT( pxUnblockedTCB );
	( void ) uxListRemove( &( pxUnblockedTCB->xEventListItem ) );
    15d6:	8e 01       	movw	r16, r28
    15d8:	04 5f       	subi	r16, 0xF4	; 244
    15da:	1f 4f       	sbci	r17, 0xFF	; 255
    15dc:	c8 01       	movw	r24, r16
    15de:	0e 94 65 01 	call	0x2ca	; 0x2ca <uxListRemove>

	if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    15e2:	80 91 f8 04 	lds	r24, 0x04F8
    15e6:	81 11       	cpse	r24, r1
    15e8:	1c c0       	rjmp	.+56     	; 0x1622 <xTaskRemoveFromEventList+0x62>
	{
		( void ) uxListRemove( &( pxUnblockedTCB->xGenericListItem ) );
    15ea:	0a 50       	subi	r16, 0x0A	; 10
    15ec:	11 09       	sbc	r17, r1
    15ee:	c8 01       	movw	r24, r16
    15f0:	0e 94 65 01 	call	0x2ca	; 0x2ca <uxListRemove>
		prvAddTaskToReadyList( pxUnblockedTCB );
    15f4:	8e 89       	ldd	r24, Y+22	; 0x16
    15f6:	90 91 00 05 	lds	r25, 0x0500
    15fa:	98 17       	cp	r25, r24
    15fc:	10 f4       	brcc	.+4      	; 0x1602 <xTaskRemoveFromEventList+0x42>
    15fe:	80 93 00 05 	sts	0x0500, r24
    1602:	90 e0       	ldi	r25, 0x00	; 0
    1604:	9c 01       	movw	r18, r24
    1606:	22 0f       	add	r18, r18
    1608:	33 1f       	adc	r19, r19
    160a:	22 0f       	add	r18, r18
    160c:	33 1f       	adc	r19, r19
    160e:	22 0f       	add	r18, r18
    1610:	33 1f       	adc	r19, r19
    1612:	82 0f       	add	r24, r18
    1614:	93 1f       	adc	r25, r19
    1616:	b8 01       	movw	r22, r16
    1618:	83 5d       	subi	r24, 0xD3	; 211
    161a:	9a 4f       	sbci	r25, 0xFA	; 250
    161c:	0e 94 13 01 	call	0x226	; 0x226 <vListInsertEnd>
    1620:	05 c0       	rjmp	.+10     	; 0x162c <xTaskRemoveFromEventList+0x6c>
	}
	else
	{
		/* The delayed and ready lists cannot be accessed, so hold this task
		pending until the scheduler is resumed. */
		vListInsertEnd( &( xPendingReadyList ), &( pxUnblockedTCB->xEventListItem ) );
    1622:	b8 01       	movw	r22, r16
    1624:	8e e0       	ldi	r24, 0x0E	; 14
    1626:	95 e0       	ldi	r25, 0x05	; 5
    1628:	0e 94 13 01 	call	0x226	; 0x226 <vListInsertEnd>
	}

	if( pxUnblockedTCB->uxPriority > pxCurrentTCB->uxPriority )
    162c:	e0 91 f6 04 	lds	r30, 0x04F6
    1630:	f0 91 f7 04 	lds	r31, 0x04F7
    1634:	9e 89       	ldd	r25, Y+22	; 0x16
    1636:	86 89       	ldd	r24, Z+22	; 0x16
    1638:	89 17       	cp	r24, r25
    163a:	20 f4       	brcc	.+8      	; 0x1644 <xTaskRemoveFromEventList+0x84>
		it should force a context switch now. */
		xReturn = pdTRUE;

		/* Mark that a yield is pending in case the user is not using the
		"xHigherPriorityTaskWoken" parameter to an ISR safe FreeRTOS function. */
		xYieldPending = pdTRUE;
    163c:	81 e0       	ldi	r24, 0x01	; 1
    163e:	80 93 fd 04 	sts	0x04FD, r24
    1642:	01 c0       	rjmp	.+2      	; 0x1646 <xTaskRemoveFromEventList+0x86>
	}
	else
	{
		xReturn = pdFALSE;
    1644:	80 e0       	ldi	r24, 0x00	; 0
		prvResetNextTaskUnblockTime();
	}
	#endif

	return xReturn;
}
    1646:	df 91       	pop	r29
    1648:	cf 91       	pop	r28
    164a:	1f 91       	pop	r17
    164c:	0f 91       	pop	r16
    164e:	08 95       	ret

00001650 <xTaskRemoveFromUnorderedEventList>:
/*-----------------------------------------------------------*/

BaseType_t xTaskRemoveFromUnorderedEventList( ListItem_t * pxEventListItem, const TickType_t xItemValue )
{
    1650:	0f 93       	push	r16
    1652:	1f 93       	push	r17
    1654:	cf 93       	push	r28
    1656:	df 93       	push	r29
	/* THIS FUNCTION MUST BE CALLED WITH THE SCHEDULER SUSPENDED.  It is used by
	the event flags implementation. */
	configASSERT( uxSchedulerSuspended != pdFALSE );

	/* Store the new item value in the event list. */
	listSET_LIST_ITEM_VALUE( pxEventListItem, xItemValue | taskEVENT_LIST_ITEM_VALUE_IN_USE );
    1658:	70 68       	ori	r23, 0x80	; 128
    165a:	fc 01       	movw	r30, r24
    165c:	71 83       	std	Z+1, r23	; 0x01
    165e:	60 83       	st	Z, r22

	/* Remove the event list form the event flag.  Interrupts do not access
	event flags. */
	pxUnblockedTCB = ( TCB_t * ) listGET_LIST_ITEM_OWNER( pxEventListItem );
    1660:	c6 81       	ldd	r28, Z+6	; 0x06
    1662:	d7 81       	ldd	r29, Z+7	; 0x07
	configASSERT( pxUnblockedTCB );
	( void ) uxListRemove( pxEventListItem );
    1664:	0e 94 65 01 	call	0x2ca	; 0x2ca <uxListRemove>

	/* Remove the task from the delayed list and add it to the ready list.  The
	scheduler is suspended so interrupts will not be accessing the ready
	lists. */
	( void ) uxListRemove( &( pxUnblockedTCB->xGenericListItem ) );
    1668:	8e 01       	movw	r16, r28
    166a:	0e 5f       	subi	r16, 0xFE	; 254
    166c:	1f 4f       	sbci	r17, 0xFF	; 255
    166e:	c8 01       	movw	r24, r16
    1670:	0e 94 65 01 	call	0x2ca	; 0x2ca <uxListRemove>
	prvAddTaskToReadyList( pxUnblockedTCB );
    1674:	8e 89       	ldd	r24, Y+22	; 0x16
    1676:	90 91 00 05 	lds	r25, 0x0500
    167a:	98 17       	cp	r25, r24
    167c:	10 f4       	brcc	.+4      	; 0x1682 <xTaskRemoveFromUnorderedEventList+0x32>
    167e:	80 93 00 05 	sts	0x0500, r24
    1682:	90 e0       	ldi	r25, 0x00	; 0
    1684:	9c 01       	movw	r18, r24
    1686:	22 0f       	add	r18, r18
    1688:	33 1f       	adc	r19, r19
    168a:	22 0f       	add	r18, r18
    168c:	33 1f       	adc	r19, r19
    168e:	22 0f       	add	r18, r18
    1690:	33 1f       	adc	r19, r19
    1692:	82 0f       	add	r24, r18
    1694:	93 1f       	adc	r25, r19
    1696:	b8 01       	movw	r22, r16
    1698:	83 5d       	subi	r24, 0xD3	; 211
    169a:	9a 4f       	sbci	r25, 0xFA	; 250
    169c:	0e 94 13 01 	call	0x226	; 0x226 <vListInsertEnd>

	if( pxUnblockedTCB->uxPriority > pxCurrentTCB->uxPriority )
    16a0:	e0 91 f6 04 	lds	r30, 0x04F6
    16a4:	f0 91 f7 04 	lds	r31, 0x04F7
    16a8:	9e 89       	ldd	r25, Y+22	; 0x16
    16aa:	86 89       	ldd	r24, Z+22	; 0x16
    16ac:	89 17       	cp	r24, r25
    16ae:	20 f4       	brcc	.+8      	; 0x16b8 <xTaskRemoveFromUnorderedEventList+0x68>
		switch now. */
		xReturn = pdTRUE;

		/* Mark that a yield is pending in case the user is not using the
		"xHigherPriorityTaskWoken" parameter to an ISR safe FreeRTOS function. */
		xYieldPending = pdTRUE;
    16b0:	81 e0       	ldi	r24, 0x01	; 1
    16b2:	80 93 fd 04 	sts	0x04FD, r24
    16b6:	01 c0       	rjmp	.+2      	; 0x16ba <xTaskRemoveFromUnorderedEventList+0x6a>
	}
	else
	{
		xReturn = pdFALSE;
    16b8:	80 e0       	ldi	r24, 0x00	; 0
	}

	return xReturn;
}
    16ba:	df 91       	pop	r29
    16bc:	cf 91       	pop	r28
    16be:	1f 91       	pop	r17
    16c0:	0f 91       	pop	r16
    16c2:	08 95       	ret

000016c4 <vTaskSetTimeOutState>:
/*-----------------------------------------------------------*/

void vTaskSetTimeOutState( TimeOut_t * const pxTimeOut )
{
	configASSERT( pxTimeOut );
	pxTimeOut->xOverflowCount = xNumOfOverflows;
    16c4:	20 91 fc 04 	lds	r18, 0x04FC
    16c8:	fc 01       	movw	r30, r24
    16ca:	20 83       	st	Z, r18
	pxTimeOut->xTimeOnEntering = xTickCount;
    16cc:	20 91 01 05 	lds	r18, 0x0501
    16d0:	30 91 02 05 	lds	r19, 0x0502
    16d4:	32 83       	std	Z+2, r19	; 0x02
    16d6:	21 83       	std	Z+1, r18	; 0x01
    16d8:	08 95       	ret

000016da <xTaskCheckForTimeOut>:
BaseType_t xReturn;

	configASSERT( pxTimeOut );
	configASSERT( pxTicksToWait );

	taskENTER_CRITICAL();
    16da:	0f b6       	in	r0, 0x3f	; 63
    16dc:	f8 94       	cli
    16de:	0f 92       	push	r0
	{
		/* Minor optimisation.  The tick count cannot change in this block. */
		const TickType_t xConstTickCount = xTickCount;
    16e0:	20 91 01 05 	lds	r18, 0x0501
    16e4:	30 91 02 05 	lds	r19, 0x0502
				xReturn = pdFALSE;
			}
			else /* We are not blocking indefinitely, perform the checks below. */
		#endif

		if( ( xNumOfOverflows != pxTimeOut->xOverflowCount ) && ( xConstTickCount >= pxTimeOut->xTimeOnEntering ) ) /*lint !e525 Indentation preferred as is to make code within pre-processor directives clearer. */
    16e8:	40 91 fc 04 	lds	r20, 0x04FC
    16ec:	dc 01       	movw	r26, r24
    16ee:	5c 91       	ld	r21, X
    16f0:	54 17       	cp	r21, r20
    16f2:	39 f0       	breq	.+14     	; 0x1702 <xTaskCheckForTimeOut+0x28>
    16f4:	11 96       	adiw	r26, 0x01	; 1
    16f6:	4d 91       	ld	r20, X+
    16f8:	5c 91       	ld	r21, X
    16fa:	12 97       	sbiw	r26, 0x02	; 2
    16fc:	24 17       	cp	r18, r20
    16fe:	35 07       	cpc	r19, r21
    1700:	c8 f4       	brcc	.+50     	; 0x1734 <xTaskCheckForTimeOut+0x5a>
			was called, but has also overflowed since vTaskSetTimeOut() was called.
			It must have wrapped all the way around and gone past us again. This
			passed since vTaskSetTimeout() was called. */
			xReturn = pdTRUE;
		}
		else if( ( xConstTickCount - pxTimeOut->xTimeOnEntering ) < *pxTicksToWait )
    1702:	dc 01       	movw	r26, r24
    1704:	11 96       	adiw	r26, 0x01	; 1
    1706:	ed 91       	ld	r30, X+
    1708:	fc 91       	ld	r31, X
    170a:	12 97       	sbiw	r26, 0x02	; 2
    170c:	db 01       	movw	r26, r22
    170e:	4d 91       	ld	r20, X+
    1710:	5c 91       	ld	r21, X
    1712:	d9 01       	movw	r26, r18
    1714:	ae 1b       	sub	r26, r30
    1716:	bf 0b       	sbc	r27, r31
    1718:	a4 17       	cp	r26, r20
    171a:	b5 07       	cpc	r27, r21
    171c:	68 f4       	brcc	.+26     	; 0x1738 <xTaskCheckForTimeOut+0x5e>
		{
			/* Not a genuine timeout. Adjust parameters for time remaining. */
			*pxTicksToWait -= ( xConstTickCount -  pxTimeOut->xTimeOnEntering );
    171e:	e2 1b       	sub	r30, r18
    1720:	f3 0b       	sbc	r31, r19
    1722:	4e 0f       	add	r20, r30
    1724:	5f 1f       	adc	r21, r31
    1726:	fb 01       	movw	r30, r22
    1728:	51 83       	std	Z+1, r21	; 0x01
    172a:	40 83       	st	Z, r20
			vTaskSetTimeOutState( pxTimeOut );
    172c:	0e 94 62 0b 	call	0x16c4	; 0x16c4 <vTaskSetTimeOutState>
			xReturn = pdFALSE;
    1730:	80 e0       	ldi	r24, 0x00	; 0
    1732:	03 c0       	rjmp	.+6      	; 0x173a <xTaskCheckForTimeOut+0x60>
		{
			/* The tick count is greater than the time at which vTaskSetTimeout()
			was called, but has also overflowed since vTaskSetTimeOut() was called.
			It must have wrapped all the way around and gone past us again. This
			passed since vTaskSetTimeout() was called. */
			xReturn = pdTRUE;
    1734:	81 e0       	ldi	r24, 0x01	; 1
    1736:	01 c0       	rjmp	.+2      	; 0x173a <xTaskCheckForTimeOut+0x60>
			vTaskSetTimeOutState( pxTimeOut );
			xReturn = pdFALSE;
		}
		else
		{
			xReturn = pdTRUE;
    1738:	81 e0       	ldi	r24, 0x01	; 1
		}
	}
	taskEXIT_CRITICAL();
    173a:	0f 90       	pop	r0
    173c:	0f be       	out	0x3f, r0	; 63

	return xReturn;
}
    173e:	08 95       	ret

00001740 <vTaskMissedYield>:
/*-----------------------------------------------------------*/

void vTaskMissedYield( void )
{
	xYieldPending = pdTRUE;
    1740:	81 e0       	ldi	r24, 0x01	; 1
    1742:	80 93 fd 04 	sts	0x04FD, r24
    1746:	08 95       	ret

00001748 <uxTaskResetEventItemValue>:

TickType_t uxTaskResetEventItemValue( void )
{
TickType_t uxReturn;

	uxReturn = listGET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ) );
    1748:	e0 91 f6 04 	lds	r30, 0x04F6
    174c:	f0 91 f7 04 	lds	r31, 0x04F7
    1750:	84 85       	ldd	r24, Z+12	; 0x0c
    1752:	95 85       	ldd	r25, Z+13	; 0x0d

	/* Reset the event list item to its normal value - so it can be used with
	queues and semaphores. */
	listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ), ( ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) pxCurrentTCB->uxPriority ) ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    1754:	e0 91 f6 04 	lds	r30, 0x04F6
    1758:	f0 91 f7 04 	lds	r31, 0x04F7
    175c:	a0 91 f6 04 	lds	r26, 0x04F6
    1760:	b0 91 f7 04 	lds	r27, 0x04F7
    1764:	56 96       	adiw	r26, 0x16	; 22
    1766:	4c 91       	ld	r20, X
    1768:	24 e0       	ldi	r18, 0x04	; 4
    176a:	30 e0       	ldi	r19, 0x00	; 0
    176c:	24 1b       	sub	r18, r20
    176e:	31 09       	sbc	r19, r1
    1770:	35 87       	std	Z+13, r19	; 0x0d
    1772:	24 87       	std	Z+12, r18	; 0x0c

	return uxReturn;
}
    1774:	08 95       	ret

00001776 <ulTaskNotifyTake>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	uint32_t ulTaskNotifyTake( BaseType_t xClearCountOnExit, TickType_t xTicksToWait )
	{
    1776:	0f 93       	push	r16
    1778:	1f 93       	push	r17
    177a:	cf 93       	push	r28
    177c:	c8 2f       	mov	r28, r24
    177e:	8b 01       	movw	r16, r22
	TickType_t xTimeToWake;
	uint32_t ulReturn;

		taskENTER_CRITICAL();
    1780:	0f b6       	in	r0, 0x3f	; 63
    1782:	f8 94       	cli
    1784:	0f 92       	push	r0
		{
			/* Only block if the notification count is not already non-zero. */
			if( pxCurrentTCB->ulNotifiedValue == 0UL )
    1786:	e0 91 f6 04 	lds	r30, 0x04F6
    178a:	f0 91 f7 04 	lds	r31, 0x04F7
    178e:	41 a1       	ldd	r20, Z+33	; 0x21
    1790:	52 a1       	ldd	r21, Z+34	; 0x22
    1792:	63 a1       	ldd	r22, Z+35	; 0x23
    1794:	74 a1       	ldd	r23, Z+36	; 0x24
    1796:	45 2b       	or	r20, r21
    1798:	46 2b       	or	r20, r22
    179a:	47 2b       	or	r20, r23
    179c:	d1 f4       	brne	.+52     	; 0x17d2 <ulTaskNotifyTake+0x5c>
			{
				/* Mark this task as waiting for a notification. */
				pxCurrentTCB->eNotifyState = eWaitingNotification;
    179e:	e0 91 f6 04 	lds	r30, 0x04F6
    17a2:	f0 91 f7 04 	lds	r31, 0x04F7
    17a6:	81 e0       	ldi	r24, 0x01	; 1
    17a8:	85 a3       	std	Z+37, r24	; 0x25

				if( xTicksToWait > ( TickType_t ) 0 )
    17aa:	01 15       	cp	r16, r1
    17ac:	11 05       	cpc	r17, r1
    17ae:	89 f0       	breq	.+34     	; 0x17d2 <ulTaskNotifyTake+0x5c>
				{
					/* The task is going to block.  First it must be removed
					from the ready list. */
					if( uxListRemove( &( pxCurrentTCB->xGenericListItem ) ) == ( UBaseType_t ) 0 )
    17b0:	80 91 f6 04 	lds	r24, 0x04F6
    17b4:	90 91 f7 04 	lds	r25, 0x04F7
    17b8:	02 96       	adiw	r24, 0x02	; 2
    17ba:	0e 94 65 01 	call	0x2ca	; 0x2ca <uxListRemove>
					{
							/* Calculate the time at which the task should be
							woken if the event does not occur.  This may
							overflow but this doesn't matter, the scheduler will
							handle it. */
							xTimeToWake = xTickCount + xTicksToWait;
    17be:	80 91 01 05 	lds	r24, 0x0501
    17c2:	90 91 02 05 	lds	r25, 0x0502
							prvAddCurrentTaskToDelayedList( xTimeToWake );
    17c6:	80 0f       	add	r24, r16
    17c8:	91 1f       	adc	r25, r17
    17ca:	0e 94 8a 06 	call	0xd14	; 0xd14 <prvAddCurrentTaskToDelayedList>

					/* All ports are written to allow a yield in a critical
					section (some will yield immediately, others wait until the
					critical section exits) - but it is not something that
					application code should ever do. */
					portYIELD_WITHIN_API();
    17ce:	0e 94 36 02 	call	0x46c	; 0x46c <vPortYield>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		taskEXIT_CRITICAL();
    17d2:	0f 90       	pop	r0
    17d4:	0f be       	out	0x3f, r0	; 63

		taskENTER_CRITICAL();
    17d6:	0f b6       	in	r0, 0x3f	; 63
    17d8:	f8 94       	cli
    17da:	0f 92       	push	r0
		{
			traceTASK_NOTIFY_TAKE();
			ulReturn = pxCurrentTCB->ulNotifiedValue;
    17dc:	e0 91 f6 04 	lds	r30, 0x04F6
    17e0:	f0 91 f7 04 	lds	r31, 0x04F7
    17e4:	61 a1       	ldd	r22, Z+33	; 0x21
    17e6:	72 a1       	ldd	r23, Z+34	; 0x22
    17e8:	83 a1       	ldd	r24, Z+35	; 0x23
    17ea:	94 a1       	ldd	r25, Z+36	; 0x24

			if( ulReturn != 0UL )
    17ec:	61 15       	cp	r22, r1
    17ee:	71 05       	cpc	r23, r1
    17f0:	81 05       	cpc	r24, r1
    17f2:	91 05       	cpc	r25, r1
    17f4:	d9 f0       	breq	.+54     	; 0x182c <ulTaskNotifyTake+0xb6>
			{
				if( xClearCountOnExit != pdFALSE )
    17f6:	cc 23       	and	r28, r28
    17f8:	49 f0       	breq	.+18     	; 0x180c <ulTaskNotifyTake+0x96>
				{
					pxCurrentTCB->ulNotifiedValue = 0UL;
    17fa:	e0 91 f6 04 	lds	r30, 0x04F6
    17fe:	f0 91 f7 04 	lds	r31, 0x04F7
    1802:	11 a2       	std	Z+33, r1	; 0x21
    1804:	12 a2       	std	Z+34, r1	; 0x22
    1806:	13 a2       	std	Z+35, r1	; 0x23
    1808:	14 a2       	std	Z+36, r1	; 0x24
    180a:	10 c0       	rjmp	.+32     	; 0x182c <ulTaskNotifyTake+0xb6>
				}
				else
				{
					( pxCurrentTCB->ulNotifiedValue )--;
    180c:	e0 91 f6 04 	lds	r30, 0x04F6
    1810:	f0 91 f7 04 	lds	r31, 0x04F7
    1814:	01 a1       	ldd	r16, Z+33	; 0x21
    1816:	12 a1       	ldd	r17, Z+34	; 0x22
    1818:	23 a1       	ldd	r18, Z+35	; 0x23
    181a:	34 a1       	ldd	r19, Z+36	; 0x24
    181c:	01 50       	subi	r16, 0x01	; 1
    181e:	11 09       	sbc	r17, r1
    1820:	21 09       	sbc	r18, r1
    1822:	31 09       	sbc	r19, r1
    1824:	01 a3       	std	Z+33, r16	; 0x21
    1826:	12 a3       	std	Z+34, r17	; 0x22
    1828:	23 a3       	std	Z+35, r18	; 0x23
    182a:	34 a3       	std	Z+36, r19	; 0x24
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}

			pxCurrentTCB->eNotifyState = eNotWaitingNotification;
    182c:	e0 91 f6 04 	lds	r30, 0x04F6
    1830:	f0 91 f7 04 	lds	r31, 0x04F7
    1834:	15 a2       	std	Z+37, r1	; 0x25
		}
		taskEXIT_CRITICAL();
    1836:	0f 90       	pop	r0
    1838:	0f be       	out	0x3f, r0	; 63

		return ulReturn;
	}
    183a:	cf 91       	pop	r28
    183c:	1f 91       	pop	r17
    183e:	0f 91       	pop	r16
    1840:	08 95       	ret

00001842 <xTaskNotifyWait>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	BaseType_t xTaskNotifyWait( uint32_t ulBitsToClearOnEntry, uint32_t ulBitsToClearOnExit, uint32_t *pulNotificationValue, TickType_t xTicksToWait )
	{
    1842:	4f 92       	push	r4
    1844:	5f 92       	push	r5
    1846:	6f 92       	push	r6
    1848:	7f 92       	push	r7
    184a:	8f 92       	push	r8
    184c:	9f 92       	push	r9
    184e:	af 92       	push	r10
    1850:	bf 92       	push	r11
    1852:	ef 92       	push	r14
    1854:	ff 92       	push	r15
    1856:	0f 93       	push	r16
    1858:	1f 93       	push	r17
    185a:	49 01       	movw	r8, r18
    185c:	5a 01       	movw	r10, r20
	TickType_t xTimeToWake;
	BaseType_t xReturn;

		taskENTER_CRITICAL();
    185e:	0f b6       	in	r0, 0x3f	; 63
    1860:	f8 94       	cli
    1862:	0f 92       	push	r0
		{
			/* Only block if a notification is not already pending. */
			if( pxCurrentTCB->eNotifyState != eNotified )
    1864:	e0 91 f6 04 	lds	r30, 0x04F6
    1868:	f0 91 f7 04 	lds	r31, 0x04F7
    186c:	25 a1       	ldd	r18, Z+37	; 0x25
    186e:	22 30       	cpi	r18, 0x02	; 2
    1870:	81 f1       	breq	.+96     	; 0x18d2 <xTaskNotifyWait+0x90>
			{
				/* Clear bits in the task's notification value as bits may get
				set	by the notifying task or interrupt.  This can be used to
				clear the value to zero. */
				pxCurrentTCB->ulNotifiedValue &= ~ulBitsToClearOnEntry;
    1872:	e0 91 f6 04 	lds	r30, 0x04F6
    1876:	f0 91 f7 04 	lds	r31, 0x04F7
    187a:	41 a0       	ldd	r4, Z+33	; 0x21
    187c:	52 a0       	ldd	r5, Z+34	; 0x22
    187e:	63 a0       	ldd	r6, Z+35	; 0x23
    1880:	74 a0       	ldd	r7, Z+36	; 0x24
    1882:	dc 01       	movw	r26, r24
    1884:	cb 01       	movw	r24, r22
    1886:	80 95       	com	r24
    1888:	90 95       	com	r25
    188a:	a0 95       	com	r26
    188c:	b0 95       	com	r27
    188e:	84 21       	and	r24, r4
    1890:	95 21       	and	r25, r5
    1892:	a6 21       	and	r26, r6
    1894:	b7 21       	and	r27, r7
    1896:	81 a3       	std	Z+33, r24	; 0x21
    1898:	92 a3       	std	Z+34, r25	; 0x22
    189a:	a3 a3       	std	Z+35, r26	; 0x23
    189c:	b4 a3       	std	Z+36, r27	; 0x24

				/* Mark this task as waiting for a notification. */
				pxCurrentTCB->eNotifyState = eWaitingNotification;
    189e:	e0 91 f6 04 	lds	r30, 0x04F6
    18a2:	f0 91 f7 04 	lds	r31, 0x04F7
    18a6:	81 e0       	ldi	r24, 0x01	; 1
    18a8:	85 a3       	std	Z+37, r24	; 0x25

				if( xTicksToWait > ( TickType_t ) 0 )
    18aa:	e1 14       	cp	r14, r1
    18ac:	f1 04       	cpc	r15, r1
    18ae:	89 f0       	breq	.+34     	; 0x18d2 <xTaskNotifyWait+0x90>
				{
					/* The task is going to block.  First it must be removed
					from the	ready list. */
					if( uxListRemove( &( pxCurrentTCB->xGenericListItem ) ) == ( UBaseType_t ) 0 )
    18b0:	80 91 f6 04 	lds	r24, 0x04F6
    18b4:	90 91 f7 04 	lds	r25, 0x04F7
    18b8:	02 96       	adiw	r24, 0x02	; 2
    18ba:	0e 94 65 01 	call	0x2ca	; 0x2ca <uxListRemove>
					{
							/* Calculate the time at which the task should be
							woken if the event does not occur.  This may
							overflow but this doesn't matter, the scheduler will
							handle it. */
							xTimeToWake = xTickCount + xTicksToWait;
    18be:	80 91 01 05 	lds	r24, 0x0501
    18c2:	90 91 02 05 	lds	r25, 0x0502
							prvAddCurrentTaskToDelayedList( xTimeToWake );
    18c6:	8e 0d       	add	r24, r14
    18c8:	9f 1d       	adc	r25, r15
    18ca:	0e 94 8a 06 	call	0xd14	; 0xd14 <prvAddCurrentTaskToDelayedList>

					/* All ports are written to allow a yield in a critical
					section (some will yield immediately, others wait until the
					critical section exits) - but it is not something that
					application code should ever do. */
					portYIELD_WITHIN_API();
    18ce:	0e 94 36 02 	call	0x46c	; 0x46c <vPortYield>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		taskEXIT_CRITICAL();
    18d2:	0f 90       	pop	r0
    18d4:	0f be       	out	0x3f, r0	; 63

		taskENTER_CRITICAL();
    18d6:	0f b6       	in	r0, 0x3f	; 63
    18d8:	f8 94       	cli
    18da:	0f 92       	push	r0
		{
			traceTASK_NOTIFY_WAIT();

			if( pulNotificationValue != NULL )
    18dc:	01 15       	cp	r16, r1
    18de:	11 05       	cpc	r17, r1
    18e0:	69 f0       	breq	.+26     	; 0x18fc <xTaskNotifyWait+0xba>
			{
				/* Output the current notification value, which may or may not
				have changed. */
				*pulNotificationValue = pxCurrentTCB->ulNotifiedValue;
    18e2:	e0 91 f6 04 	lds	r30, 0x04F6
    18e6:	f0 91 f7 04 	lds	r31, 0x04F7
    18ea:	81 a1       	ldd	r24, Z+33	; 0x21
    18ec:	92 a1       	ldd	r25, Z+34	; 0x22
    18ee:	a3 a1       	ldd	r26, Z+35	; 0x23
    18f0:	b4 a1       	ldd	r27, Z+36	; 0x24
    18f2:	f8 01       	movw	r30, r16
    18f4:	80 83       	st	Z, r24
    18f6:	91 83       	std	Z+1, r25	; 0x01
    18f8:	a2 83       	std	Z+2, r26	; 0x02
    18fa:	b3 83       	std	Z+3, r27	; 0x03

			/* If eNotifyValue is set then either the task never entered the
			blocked state (because a notification was already pending) or the
			task unblocked because of a notification.  Otherwise the task
			unblocked because of a timeout. */
			if( pxCurrentTCB->eNotifyState == eWaitingNotification )
    18fc:	e0 91 f6 04 	lds	r30, 0x04F6
    1900:	f0 91 f7 04 	lds	r31, 0x04F7
    1904:	85 a1       	ldd	r24, Z+37	; 0x25
    1906:	81 30       	cpi	r24, 0x01	; 1
    1908:	b1 f0       	breq	.+44     	; 0x1936 <xTaskNotifyWait+0xf4>
			}
			else
			{
				/* A notification was already pending or a notification was
				received while the task was waiting. */
				pxCurrentTCB->ulNotifiedValue &= ~ulBitsToClearOnExit;
    190a:	e0 91 f6 04 	lds	r30, 0x04F6
    190e:	f0 91 f7 04 	lds	r31, 0x04F7
    1912:	81 a1       	ldd	r24, Z+33	; 0x21
    1914:	92 a1       	ldd	r25, Z+34	; 0x22
    1916:	a3 a1       	ldd	r26, Z+35	; 0x23
    1918:	b4 a1       	ldd	r27, Z+36	; 0x24
    191a:	80 94       	com	r8
    191c:	90 94       	com	r9
    191e:	a0 94       	com	r10
    1920:	b0 94       	com	r11
    1922:	88 22       	and	r8, r24
    1924:	99 22       	and	r9, r25
    1926:	aa 22       	and	r10, r26
    1928:	bb 22       	and	r11, r27
    192a:	81 a2       	std	Z+33, r8	; 0x21
    192c:	92 a2       	std	Z+34, r9	; 0x22
    192e:	a3 a2       	std	Z+35, r10	; 0x23
    1930:	b4 a2       	std	Z+36, r11	; 0x24
				xReturn = pdTRUE;
    1932:	81 e0       	ldi	r24, 0x01	; 1
    1934:	01 c0       	rjmp	.+2      	; 0x1938 <xTaskNotifyWait+0xf6>
			task unblocked because of a notification.  Otherwise the task
			unblocked because of a timeout. */
			if( pxCurrentTCB->eNotifyState == eWaitingNotification )
			{
				/* A notification was not received. */
				xReturn = pdFALSE;
    1936:	80 e0       	ldi	r24, 0x00	; 0
				received while the task was waiting. */
				pxCurrentTCB->ulNotifiedValue &= ~ulBitsToClearOnExit;
				xReturn = pdTRUE;
			}

			pxCurrentTCB->eNotifyState = eNotWaitingNotification;
    1938:	e0 91 f6 04 	lds	r30, 0x04F6
    193c:	f0 91 f7 04 	lds	r31, 0x04F7
    1940:	15 a2       	std	Z+37, r1	; 0x25
		}
		taskEXIT_CRITICAL();
    1942:	0f 90       	pop	r0
    1944:	0f be       	out	0x3f, r0	; 63

		return xReturn;
	}
    1946:	1f 91       	pop	r17
    1948:	0f 91       	pop	r16
    194a:	ff 90       	pop	r15
    194c:	ef 90       	pop	r14
    194e:	bf 90       	pop	r11
    1950:	af 90       	pop	r10
    1952:	9f 90       	pop	r9
    1954:	8f 90       	pop	r8
    1956:	7f 90       	pop	r7
    1958:	6f 90       	pop	r6
    195a:	5f 90       	pop	r5
    195c:	4f 90       	pop	r4
    195e:	08 95       	ret

00001960 <xTaskGenericNotify>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	BaseType_t xTaskGenericNotify( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, uint32_t *pulPreviousNotificationValue )
	{
    1960:	cf 92       	push	r12
    1962:	df 92       	push	r13
    1964:	ef 92       	push	r14
    1966:	ff 92       	push	r15
    1968:	0f 93       	push	r16
    196a:	1f 93       	push	r17
    196c:	cf 93       	push	r28
    196e:	df 93       	push	r29
    1970:	ec 01       	movw	r28, r24
	BaseType_t xReturn = pdPASS;

		configASSERT( xTaskToNotify );
		pxTCB = ( TCB_t * ) xTaskToNotify;

		taskENTER_CRITICAL();
    1972:	0f b6       	in	r0, 0x3f	; 63
    1974:	f8 94       	cli
    1976:	0f 92       	push	r0
		{
			if( pulPreviousNotificationValue != NULL )
    1978:	01 15       	cp	r16, r1
    197a:	11 05       	cpc	r17, r1
    197c:	49 f0       	breq	.+18     	; 0x1990 <xTaskGenericNotify+0x30>
			{
				*pulPreviousNotificationValue = pxTCB->ulNotifiedValue;
    197e:	c9 a0       	ldd	r12, Y+33	; 0x21
    1980:	da a0       	ldd	r13, Y+34	; 0x22
    1982:	eb a0       	ldd	r14, Y+35	; 0x23
    1984:	fc a0       	ldd	r15, Y+36	; 0x24
    1986:	f8 01       	movw	r30, r16
    1988:	c0 82       	st	Z, r12
    198a:	d1 82       	std	Z+1, r13	; 0x01
    198c:	e2 82       	std	Z+2, r14	; 0x02
    198e:	f3 82       	std	Z+3, r15	; 0x03
			}

			eOriginalNotifyState = pxTCB->eNotifyState;
    1990:	8d a1       	ldd	r24, Y+37	; 0x25

			pxTCB->eNotifyState = eNotified;
    1992:	92 e0       	ldi	r25, 0x02	; 2
    1994:	9d a3       	std	Y+37, r25	; 0x25

			switch( eAction )
    1996:	22 30       	cpi	r18, 0x02	; 2
    1998:	b1 f0       	breq	.+44     	; 0x19c6 <xTaskGenericNotify+0x66>
    199a:	18 f4       	brcc	.+6      	; 0x19a2 <xTaskGenericNotify+0x42>
    199c:	21 30       	cpi	r18, 0x01	; 1
    199e:	31 f0       	breq	.+12     	; 0x19ac <xTaskGenericNotify+0x4c>
    19a0:	2a c0       	rjmp	.+84     	; 0x19f6 <xTaskGenericNotify+0x96>
    19a2:	23 30       	cpi	r18, 0x03	; 3
    19a4:	e9 f0       	breq	.+58     	; 0x19e0 <xTaskGenericNotify+0x80>
    19a6:	24 30       	cpi	r18, 0x04	; 4
    19a8:	01 f1       	breq	.+64     	; 0x19ea <xTaskGenericNotify+0x8a>
    19aa:	25 c0       	rjmp	.+74     	; 0x19f6 <xTaskGenericNotify+0x96>
			{
				case eSetBits	:
					pxTCB->ulNotifiedValue |= ulValue;
    19ac:	c9 a0       	ldd	r12, Y+33	; 0x21
    19ae:	da a0       	ldd	r13, Y+34	; 0x22
    19b0:	eb a0       	ldd	r14, Y+35	; 0x23
    19b2:	fc a0       	ldd	r15, Y+36	; 0x24
    19b4:	4c 29       	or	r20, r12
    19b6:	5d 29       	or	r21, r13
    19b8:	6e 29       	or	r22, r14
    19ba:	7f 29       	or	r23, r15
    19bc:	49 a3       	std	Y+33, r20	; 0x21
    19be:	5a a3       	std	Y+34, r21	; 0x22
    19c0:	6b a3       	std	Y+35, r22	; 0x23
    19c2:	7c a3       	std	Y+36, r23	; 0x24
					break;
    19c4:	18 c0       	rjmp	.+48     	; 0x19f6 <xTaskGenericNotify+0x96>

				case eIncrement	:
					( pxTCB->ulNotifiedValue )++;
    19c6:	49 a1       	ldd	r20, Y+33	; 0x21
    19c8:	5a a1       	ldd	r21, Y+34	; 0x22
    19ca:	6b a1       	ldd	r22, Y+35	; 0x23
    19cc:	7c a1       	ldd	r23, Y+36	; 0x24
    19ce:	4f 5f       	subi	r20, 0xFF	; 255
    19d0:	5f 4f       	sbci	r21, 0xFF	; 255
    19d2:	6f 4f       	sbci	r22, 0xFF	; 255
    19d4:	7f 4f       	sbci	r23, 0xFF	; 255
    19d6:	49 a3       	std	Y+33, r20	; 0x21
    19d8:	5a a3       	std	Y+34, r21	; 0x22
    19da:	6b a3       	std	Y+35, r22	; 0x23
    19dc:	7c a3       	std	Y+36, r23	; 0x24
					break;
    19de:	0b c0       	rjmp	.+22     	; 0x19f6 <xTaskGenericNotify+0x96>

				case eSetValueWithOverwrite	:
					pxTCB->ulNotifiedValue = ulValue;
    19e0:	49 a3       	std	Y+33, r20	; 0x21
    19e2:	5a a3       	std	Y+34, r21	; 0x22
    19e4:	6b a3       	std	Y+35, r22	; 0x23
    19e6:	7c a3       	std	Y+36, r23	; 0x24
					break;
    19e8:	06 c0       	rjmp	.+12     	; 0x19f6 <xTaskGenericNotify+0x96>

				case eSetValueWithoutOverwrite :
					if( eOriginalNotifyState != eNotified )
    19ea:	82 30       	cpi	r24, 0x02	; 2
    19ec:	71 f1       	breq	.+92     	; 0x1a4a <xTaskGenericNotify+0xea>
					{
						pxTCB->ulNotifiedValue = ulValue;
    19ee:	49 a3       	std	Y+33, r20	; 0x21
    19f0:	5a a3       	std	Y+34, r21	; 0x22
    19f2:	6b a3       	std	Y+35, r22	; 0x23
    19f4:	7c a3       	std	Y+36, r23	; 0x24

			traceTASK_NOTIFY();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( eOriginalNotifyState == eWaitingNotification )
    19f6:	81 30       	cpi	r24, 0x01	; 1
    19f8:	51 f5       	brne	.+84     	; 0x1a4e <xTaskGenericNotify+0xee>
			{
				( void ) uxListRemove( &( pxTCB->xGenericListItem ) );
    19fa:	8e 01       	movw	r16, r28
    19fc:	0e 5f       	subi	r16, 0xFE	; 254
    19fe:	1f 4f       	sbci	r17, 0xFF	; 255
    1a00:	c8 01       	movw	r24, r16
    1a02:	0e 94 65 01 	call	0x2ca	; 0x2ca <uxListRemove>
				prvAddTaskToReadyList( pxTCB );
    1a06:	8e 89       	ldd	r24, Y+22	; 0x16
    1a08:	90 91 00 05 	lds	r25, 0x0500
    1a0c:	98 17       	cp	r25, r24
    1a0e:	10 f4       	brcc	.+4      	; 0x1a14 <xTaskGenericNotify+0xb4>
    1a10:	80 93 00 05 	sts	0x0500, r24
    1a14:	90 e0       	ldi	r25, 0x00	; 0
    1a16:	9c 01       	movw	r18, r24
    1a18:	22 0f       	add	r18, r18
    1a1a:	33 1f       	adc	r19, r19
    1a1c:	22 0f       	add	r18, r18
    1a1e:	33 1f       	adc	r19, r19
    1a20:	22 0f       	add	r18, r18
    1a22:	33 1f       	adc	r19, r19
    1a24:	82 0f       	add	r24, r18
    1a26:	93 1f       	adc	r25, r19
    1a28:	b8 01       	movw	r22, r16
    1a2a:	83 5d       	subi	r24, 0xD3	; 211
    1a2c:	9a 4f       	sbci	r25, 0xFA	; 250
    1a2e:	0e 94 13 01 	call	0x226	; 0x226 <vListInsertEnd>
					earliest possible time. */
					prvResetNextTaskUnblockTime();
				}
				#endif

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    1a32:	e0 91 f6 04 	lds	r30, 0x04F6
    1a36:	f0 91 f7 04 	lds	r31, 0x04F7
    1a3a:	9e 89       	ldd	r25, Y+22	; 0x16
    1a3c:	86 89       	ldd	r24, Z+22	; 0x16
    1a3e:	89 17       	cp	r24, r25
    1a40:	40 f4       	brcc	.+16     	; 0x1a52 <xTaskGenericNotify+0xf2>
				{
					/* The notified task has a priority above the currently
					executing task so a yield is required. */
					taskYIELD_IF_USING_PREEMPTION();
    1a42:	0e 94 36 02 	call	0x46c	; 0x46c <vPortYield>
    1a46:	81 e0       	ldi	r24, 0x01	; 1
    1a48:	05 c0       	rjmp	.+10     	; 0x1a54 <xTaskGenericNotify+0xf4>
						pxTCB->ulNotifiedValue = ulValue;
					}
					else
					{
						/* The value could not be written to the task. */
						xReturn = pdFAIL;
    1a4a:	80 e0       	ldi	r24, 0x00	; 0
    1a4c:	03 c0       	rjmp	.+6      	; 0x1a54 <xTaskGenericNotify+0xf4>
    1a4e:	81 e0       	ldi	r24, 0x01	; 1
    1a50:	01 c0       	rjmp	.+2      	; 0x1a54 <xTaskGenericNotify+0xf4>
    1a52:	81 e0       	ldi	r24, 0x01	; 1
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		taskEXIT_CRITICAL();
    1a54:	0f 90       	pop	r0
    1a56:	0f be       	out	0x3f, r0	; 63

		return xReturn;
	}
    1a58:	df 91       	pop	r29
    1a5a:	cf 91       	pop	r28
    1a5c:	1f 91       	pop	r17
    1a5e:	0f 91       	pop	r16
    1a60:	ff 90       	pop	r15
    1a62:	ef 90       	pop	r14
    1a64:	df 90       	pop	r13
    1a66:	cf 90       	pop	r12
    1a68:	08 95       	ret

00001a6a <xTaskGenericNotifyFromISR>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	BaseType_t xTaskGenericNotifyFromISR( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, uint32_t *pulPreviousNotificationValue, BaseType_t *pxHigherPriorityTaskWoken )
	{
    1a6a:	af 92       	push	r10
    1a6c:	bf 92       	push	r11
    1a6e:	cf 92       	push	r12
    1a70:	df 92       	push	r13
    1a72:	ef 92       	push	r14
    1a74:	ff 92       	push	r15
    1a76:	0f 93       	push	r16
    1a78:	1f 93       	push	r17
    1a7a:	cf 93       	push	r28
    1a7c:	df 93       	push	r29
    1a7e:	ec 01       	movw	r28, r24
    1a80:	57 01       	movw	r10, r14

		pxTCB = ( TCB_t * ) xTaskToNotify;

		uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
		{
			if( pulPreviousNotificationValue != NULL )
    1a82:	01 15       	cp	r16, r1
    1a84:	11 05       	cpc	r17, r1
    1a86:	49 f0       	breq	.+18     	; 0x1a9a <xTaskGenericNotifyFromISR+0x30>
			{
				*pulPreviousNotificationValue = pxTCB->ulNotifiedValue;
    1a88:	c9 a0       	ldd	r12, Y+33	; 0x21
    1a8a:	da a0       	ldd	r13, Y+34	; 0x22
    1a8c:	eb a0       	ldd	r14, Y+35	; 0x23
    1a8e:	fc a0       	ldd	r15, Y+36	; 0x24
    1a90:	f8 01       	movw	r30, r16
    1a92:	c0 82       	st	Z, r12
    1a94:	d1 82       	std	Z+1, r13	; 0x01
    1a96:	e2 82       	std	Z+2, r14	; 0x02
    1a98:	f3 82       	std	Z+3, r15	; 0x03
			}

			eOriginalNotifyState = pxTCB->eNotifyState;
    1a9a:	3d a1       	ldd	r19, Y+37	; 0x25
			pxTCB->eNotifyState = eNotified;
    1a9c:	82 e0       	ldi	r24, 0x02	; 2
    1a9e:	8d a3       	std	Y+37, r24	; 0x25

			switch( eAction )
    1aa0:	22 30       	cpi	r18, 0x02	; 2
    1aa2:	b1 f0       	breq	.+44     	; 0x1ad0 <xTaskGenericNotifyFromISR+0x66>
    1aa4:	18 f4       	brcc	.+6      	; 0x1aac <xTaskGenericNotifyFromISR+0x42>
    1aa6:	21 30       	cpi	r18, 0x01	; 1
    1aa8:	31 f0       	breq	.+12     	; 0x1ab6 <xTaskGenericNotifyFromISR+0x4c>
    1aaa:	29 c0       	rjmp	.+82     	; 0x1afe <xTaskGenericNotifyFromISR+0x94>
    1aac:	23 30       	cpi	r18, 0x03	; 3
    1aae:	e1 f0       	breq	.+56     	; 0x1ae8 <xTaskGenericNotifyFromISR+0x7e>
    1ab0:	24 30       	cpi	r18, 0x04	; 4
    1ab2:	f9 f0       	breq	.+62     	; 0x1af2 <xTaskGenericNotifyFromISR+0x88>
    1ab4:	24 c0       	rjmp	.+72     	; 0x1afe <xTaskGenericNotifyFromISR+0x94>
			{
				case eSetBits	:
					pxTCB->ulNotifiedValue |= ulValue;
    1ab6:	89 a1       	ldd	r24, Y+33	; 0x21
    1ab8:	9a a1       	ldd	r25, Y+34	; 0x22
    1aba:	ab a1       	ldd	r26, Y+35	; 0x23
    1abc:	bc a1       	ldd	r27, Y+36	; 0x24
    1abe:	48 2b       	or	r20, r24
    1ac0:	59 2b       	or	r21, r25
    1ac2:	6a 2b       	or	r22, r26
    1ac4:	7b 2b       	or	r23, r27
    1ac6:	49 a3       	std	Y+33, r20	; 0x21
    1ac8:	5a a3       	std	Y+34, r21	; 0x22
    1aca:	6b a3       	std	Y+35, r22	; 0x23
    1acc:	7c a3       	std	Y+36, r23	; 0x24
					break;
    1ace:	17 c0       	rjmp	.+46     	; 0x1afe <xTaskGenericNotifyFromISR+0x94>

				case eIncrement	:
					( pxTCB->ulNotifiedValue )++;
    1ad0:	89 a1       	ldd	r24, Y+33	; 0x21
    1ad2:	9a a1       	ldd	r25, Y+34	; 0x22
    1ad4:	ab a1       	ldd	r26, Y+35	; 0x23
    1ad6:	bc a1       	ldd	r27, Y+36	; 0x24
    1ad8:	01 96       	adiw	r24, 0x01	; 1
    1ada:	a1 1d       	adc	r26, r1
    1adc:	b1 1d       	adc	r27, r1
    1ade:	89 a3       	std	Y+33, r24	; 0x21
    1ae0:	9a a3       	std	Y+34, r25	; 0x22
    1ae2:	ab a3       	std	Y+35, r26	; 0x23
    1ae4:	bc a3       	std	Y+36, r27	; 0x24
					break;
    1ae6:	0b c0       	rjmp	.+22     	; 0x1afe <xTaskGenericNotifyFromISR+0x94>

				case eSetValueWithOverwrite	:
					pxTCB->ulNotifiedValue = ulValue;
    1ae8:	49 a3       	std	Y+33, r20	; 0x21
    1aea:	5a a3       	std	Y+34, r21	; 0x22
    1aec:	6b a3       	std	Y+35, r22	; 0x23
    1aee:	7c a3       	std	Y+36, r23	; 0x24
					break;
    1af0:	06 c0       	rjmp	.+12     	; 0x1afe <xTaskGenericNotifyFromISR+0x94>

				case eSetValueWithoutOverwrite :
					if( eOriginalNotifyState != eNotified )
    1af2:	32 30       	cpi	r19, 0x02	; 2
    1af4:	e9 f1       	breq	.+122    	; 0x1b70 <xTaskGenericNotifyFromISR+0x106>
					{
						pxTCB->ulNotifiedValue = ulValue;
    1af6:	49 a3       	std	Y+33, r20	; 0x21
    1af8:	5a a3       	std	Y+34, r21	; 0x22
    1afa:	6b a3       	std	Y+35, r22	; 0x23
    1afc:	7c a3       	std	Y+36, r23	; 0x24

			traceTASK_NOTIFY_FROM_ISR();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( eOriginalNotifyState == eWaitingNotification )
    1afe:	31 30       	cpi	r19, 0x01	; 1
    1b00:	c9 f5       	brne	.+114    	; 0x1b74 <xTaskGenericNotifyFromISR+0x10a>
			{
				/* The task should not have been on an event list. */
				configASSERT( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) == NULL );

				if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    1b02:	80 91 f8 04 	lds	r24, 0x04F8
    1b06:	81 11       	cpse	r24, r1
    1b08:	1d c0       	rjmp	.+58     	; 0x1b44 <xTaskGenericNotifyFromISR+0xda>
				{
					( void ) uxListRemove( &( pxTCB->xGenericListItem ) );
    1b0a:	8e 01       	movw	r16, r28
    1b0c:	0e 5f       	subi	r16, 0xFE	; 254
    1b0e:	1f 4f       	sbci	r17, 0xFF	; 255
    1b10:	c8 01       	movw	r24, r16
    1b12:	0e 94 65 01 	call	0x2ca	; 0x2ca <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    1b16:	8e 89       	ldd	r24, Y+22	; 0x16
    1b18:	90 91 00 05 	lds	r25, 0x0500
    1b1c:	98 17       	cp	r25, r24
    1b1e:	10 f4       	brcc	.+4      	; 0x1b24 <xTaskGenericNotifyFromISR+0xba>
    1b20:	80 93 00 05 	sts	0x0500, r24
    1b24:	90 e0       	ldi	r25, 0x00	; 0
    1b26:	9c 01       	movw	r18, r24
    1b28:	22 0f       	add	r18, r18
    1b2a:	33 1f       	adc	r19, r19
    1b2c:	22 0f       	add	r18, r18
    1b2e:	33 1f       	adc	r19, r19
    1b30:	22 0f       	add	r18, r18
    1b32:	33 1f       	adc	r19, r19
    1b34:	82 0f       	add	r24, r18
    1b36:	93 1f       	adc	r25, r19
    1b38:	b8 01       	movw	r22, r16
    1b3a:	83 5d       	subi	r24, 0xD3	; 211
    1b3c:	9a 4f       	sbci	r25, 0xFA	; 250
    1b3e:	0e 94 13 01 	call	0x226	; 0x226 <vListInsertEnd>
    1b42:	07 c0       	rjmp	.+14     	; 0x1b52 <xTaskGenericNotifyFromISR+0xe8>
				}
				else
				{
					/* The delayed and ready lists cannot be accessed, so hold
					this task pending until the scheduler is resumed. */
					vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );
    1b44:	be 01       	movw	r22, r28
    1b46:	64 5f       	subi	r22, 0xF4	; 244
    1b48:	7f 4f       	sbci	r23, 0xFF	; 255
    1b4a:	8e e0       	ldi	r24, 0x0E	; 14
    1b4c:	95 e0       	ldi	r25, 0x05	; 5
    1b4e:	0e 94 13 01 	call	0x226	; 0x226 <vListInsertEnd>
				}

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    1b52:	e0 91 f6 04 	lds	r30, 0x04F6
    1b56:	f0 91 f7 04 	lds	r31, 0x04F7
    1b5a:	9e 89       	ldd	r25, Y+22	; 0x16
    1b5c:	86 89       	ldd	r24, Z+22	; 0x16
    1b5e:	89 17       	cp	r24, r25
    1b60:	58 f4       	brcc	.+22     	; 0x1b78 <xTaskGenericNotifyFromISR+0x10e>
				{
					/* The notified task has a priority above the currently
					executing task so a yield is required. */
					if( pxHigherPriorityTaskWoken != NULL )
    1b62:	a1 14       	cp	r10, r1
    1b64:	b1 04       	cpc	r11, r1
    1b66:	51 f0       	breq	.+20     	; 0x1b7c <xTaskGenericNotifyFromISR+0x112>
					{
						*pxHigherPriorityTaskWoken = pdTRUE;
    1b68:	81 e0       	ldi	r24, 0x01	; 1
    1b6a:	f5 01       	movw	r30, r10
    1b6c:	80 83       	st	Z, r24
    1b6e:	07 c0       	rjmp	.+14     	; 0x1b7e <xTaskGenericNotifyFromISR+0x114>
						pxTCB->ulNotifiedValue = ulValue;
					}
					else
					{
						/* The value could not be written to the task. */
						xReturn = pdFAIL;
    1b70:	80 e0       	ldi	r24, 0x00	; 0
    1b72:	05 c0       	rjmp	.+10     	; 0x1b7e <xTaskGenericNotifyFromISR+0x114>
    1b74:	81 e0       	ldi	r24, 0x01	; 1
    1b76:	03 c0       	rjmp	.+6      	; 0x1b7e <xTaskGenericNotifyFromISR+0x114>
    1b78:	81 e0       	ldi	r24, 0x01	; 1
    1b7a:	01 c0       	rjmp	.+2      	; 0x1b7e <xTaskGenericNotifyFromISR+0x114>
    1b7c:	81 e0       	ldi	r24, 0x01	; 1
			}
		}
		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

		return xReturn;
	}
    1b7e:	df 91       	pop	r29
    1b80:	cf 91       	pop	r28
    1b82:	1f 91       	pop	r17
    1b84:	0f 91       	pop	r16
    1b86:	ff 90       	pop	r15
    1b88:	ef 90       	pop	r14
    1b8a:	df 90       	pop	r13
    1b8c:	cf 90       	pop	r12
    1b8e:	bf 90       	pop	r11
    1b90:	af 90       	pop	r10
    1b92:	08 95       	ret

00001b94 <vTaskNotifyGiveFromISR>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	void vTaskNotifyGiveFromISR( TaskHandle_t xTaskToNotify, BaseType_t *pxHigherPriorityTaskWoken )
	{
    1b94:	ef 92       	push	r14
    1b96:	ff 92       	push	r15
    1b98:	0f 93       	push	r16
    1b9a:	1f 93       	push	r17
    1b9c:	cf 93       	push	r28
    1b9e:	df 93       	push	r29
    1ba0:	ec 01       	movw	r28, r24
    1ba2:	8b 01       	movw	r16, r22

		pxTCB = ( TCB_t * ) xTaskToNotify;

		uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
		{
			eOriginalNotifyState = pxTCB->eNotifyState;
    1ba4:	8d a1       	ldd	r24, Y+37	; 0x25
			pxTCB->eNotifyState = eNotified;
    1ba6:	92 e0       	ldi	r25, 0x02	; 2
    1ba8:	9d a3       	std	Y+37, r25	; 0x25

			/* 'Giving' is equivalent to incrementing a count in a counting
			semaphore. */
			( pxTCB->ulNotifiedValue )++;
    1baa:	49 a1       	ldd	r20, Y+33	; 0x21
    1bac:	5a a1       	ldd	r21, Y+34	; 0x22
    1bae:	6b a1       	ldd	r22, Y+35	; 0x23
    1bb0:	7c a1       	ldd	r23, Y+36	; 0x24
    1bb2:	4f 5f       	subi	r20, 0xFF	; 255
    1bb4:	5f 4f       	sbci	r21, 0xFF	; 255
    1bb6:	6f 4f       	sbci	r22, 0xFF	; 255
    1bb8:	7f 4f       	sbci	r23, 0xFF	; 255
    1bba:	49 a3       	std	Y+33, r20	; 0x21
    1bbc:	5a a3       	std	Y+34, r21	; 0x22
    1bbe:	6b a3       	std	Y+35, r22	; 0x23
    1bc0:	7c a3       	std	Y+36, r23	; 0x24

			traceTASK_NOTIFY_GIVE_FROM_ISR();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( eOriginalNotifyState == eWaitingNotification )
    1bc2:	81 30       	cpi	r24, 0x01	; 1
    1bc4:	b9 f5       	brne	.+110    	; 0x1c34 <vTaskNotifyGiveFromISR+0xa0>
			{
				/* The task should not have been on an event list. */
				configASSERT( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) == NULL );

				if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    1bc6:	80 91 f8 04 	lds	r24, 0x04F8
    1bca:	81 11       	cpse	r24, r1
    1bcc:	1e c0       	rjmp	.+60     	; 0x1c0a <vTaskNotifyGiveFromISR+0x76>
				{
					( void ) uxListRemove( &( pxTCB->xGenericListItem ) );
    1bce:	7e 01       	movw	r14, r28
    1bd0:	82 e0       	ldi	r24, 0x02	; 2
    1bd2:	e8 0e       	add	r14, r24
    1bd4:	f1 1c       	adc	r15, r1
    1bd6:	c7 01       	movw	r24, r14
    1bd8:	0e 94 65 01 	call	0x2ca	; 0x2ca <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    1bdc:	8e 89       	ldd	r24, Y+22	; 0x16
    1bde:	90 91 00 05 	lds	r25, 0x0500
    1be2:	98 17       	cp	r25, r24
    1be4:	10 f4       	brcc	.+4      	; 0x1bea <vTaskNotifyGiveFromISR+0x56>
    1be6:	80 93 00 05 	sts	0x0500, r24
    1bea:	90 e0       	ldi	r25, 0x00	; 0
    1bec:	9c 01       	movw	r18, r24
    1bee:	22 0f       	add	r18, r18
    1bf0:	33 1f       	adc	r19, r19
    1bf2:	22 0f       	add	r18, r18
    1bf4:	33 1f       	adc	r19, r19
    1bf6:	22 0f       	add	r18, r18
    1bf8:	33 1f       	adc	r19, r19
    1bfa:	82 0f       	add	r24, r18
    1bfc:	93 1f       	adc	r25, r19
    1bfe:	b7 01       	movw	r22, r14
    1c00:	83 5d       	subi	r24, 0xD3	; 211
    1c02:	9a 4f       	sbci	r25, 0xFA	; 250
    1c04:	0e 94 13 01 	call	0x226	; 0x226 <vListInsertEnd>
    1c08:	07 c0       	rjmp	.+14     	; 0x1c18 <vTaskNotifyGiveFromISR+0x84>
				}
				else
				{
					/* The delayed and ready lists cannot be accessed, so hold
					this task pending until the scheduler is resumed. */
					vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );
    1c0a:	be 01       	movw	r22, r28
    1c0c:	64 5f       	subi	r22, 0xF4	; 244
    1c0e:	7f 4f       	sbci	r23, 0xFF	; 255
    1c10:	8e e0       	ldi	r24, 0x0E	; 14
    1c12:	95 e0       	ldi	r25, 0x05	; 5
    1c14:	0e 94 13 01 	call	0x226	; 0x226 <vListInsertEnd>
				}

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    1c18:	e0 91 f6 04 	lds	r30, 0x04F6
    1c1c:	f0 91 f7 04 	lds	r31, 0x04F7
    1c20:	9e 89       	ldd	r25, Y+22	; 0x16
    1c22:	86 89       	ldd	r24, Z+22	; 0x16
    1c24:	89 17       	cp	r24, r25
    1c26:	30 f4       	brcc	.+12     	; 0x1c34 <vTaskNotifyGiveFromISR+0xa0>
				{
					/* The notified task has a priority above the currently
					executing task so a yield is required. */
					if( pxHigherPriorityTaskWoken != NULL )
    1c28:	01 15       	cp	r16, r1
    1c2a:	11 05       	cpc	r17, r1
    1c2c:	19 f0       	breq	.+6      	; 0x1c34 <vTaskNotifyGiveFromISR+0xa0>
					{
						*pxHigherPriorityTaskWoken = pdTRUE;
    1c2e:	81 e0       	ldi	r24, 0x01	; 1
    1c30:	f8 01       	movw	r30, r16
    1c32:	80 83       	st	Z, r24
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
	}
    1c34:	df 91       	pop	r29
    1c36:	cf 91       	pop	r28
    1c38:	1f 91       	pop	r17
    1c3a:	0f 91       	pop	r16
    1c3c:	ff 90       	pop	r15
    1c3e:	ef 90       	pop	r14
    1c40:	08 95       	ret

00001c42 <xTaskNotifyStateClear>:

		pxTCB = ( TCB_t * ) xTask;

		/* If null is passed in here then it is the calling task that is having
		its notification state cleared. */
		pxTCB = prvGetTCBFromHandle( pxTCB );
    1c42:	00 97       	sbiw	r24, 0x00	; 0
    1c44:	21 f4       	brne	.+8      	; 0x1c4e <xTaskNotifyStateClear+0xc>
    1c46:	80 91 f6 04 	lds	r24, 0x04F6
    1c4a:	90 91 f7 04 	lds	r25, 0x04F7

		taskENTER_CRITICAL();
    1c4e:	0f b6       	in	r0, 0x3f	; 63
    1c50:	f8 94       	cli
    1c52:	0f 92       	push	r0
		{
			if( pxTCB->eNotifyState == eNotified )
    1c54:	fc 01       	movw	r30, r24
    1c56:	25 a1       	ldd	r18, Z+37	; 0x25
    1c58:	22 30       	cpi	r18, 0x02	; 2
    1c5a:	19 f4       	brne	.+6      	; 0x1c62 <xTaskNotifyStateClear+0x20>
			{
				pxTCB->eNotifyState = eNotWaitingNotification;
    1c5c:	15 a2       	std	Z+37, r1	; 0x25
				xReturn = pdPASS;
    1c5e:	81 e0       	ldi	r24, 0x01	; 1
    1c60:	01 c0       	rjmp	.+2      	; 0x1c64 <xTaskNotifyStateClear+0x22>
			}
			else
			{
				xReturn = pdFAIL;
    1c62:	80 e0       	ldi	r24, 0x00	; 0
			}
		}
		taskEXIT_CRITICAL();
    1c64:	0f 90       	pop	r0
    1c66:	0f be       	out	0x3f, r0	; 63

		return xReturn;
	}
    1c68:	08 95       	ret

00001c6a <memcpy>:
    1c6a:	fb 01       	movw	r30, r22
    1c6c:	dc 01       	movw	r26, r24
    1c6e:	02 c0       	rjmp	.+4      	; 0x1c74 <memcpy+0xa>
    1c70:	01 90       	ld	r0, Z+
    1c72:	0d 92       	st	X+, r0
    1c74:	41 50       	subi	r20, 0x01	; 1
    1c76:	50 40       	sbci	r21, 0x00	; 0
    1c78:	d8 f7       	brcc	.-10     	; 0x1c70 <memcpy+0x6>
    1c7a:	08 95       	ret

00001c7c <_exit>:
    1c7c:	f8 94       	cli

00001c7e <__stop_program>:
    1c7e:	ff cf       	rjmp	.-2      	; 0x1c7e <__stop_program>
